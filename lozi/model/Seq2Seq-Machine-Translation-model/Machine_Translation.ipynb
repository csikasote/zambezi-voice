{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hB3RXcYyL9gQ"
   },
   "source": [
    "# Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Machine Translation model for Nyanja-English\n",
    "# UNZA\n",
    "## Zambezi-Voice\n",
    "### Supervisor: Mr. Clayton Sikasote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KF477bqbGeNu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lh65nfALNlIH"
   },
   "source": [
    "### Dataset Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fU80Ao-AGaob"
   },
   "outputs": [],
   "source": [
    "file = open(\"nya.txt\", 'r', encoding = \"utf8\")\n",
    "raw_data = []\n",
    "\n",
    "for line in file:\n",
    "    pos = line.find(\"CC-BY\")\n",
    "    line = line[:pos-1]\n",
    "    \n",
    "    # Split the data into english and Italian\n",
    "    eng, nya = line.split('\\t')\n",
    "    \n",
    "    # form tuples of the data\n",
    "    data = eng, nya\n",
    "    raw_data.append(data)\n",
    "    \n",
    "file.close()\n",
    "\n",
    "def convert(list): \n",
    "    return tuple(list) \n",
    "\n",
    "data = convert(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('Bere.', 'Breast.'),\n",
       " ('Bereka.', 'to bear.'),\n",
       " ('Biliwila.', 'to be green.'),\n",
       " ('Bingu.', 'roar of thunder.'),\n",
       " ('Birimankhwe.', 'Chameleon.'),\n",
       " ('Bisa.', 'To hide something.'),\n",
       " ('Bisala.', 'to hide oneself.'),\n",
       " ('Bodza.', 'a lie.'),\n",
       " ('Bondo.', 'Knee.'),\n",
       " ('Bongo-Bongo.', 'Brain.'),\n",
       " ('Boola.', 'to pierce.'),\n",
       " ('Bovu.', 'cheeks.'),\n",
       " ('Buluzi.', 'Lizard.'),\n",
       " ('Busa.', 'to herd.'),\n",
       " ('Busa.', 'place for flock to rest or eat.'),\n",
       " ('Buthu.', 'a little girl who has not yet reached puberty.'),\n",
       " ('Buula.', 'to groan.'),\n",
       " ('Bvaka.', 'to clothe someone.'),\n",
       " ('Bvala.', 'to put on clothes.'),\n",
       " ('Bveka.', 'to clothe someone.'),\n",
       " ('Bvika.', 'to thatch.'),\n",
       " ('Bviika.', 'to dip.'),\n",
       " ('Bvina.', 'to dance.'),\n",
       " ('Bvumbala.', 'to take out.'),\n",
       " ('Bvomera.', 'to agree.'),\n",
       " ('Bvula.', 'to take off clothes.'),\n",
       " ('Bvulala.', 'to be wounded.'),\n",
       " ('Bvulaza.', 'to hurt someone seriously.'),\n",
       " ('Bvumbwe.', 'wild cat.'),\n",
       " ('Bvumbwa.', 'to be wet with rain.'),\n",
       " ('Bvunda.', 'to be rotten.'),\n",
       " ('Bvundikila.', 'to cover.'),\n",
       " ('Bvundula.', 'to stir up.'),\n",
       " ('Bvundukula.', 'to uncover.'),\n",
       " ('Chipasu-pasu.', 'desolation.'),\n",
       " ('Chipata.', 'a gate.'),\n",
       " ('Chipatso.', 'a fruit.'),\n",
       " ('Chipere.', 'a skin disease.'),\n",
       " ('Chipewa.', 'hat.'),\n",
       " ('Chiphuphu.', 'a bribe.'),\n",
       " ('Chipinda.', 'bedroom.'),\n",
       " ('Chiponde.', 'mashed food mostly peanut butter.'),\n",
       " ('Chipongwe.', 'rudeness.'),\n",
       " ('Chipsepse.', 'tail fish.'),\n",
       " ('Chipsera.', 'the scar of an old wound.'),\n",
       " ('Dzala.', 'ash heap.'),\n",
       " ('Dzana.', 'the day before yesterday.'),\n",
       " ('Dzabdira.', 'to stagger.'),\n",
       " ('Dzanda.', 'to stagger.'),\n",
       " ('Dzandidzandzi.', 'the weak.'),\n",
       " ('Dzanja.', 'arm.'),\n",
       " ('Dzaza.', 'to fill.'),\n",
       " ('Fa.', 'to die.'),\n",
       " ('Falitsa.', 'to spread about.'),\n",
       " ('Fanana.', 'to be similar.'),\n",
       " ('Fanizo.', 'a parable.'),\n",
       " ('Fano.', 'an image.'),\n",
       " ('Fatsa.', 'to be kind.'),\n",
       " ('Felela.', 'thatch.'),\n",
       " ('Feluka.', 'to fail.'),\n",
       " ('Fendaluzi.', 'the Luzi tree.'),\n",
       " ('Fesa.', 'to sow.'),\n",
       " ('Fewa.', 'to be soft.'),\n",
       " ('Fika.', 'to arrive.'),\n",
       " ('Gareta.', 'a cart.'),\n",
       " ('Garu.', 'a dog.'),\n",
       " ('Gaula.', 'to dig.'),\n",
       " ('Gawa.', 'to divide.'),\n",
       " ('Gaya.', 'to grind.'),\n",
       " ('Gela/Gera.', 'to shave.'),\n",
       " ('Gogo', 'a grandparent.'),\n",
       " ('Gogoda.', 'to knock.'),\n",
       " ('Goli.', 'a slave-stick.'),\n",
       " ('Gombe.', 'the edge.'),\n",
       " ('Gomola.', 'sweet.'),\n",
       " ('Gulula.', 'to take out of it`s socket.'),\n",
       " ('Gumuka.', 'to fall down.'),\n",
       " ('Gund.', 'to hit.'),\n",
       " ('Gundika.', 'to be in full swing.'),\n",
       " ('Guwa.', 'a platform.'),\n",
       " ('Gwa.', 'to fall.'),\n",
       " ('Gwa.', 'strong.'),\n",
       " ('Gwada.', 'to kneel down.'),\n",
       " ('Gwedza.', 'to shake.'),\n",
       " ('Gwedeza.', 'to shake.'),\n",
       " ('Gwero.', 'a source.'),\n",
       " ('Gwira.', 'to catch'),\n",
       " ('Gwirana.', 'to hold each other.'),\n",
       " ('Kacamba.', 'sweet potatoe.'),\n",
       " ('Kacasu.', 'distilled beer.'),\n",
       " ('Kacere.', 'a very large evergreen tree.'),\n",
       " ('Kacetecete.', 'in silence.'),\n",
       " ('Kacisi.', 'a small hut for the spirits of the dead.'),\n",
       " ('Kadendene.', 'heel.'),\n",
       " ('Kaduka.', 'jealousy.'),\n",
       " ('Kadzitape.', 'a tell-tale.'),\n",
       " ('Kadzidzi.', 'a small owl with a large head.'),\n",
       " ('Kaidi.', 'a jail.'),\n",
       " ('Kaikakaika.', 'to doubt.'),\n",
       " ('Kali.', 'angry.'),\n",
       " ('Kalimba.', 'a hand piano.'),\n",
       " ('Kalipa.', 'to be angry.'),\n",
       " ('Kalipira.', 'to be angry against someone.'),\n",
       " ('Kalilombe.', 'a Chamleon.'),\n",
       " ('Kaliwa.', 'a pipe.'),\n",
       " ('Kalize.', 'centipede.'),\n",
       " ('Kalulu.', 'Rabbit.'),\n",
       " ('Kama.', 'to milk.'),\n",
       " ('Kama.', 'a bedstead.'),\n",
       " ('Kamba.', 'to tell.'),\n",
       " ('Kamba.', 'a Tortoise.'),\n",
       " ('Kanthu.', 'something.'),\n",
       " ('Kamula.', 'to open.'),\n",
       " ('Kanya.', 'to knead dough.'),\n",
       " ('Kapa.', 'to bail water out of a boat.'),\n",
       " ('Kapena.', 'maybe.'),\n",
       " ('Kapici.', 'a stout pole.'),\n",
       " ('Kapitao.', 'Captain.'),\n",
       " ('Kapokola.', 'Police.'),\n",
       " ('Kapolo.', 'a slave.'),\n",
       " ('Kasenye.', 'the smallest of the Antelopes.'),\n",
       " ('Kasule.', 'a Whitlow.'),\n",
       " ('Kasupe.', 'a spring of water.'),\n",
       " ('Katemo.', 'a small axe.'),\n",
       " ('Kapompho.', 'axe.'),\n",
       " ('Katondo.', 'a kind of red soil.'),\n",
       " ('Katundu.', 'belongings.'),\n",
       " ('Kavalo.', 'a horse.'),\n",
       " ('Kawiri.', 'twice.'),\n",
       " ('Kaya.', 'perhaps.'),\n",
       " ('Kayikira.', 'to doubt.'),\n",
       " ('Khumba.', 'to desire strongly.'),\n",
       " ('Khumbi.', 'a shed.'),\n",
       " ('khundu.', 'a side.'),\n",
       " ('Khumi.', 'ten.'),\n",
       " ('Khungu.', 'skin.'),\n",
       " ('Khunkha.', 'to collect the gleanings after the harvest.'),\n",
       " ('Khungubwi.', 'a crow.'),\n",
       " ('Khungwa.', 'bark of a tree.'),\n",
       " ('Khunyu.', 'Epilesy.'),\n",
       " ('Khuphuka.', 'to get rich suddenly.'),\n",
       " ('Khuta.', 'to be satisfied.'),\n",
       " ('Kodi?', 'introduces a question.'),\n",
       " ('Kodi.', 'Really!'),\n",
       " ('Kodola.', 'to beakon.'),\n",
       " ('Kodza.', 'to urinate.'),\n",
       " ('Koka.', 'to pull.'),\n",
       " ('Kokoma.', 'to roar.'),\n",
       " ('Kokota.', 'to scrape out.'),\n",
       " ('Kola.', 'to catch.'),\n",
       " ('Kolera.', 'to be on fire.'),\n",
       " ('Koleza.', 'to blow into the fire.'),\n",
       " ('Kutumula.', 'to shake off.'),\n",
       " ('Kutsagana.', 'to accompany each other.'),\n",
       " ('Kutsira.', 'to pour.'),\n",
       " ('Kutsukuluza.', 'to rinse.'),\n",
       " ('Kuthwawa.', 'to run away.'),\n",
       " ('Kuwa.', 'to cry out.'),\n",
       " ('Kuwanitsa.', 'to be able.'),\n",
       " ('Landa.', 'to seize.'),\n",
       " ('Landira.', 'to receive.'),\n",
       " ('Landitsa.', 'to set free.'),\n",
       " ('Langa.', 'to punish.'),\n",
       " ('Langiza.', 'to advise.'),\n",
       " ('Lankhula.', 'to speak.'),\n",
       " ('Lapa.', 'to regret.'),\n",
       " ('Lasa.', 'to hit.'),\n",
       " ('Ledzera.', 'to be drunk.'),\n",
       " ('Leka.', 'to cease doing something.'),\n",
       " ('Lekana.', 'to part.'),\n",
       " ('Lekerera.', 'to bear with.'),\n",
       " ('Lema.', 'to be tired.'),\n",
       " ('Lemara.', 'to be lame.'),\n",
       " ('Lemba.', 'to write.'),\n",
       " ('Lemkeza.', 'to respect.'),\n",
       " ('Lemera.', 'to be heavy.'),\n",
       " ('Litepo.', 'leaf.'),\n",
       " ('Liti.', 'when?'),\n",
       " ('Litsilo.', 'dirt.'),\n",
       " ('Litsipa.', 'headache.'),\n",
       " ('Liu.', 'a voice.'),\n",
       " ('Liunda.', 'pl. Maunda.'),\n",
       " ('Liwiro.', 'speed.'),\n",
       " ('Liwombo.', 'the fontane.'),\n",
       " ('Lodza.', 'to bewitch.'),\n",
       " ('Lodzera.', 'to be drunk.'),\n",
       " ('Loko.', 'a lock.'),\n",
       " ('Lowa.', 'to enter.'),\n",
       " ('Lowana.', 'to live together.'),\n",
       " ('Lowe.', 'a wet place in the ground.'),\n",
       " ('Lowera.', 'cut in.'),\n",
       " ('Lowetsa.', 'to bring in.'),\n",
       " ('Loza.', 'to point towards.'),\n",
       " ('Makwerero.', 'a ladder.'),\n",
       " ('Makwinya.', 'wrinkles on eithr clothes.'),\n",
       " ('Mlalanje.', 'sing.'),\n",
       " ('Malasha.', 'charcoal.'),\n",
       " ('Malaulo.', 'evil tidings.'),\n",
       " ('Malaya.', 'shirt.'),\n",
       " ('Malemba.', 'what is written.'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodding Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kU5L1oaHIc5R"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(s):\n",
    "    s = unicode_to_ascii(s.lower())\n",
    "    s = re.sub(r'([!.?])', r' \\1', s)\n",
    "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
    "    s = re.sub(r'\\s+', r' ', s)\n",
    "\n",
    "    s = s.strip()\n",
    "    s = '<start>' +' '+ s +' '+' <end>'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data Required to Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ca73UuX8IdAR"
   },
   "outputs": [],
   "source": [
    "# Limiting the data and Splitting into seperate lists and add tokens\n",
    "\n",
    "data = data[:150]\n",
    "\n",
    "lang_eng = []\n",
    "lang_nya = []\n",
    "\n",
    "raw_data_eng, raw_data_nya = list(zip(*data))\n",
    "raw_data_eng, raw_data_nya = list(raw_data_eng), list(raw_data_nya)\n",
    "\n",
    "for i, j in zip(raw_data_eng, raw_data_nya):\n",
    "  preprocessed_data_eng = preprocess_sentence(i)\n",
    "  preprocessed_data_nya = preprocess_sentence(j)\n",
    "  lang_eng.append(preprocessed_data_eng)\n",
    "  lang_nya.append(preprocessed_data_nya)\n",
    "\n",
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer\n",
    "\n",
    "input_tensor, inp_lang = tokenize(lang_eng)\n",
    "target_tensor, targ_lang = tokenize(lang_nya)\n",
    "\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVfnBuJIIdC_",
    "outputId": "3e0d1cf1-fefe-4740-9fff-18422a4da1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 30 30\n",
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "12 ----> biliwila\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "4 ----> to\n",
      "6 ----> be\n",
      "41 ----> green\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
    "\n",
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "\n",
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Buffer and a Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEha39YYFXn4",
    "outputId": "98456fac-e1f8-4c1a-9c5e-bed0fb212f4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 19:01:26.909955: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-27 19:01:26.910056: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 5), dtype=tf.int32, name=None), TensorSpec(shape=(64, 12), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WB0m23oZSRxa"
   },
   "source": [
    "### Encoder Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KWHj4HbGIdFX"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, inp_vocab_size, embedding_size, lstm_size, input_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        \n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = tf.keras.layers.Embedding(inp_vocab_size, embedding_size)\n",
    "        self.lstm = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
    "\n",
    "    def call(self, input_sequence, states):\n",
    "      \n",
    "        embed = self.embedding(input_sequence)\n",
    "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
    "\n",
    "        return output, state_h, state_c\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "    \n",
    "        return (tf.zeros([batch_size, self.lstm_size]),\n",
    "                tf.zeros([batch_size, self.lstm_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjb3_4c6Sld4"
   },
   "source": [
    "### Dot Attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oCaMyZWKSe_I"
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,scoring_function, att_units):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.scoring_function = scoring_function\n",
    "        self.att_units = att_units\n",
    "\n",
    "        if self.scoring_function=='dot':\n",
    "            pass\n",
    "            # For general, it would be self.wa = tf.keras.layers.Dense(att_units)\n",
    "\n",
    "\n",
    "    def call(self,decoder_hidden_state,encoder_output):\n",
    "\n",
    "        if self.scoring_function == 'dot':\n",
    "            \n",
    "            new_state = tf.expand_dims(decoder_hidden_state, -1)\n",
    "            score = tf.matmul(encoder_output, new_state)\n",
    "            weights = tf.nn.softmax(score, axis=1)\n",
    "            context = weights * encoder_output\n",
    "            context_vector = tf.reduce_sum(context, axis=1)\n",
    "                                \n",
    "            return context_vector, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXFVBTXDS_-Y"
   },
   "source": [
    "### One Step Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "29ycCzwaS9ZZ"
   },
   "outputs": [],
   "source": [
    "class One_Step_Decoder(tf.keras.Model):\n",
    "    def __init__(self, tar_vocab_size, embedding_dim, input_length, dec_units, score_fun, att_units):\n",
    "        super(One_Step_Decoder, self).__init__()\n",
    "        # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "        self.tar_vocab_size = tar_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.dec_units = dec_units\n",
    "        self.score_fun = score_fun\n",
    "        self.att_units = att_units\n",
    "        self.embedding = tf.keras.layers.Embedding(self.tar_vocab_size, self.embedding_dim, \n",
    "                                                   input_length=self.input_length)\n",
    "        \n",
    "        self.lstm = tf.keras.layers.LSTM(self.dec_units, return_sequences=True, \n",
    "                                         return_state=True)\n",
    "        \n",
    "        self.output_layer = tf.keras.layers.Dense(self.tar_vocab_size)\n",
    "        \n",
    "        self.attention = Attention(self.score_fun, self.att_units)\n",
    "\n",
    "    def call(self, input_to_decoder, encoder_output, state_h, state_c):\n",
    "        \n",
    "        result = self.embedding(input_to_decoder)\n",
    "        \n",
    "        context_vector, weights = self.attention(state_h, encoder_output)\n",
    "        \n",
    "        concat = tf.concat([tf.expand_dims(context_vector, 1), result], axis=-1)\n",
    "        \n",
    "        decoder_output, hidden_state, cell_state = self.lstm(concat, initial_state=[state_h, state_c])\n",
    "        \n",
    "        final_output = tf.reshape(decoder_output, (-1, decoder_output.shape[2]))\n",
    "        final_output = self.output_layer(final_output)\n",
    "        \n",
    "        return final_output, hidden_state, cell_state, weights, context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LP7VnWvwTLpz"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GwF7tSNlTMy_"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, out_vocab_size, embedding_dim, output_length, dec_units ,score_fun ,att_units):\n",
    "        #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "        super(Decoder, self).__init__()\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_length = output_length\n",
    "        self.dec_units = dec_units\n",
    "        self.score_fun = score_fun\n",
    "        self.att_units = att_units\n",
    "        self.onestepdecoder = One_Step_Decoder(self.out_vocab_size, self.embedding_dim, self.output_length,\n",
    "                                               self.dec_units, self.score_fun, self.att_units)\n",
    "        \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state):\n",
    "        \n",
    "        all_outputs= tf.TensorArray(tf.float32, size=input_to_decoder.shape[1], name=\"output_arrays\")\n",
    "        \n",
    "        \n",
    "        for timestep in range(input_to_decoder.shape[1]):\n",
    "            output, decoder_hidden_state, decoder_cell_state, weights, context_vector = self.onestepdecoder(\n",
    "                                                                                    input_to_decoder[:,timestep:timestep+1], \n",
    "                                                                                    encoder_output, \n",
    "                                                                                    decoder_hidden_state,\n",
    "                                                                                    decoder_cell_state)\n",
    "            \n",
    "            all_outputs = all_outputs.write(timestep, output)\n",
    "        \n",
    "        all_outputs = tf.transpose(all_outputs.stack(), (1, 0, 2)) \n",
    "\n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OAoXiaITo07"
   },
   "source": [
    "### Call The Encoder Decoder Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Qkg5csDhTW8Z"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "    def __init__(self, inp_vocab_size, out_vocab_size, embedding_size, lstm_size, \n",
    "                 input_length, output_length, dec_units ,score_fun ,att_units, batch_size):\n",
    "        \n",
    "        super(encoder_decoder, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(inp_vocab_size, embedding_size, lstm_size, input_length)\n",
    "        self.decoder = Decoder(out_vocab_size, embedding_size, output_length, \n",
    "                               dec_units, score_fun, att_units)\n",
    "    \n",
    "    def call(self, data):\n",
    "        \n",
    "        input_sequence, input_to_decoder = data[0],data[1]\n",
    "        initial_state = self.encoder.initialize_states(batch_size=64)\n",
    "        encoder_output, state_h, state_c = self.encoder(input_sequence, initial_state)\n",
    "        decoder_hidden_state = state_h\n",
    "        decoder_cell_state = state_c\n",
    "        decoder_output = self.decoder(input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state)\n",
    "        \n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4r8gqMeaT4DY"
   },
   "source": [
    "### Custom Loss Function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "A_uEicf9T2O6"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2bqE3wVUtOZ"
   },
   "source": [
    "### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB5pZyEFUwjl",
    "outputId": "1e3ffb1a-4c17-4834-eb75-de568d5b005c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: logs: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir logs\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"dot.h5\", monitor='val_loss', verbose=1, save_weights_only=True)\n",
    "\n",
    "logdir='logs'\n",
    "tensorboard_Visualization = TensorBoard(log_dir=logdir)\n",
    "\n",
    "input_vocab_size = len(inp_lang.word_index)+1\n",
    "output_vocab_size = len(targ_lang.word_index)+1\n",
    "\n",
    "input_len = max_length_inp\n",
    "output_len = max_length_targ\n",
    "\n",
    "lstm_size = 128\n",
    "att_units = 256\n",
    "dec_units = 128\n",
    "embedding_size = 300\n",
    "embedding_dim = 300\n",
    "score_fun = 'dot'\n",
    "steps = len(input_tensor)//64\n",
    "batch_size=64\n",
    "\n",
    "model = encoder_decoder(input_vocab_size,output_vocab_size,embedding_size,lstm_size,input_len,output_len,dec_units,score_fun,att_units, batch_size)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=model.layers[0],\n",
    "                                 decoder=model.layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HySImJjAU8dh"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden,enc_state = model.layers[0](inp, enc_hidden)\n",
    "\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      predictions = model.layers[1](dec_input,enc_output,enc_hidden,enc_state)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = model.layers[0].trainable_variables + model.layers[1].trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NEYjgVJ-U_b4",
    "outputId": "575349d5-7583-4791-d471-a1f25ff55ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.2881\n",
      "Epoch 1 Loss 0.2881\n",
      "Time taken for 1 epoch 0.20052194595336914 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.2891\n",
      "Epoch 2 Loss 0.2891\n",
      "Time taken for 1 epoch 0.1633610725402832 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.2939\n",
      "Epoch 3 Loss 0.2939\n",
      "Time taken for 1 epoch 0.10665607452392578 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2868\n",
      "Epoch 4 Loss 0.2868\n",
      "Time taken for 1 epoch 0.15123605728149414 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.2783\n",
      "Epoch 5 Loss 0.2783\n",
      "Time taken for 1 epoch 0.08801102638244629 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.2872\n",
      "Epoch 6 Loss 0.2872\n",
      "Time taken for 1 epoch 0.16629600524902344 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.2770\n",
      "Epoch 7 Loss 0.2770\n",
      "Time taken for 1 epoch 0.14885687828063965 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.2816\n",
      "Epoch 8 Loss 0.2816\n",
      "Time taken for 1 epoch 0.3919680118560791 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.2847\n",
      "Epoch 9 Loss 0.2847\n",
      "Time taken for 1 epoch 0.11553215980529785 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2729\n",
      "Epoch 10 Loss 0.2729\n",
      "Time taken for 1 epoch 0.2240908145904541 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.2812\n",
      "Epoch 11 Loss 0.2812\n",
      "Time taken for 1 epoch 0.11200714111328125 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.2788\n",
      "Epoch 12 Loss 0.2788\n",
      "Time taken for 1 epoch 0.2327258586883545 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.2742\n",
      "Epoch 13 Loss 0.2742\n",
      "Time taken for 1 epoch 0.12712383270263672 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.2751\n",
      "Epoch 14 Loss 0.2751\n",
      "Time taken for 1 epoch 0.23403596878051758 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.2706\n",
      "Epoch 15 Loss 0.2706\n",
      "Time taken for 1 epoch 0.10050106048583984 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.2697\n",
      "Epoch 16 Loss 0.2697\n",
      "Time taken for 1 epoch 0.16238689422607422 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.2736\n",
      "Epoch 17 Loss 0.2736\n",
      "Time taken for 1 epoch 0.07214021682739258 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.2702\n",
      "Epoch 18 Loss 0.2702\n",
      "Time taken for 1 epoch 0.15366888046264648 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.2680\n",
      "Epoch 19 Loss 0.2680\n",
      "Time taken for 1 epoch 0.0709378719329834 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.2655\n",
      "Epoch 20 Loss 0.2655\n",
      "Time taken for 1 epoch 0.1534128189086914 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.2591\n",
      "Epoch 21 Loss 0.2591\n",
      "Time taken for 1 epoch 0.07908225059509277 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.2617\n",
      "Epoch 22 Loss 0.2617\n",
      "Time taken for 1 epoch 0.1555309295654297 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.2644\n",
      "Epoch 23 Loss 0.2644\n",
      "Time taken for 1 epoch 0.07220292091369629 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.2662\n",
      "Epoch 24 Loss 0.2662\n",
      "Time taken for 1 epoch 0.15208697319030762 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.2629\n",
      "Epoch 25 Loss 0.2629\n",
      "Time taken for 1 epoch 0.07784199714660645 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.2554\n",
      "Epoch 26 Loss 0.2554\n",
      "Time taken for 1 epoch 0.15824198722839355 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.2665\n",
      "Epoch 27 Loss 0.2665\n",
      "Time taken for 1 epoch 0.07539200782775879 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.2671\n",
      "Epoch 28 Loss 0.2671\n",
      "Time taken for 1 epoch 0.15831971168518066 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.2667\n",
      "Epoch 29 Loss 0.2667\n",
      "Time taken for 1 epoch 0.0845041275024414 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.2609\n",
      "Epoch 30 Loss 0.2609\n",
      "Time taken for 1 epoch 0.167313814163208 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.2535\n",
      "Epoch 31 Loss 0.2535\n",
      "Time taken for 1 epoch 0.07583498954772949 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.2553\n",
      "Epoch 32 Loss 0.2553\n",
      "Time taken for 1 epoch 0.1535320281982422 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.2575\n",
      "Epoch 33 Loss 0.2575\n",
      "Time taken for 1 epoch 0.07446599006652832 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.2522\n",
      "Epoch 34 Loss 0.2522\n",
      "Time taken for 1 epoch 0.16533374786376953 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.2591\n",
      "Epoch 35 Loss 0.2591\n",
      "Time taken for 1 epoch 0.07264494895935059 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.2525\n",
      "Epoch 36 Loss 0.2525\n",
      "Time taken for 1 epoch 0.14947104454040527 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.2531\n",
      "Epoch 37 Loss 0.2531\n",
      "Time taken for 1 epoch 0.0738983154296875 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.2465\n",
      "Epoch 38 Loss 0.2465\n",
      "Time taken for 1 epoch 0.15018510818481445 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.2525\n",
      "Epoch 39 Loss 0.2525\n",
      "Time taken for 1 epoch 0.07595181465148926 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.2534\n",
      "Epoch 40 Loss 0.2534\n",
      "Time taken for 1 epoch 0.1482529640197754 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.2469\n",
      "Epoch 41 Loss 0.2469\n",
      "Time taken for 1 epoch 0.07465314865112305 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.2482\n",
      "Epoch 42 Loss 0.2482\n",
      "Time taken for 1 epoch 0.16120386123657227 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.2487\n",
      "Epoch 43 Loss 0.2487\n",
      "Time taken for 1 epoch 0.07343697547912598 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.2466\n",
      "Epoch 44 Loss 0.2466\n",
      "Time taken for 1 epoch 0.15486717224121094 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.2484\n",
      "Epoch 45 Loss 0.2484\n",
      "Time taken for 1 epoch 0.07879018783569336 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.2479\n",
      "Epoch 46 Loss 0.2479\n",
      "Time taken for 1 epoch 0.15588974952697754 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.2454\n",
      "Epoch 47 Loss 0.2454\n",
      "Time taken for 1 epoch 0.07432293891906738 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.2388\n",
      "Epoch 48 Loss 0.2388\n",
      "Time taken for 1 epoch 0.15188813209533691 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.2427\n",
      "Epoch 49 Loss 0.2427\n",
      "Time taken for 1 epoch 0.07602715492248535 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.2433\n",
      "Epoch 50 Loss 0.2433\n",
      "Time taken for 1 epoch 0.15700006484985352 sec\n",
      "\n",
      "Epoch 51 Batch 0 Loss 0.2435\n",
      "Epoch 51 Loss 0.2435\n",
      "Time taken for 1 epoch 0.07414007186889648 sec\n",
      "\n",
      "Epoch 52 Batch 0 Loss 0.2493\n",
      "Epoch 52 Loss 0.2493\n",
      "Time taken for 1 epoch 0.16182398796081543 sec\n",
      "\n",
      "Epoch 53 Batch 0 Loss 0.2436\n",
      "Epoch 53 Loss 0.2436\n",
      "Time taken for 1 epoch 0.0747840404510498 sec\n",
      "\n",
      "Epoch 54 Batch 0 Loss 0.2440\n",
      "Epoch 54 Loss 0.2440\n",
      "Time taken for 1 epoch 0.15493178367614746 sec\n",
      "\n",
      "Epoch 55 Batch 0 Loss 0.2415\n",
      "Epoch 55 Loss 0.2415\n",
      "Time taken for 1 epoch 0.07385087013244629 sec\n",
      "\n",
      "Epoch 56 Batch 0 Loss 0.2352\n",
      "Epoch 56 Loss 0.2352\n",
      "Time taken for 1 epoch 0.16146397590637207 sec\n",
      "\n",
      "Epoch 57 Batch 0 Loss 0.2410\n",
      "Epoch 57 Loss 0.2410\n",
      "Time taken for 1 epoch 0.07848286628723145 sec\n",
      "\n",
      "Epoch 58 Batch 0 Loss 0.2414\n",
      "Epoch 58 Loss 0.2414\n",
      "Time taken for 1 epoch 0.15451431274414062 sec\n",
      "\n",
      "Epoch 59 Batch 0 Loss 0.2331\n",
      "Epoch 59 Loss 0.2331\n",
      "Time taken for 1 epoch 0.07552003860473633 sec\n",
      "\n",
      "Epoch 60 Batch 0 Loss 0.2337\n",
      "Epoch 60 Loss 0.2337\n",
      "Time taken for 1 epoch 0.15964412689208984 sec\n",
      "\n",
      "Epoch 61 Batch 0 Loss 0.2331\n",
      "Epoch 61 Loss 0.2331\n",
      "Time taken for 1 epoch 0.07596588134765625 sec\n",
      "\n",
      "Epoch 62 Batch 0 Loss 0.2314\n",
      "Epoch 62 Loss 0.2314\n",
      "Time taken for 1 epoch 0.16821503639221191 sec\n",
      "\n",
      "Epoch 63 Batch 0 Loss 0.2307\n",
      "Epoch 63 Loss 0.2307\n",
      "Time taken for 1 epoch 0.08905291557312012 sec\n",
      "\n",
      "Epoch 64 Batch 0 Loss 0.2323\n",
      "Epoch 64 Loss 0.2323\n",
      "Time taken for 1 epoch 0.23143672943115234 sec\n",
      "\n",
      "Epoch 65 Batch 0 Loss 0.2250\n",
      "Epoch 65 Loss 0.2250\n",
      "Time taken for 1 epoch 0.09430789947509766 sec\n",
      "\n",
      "Epoch 66 Batch 0 Loss 0.2385\n",
      "Epoch 66 Loss 0.2385\n",
      "Time taken for 1 epoch 0.17752504348754883 sec\n",
      "\n",
      "Epoch 67 Batch 0 Loss 0.2310\n",
      "Epoch 67 Loss 0.2310\n",
      "Time taken for 1 epoch 0.08146882057189941 sec\n",
      "\n",
      "Epoch 68 Batch 0 Loss 0.2228\n",
      "Epoch 68 Loss 0.2228\n",
      "Time taken for 1 epoch 0.15381407737731934 sec\n",
      "\n",
      "Epoch 69 Batch 0 Loss 0.2241\n",
      "Epoch 69 Loss 0.2241\n",
      "Time taken for 1 epoch 0.07189130783081055 sec\n",
      "\n",
      "Epoch 70 Batch 0 Loss 0.2222\n",
      "Epoch 70 Loss 0.2222\n",
      "Time taken for 1 epoch 0.14897894859313965 sec\n",
      "\n",
      "Epoch 71 Batch 0 Loss 0.2296\n",
      "Epoch 71 Loss 0.2296\n",
      "Time taken for 1 epoch 0.07122087478637695 sec\n",
      "\n",
      "Epoch 72 Batch 0 Loss 0.2266\n",
      "Epoch 72 Loss 0.2266\n",
      "Time taken for 1 epoch 0.14838600158691406 sec\n",
      "\n",
      "Epoch 73 Batch 0 Loss 0.2385\n",
      "Epoch 73 Loss 0.2385\n",
      "Time taken for 1 epoch 0.07539010047912598 sec\n",
      "\n",
      "Epoch 74 Batch 0 Loss 0.2248\n",
      "Epoch 74 Loss 0.2248\n",
      "Time taken for 1 epoch 0.14842438697814941 sec\n",
      "\n",
      "Epoch 75 Batch 0 Loss 0.2250\n",
      "Epoch 75 Loss 0.2250\n",
      "Time taken for 1 epoch 0.07496285438537598 sec\n",
      "\n",
      "Epoch 76 Batch 0 Loss 0.2292\n",
      "Epoch 76 Loss 0.2292\n",
      "Time taken for 1 epoch 0.14780712127685547 sec\n",
      "\n",
      "Epoch 77 Batch 0 Loss 0.2159\n",
      "Epoch 77 Loss 0.2159\n",
      "Time taken for 1 epoch 0.0734872817993164 sec\n",
      "\n",
      "Epoch 78 Batch 0 Loss 0.2278\n",
      "Epoch 78 Loss 0.2278\n",
      "Time taken for 1 epoch 0.14878606796264648 sec\n",
      "\n",
      "Epoch 79 Batch 0 Loss 0.2272\n",
      "Epoch 79 Loss 0.2272\n",
      "Time taken for 1 epoch 0.07578897476196289 sec\n",
      "\n",
      "Epoch 80 Batch 0 Loss 0.2220\n",
      "Epoch 80 Loss 0.2220\n",
      "Time taken for 1 epoch 0.14824414253234863 sec\n",
      "\n",
      "Epoch 81 Batch 0 Loss 0.2170\n",
      "Epoch 81 Loss 0.2170\n",
      "Time taken for 1 epoch 0.07236981391906738 sec\n",
      "\n",
      "Epoch 82 Batch 0 Loss 0.2203\n",
      "Epoch 82 Loss 0.2203\n",
      "Time taken for 1 epoch 0.1480119228363037 sec\n",
      "\n",
      "Epoch 83 Batch 0 Loss 0.2174\n",
      "Epoch 83 Loss 0.2174\n",
      "Time taken for 1 epoch 0.07268500328063965 sec\n",
      "\n",
      "Epoch 84 Batch 0 Loss 0.2134\n",
      "Epoch 84 Loss 0.2134\n",
      "Time taken for 1 epoch 0.1525859832763672 sec\n",
      "\n",
      "Epoch 85 Batch 0 Loss 0.2194\n",
      "Epoch 85 Loss 0.2194\n",
      "Time taken for 1 epoch 0.07466506958007812 sec\n",
      "\n",
      "Epoch 86 Batch 0 Loss 0.2140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Loss 0.2140\n",
      "Time taken for 1 epoch 0.15285468101501465 sec\n",
      "\n",
      "Epoch 87 Batch 0 Loss 0.2156\n",
      "Epoch 87 Loss 0.2156\n",
      "Time taken for 1 epoch 0.07833290100097656 sec\n",
      "\n",
      "Epoch 88 Batch 0 Loss 0.2087\n",
      "Epoch 88 Loss 0.2087\n",
      "Time taken for 1 epoch 0.15641188621520996 sec\n",
      "\n",
      "Epoch 89 Batch 0 Loss 0.2105\n",
      "Epoch 89 Loss 0.2105\n",
      "Time taken for 1 epoch 0.08012628555297852 sec\n",
      "\n",
      "Epoch 90 Batch 0 Loss 0.2081\n",
      "Epoch 90 Loss 0.2081\n",
      "Time taken for 1 epoch 0.16442394256591797 sec\n",
      "\n",
      "Epoch 91 Batch 0 Loss 0.2123\n",
      "Epoch 91 Loss 0.2123\n",
      "Time taken for 1 epoch 0.08856081962585449 sec\n",
      "\n",
      "Epoch 92 Batch 0 Loss 0.2115\n",
      "Epoch 92 Loss 0.2115\n",
      "Time taken for 1 epoch 0.25122618675231934 sec\n",
      "\n",
      "Epoch 93 Batch 0 Loss 0.2159\n",
      "Epoch 93 Loss 0.2159\n",
      "Time taken for 1 epoch 0.10761022567749023 sec\n",
      "\n",
      "Epoch 94 Batch 0 Loss 0.2061\n",
      "Epoch 94 Loss 0.2061\n",
      "Time taken for 1 epoch 0.6066148281097412 sec\n",
      "\n",
      "Epoch 95 Batch 0 Loss 0.2125\n",
      "Epoch 95 Loss 0.2125\n",
      "Time taken for 1 epoch 0.07062816619873047 sec\n",
      "\n",
      "Epoch 96 Batch 0 Loss 0.2003\n",
      "Epoch 96 Loss 0.2003\n",
      "Time taken for 1 epoch 0.14979887008666992 sec\n",
      "\n",
      "Epoch 97 Batch 0 Loss 0.2087\n",
      "Epoch 97 Loss 0.2087\n",
      "Time taken for 1 epoch 0.07433915138244629 sec\n",
      "\n",
      "Epoch 98 Batch 0 Loss 0.2075\n",
      "Epoch 98 Loss 0.2075\n",
      "Time taken for 1 epoch 0.1692509651184082 sec\n",
      "\n",
      "Epoch 99 Batch 0 Loss 0.2030\n",
      "Epoch 99 Loss 0.2030\n",
      "Time taken for 1 epoch 0.0791621208190918 sec\n",
      "\n",
      "Epoch 100 Batch 0 Loss 0.2116\n",
      "Epoch 100 Loss 0.2116\n",
      "Time taken for 1 epoch 0.15507912635803223 sec\n",
      "\n",
      "Epoch 101 Batch 0 Loss 0.2042\n",
      "Epoch 101 Loss 0.2042\n",
      "Time taken for 1 epoch 0.07722997665405273 sec\n",
      "\n",
      "Epoch 102 Batch 0 Loss 0.2031\n",
      "Epoch 102 Loss 0.2031\n",
      "Time taken for 1 epoch 0.15033793449401855 sec\n",
      "\n",
      "Epoch 103 Batch 0 Loss 0.1957\n",
      "Epoch 103 Loss 0.1957\n",
      "Time taken for 1 epoch 0.07329893112182617 sec\n",
      "\n",
      "Epoch 104 Batch 0 Loss 0.1938\n",
      "Epoch 104 Loss 0.1938\n",
      "Time taken for 1 epoch 0.14838504791259766 sec\n",
      "\n",
      "Epoch 105 Batch 0 Loss 0.2024\n",
      "Epoch 105 Loss 0.2024\n",
      "Time taken for 1 epoch 0.07417583465576172 sec\n",
      "\n",
      "Epoch 106 Batch 0 Loss 0.2034\n",
      "Epoch 106 Loss 0.2034\n",
      "Time taken for 1 epoch 0.15345311164855957 sec\n",
      "\n",
      "Epoch 107 Batch 0 Loss 0.1992\n",
      "Epoch 107 Loss 0.1992\n",
      "Time taken for 1 epoch 0.07053303718566895 sec\n",
      "\n",
      "Epoch 108 Batch 0 Loss 0.1973\n",
      "Epoch 108 Loss 0.1973\n",
      "Time taken for 1 epoch 0.15319013595581055 sec\n",
      "\n",
      "Epoch 109 Batch 0 Loss 0.2072\n",
      "Epoch 109 Loss 0.2072\n",
      "Time taken for 1 epoch 0.07263326644897461 sec\n",
      "\n",
      "Epoch 110 Batch 0 Loss 0.1991\n",
      "Epoch 110 Loss 0.1991\n",
      "Time taken for 1 epoch 0.15151715278625488 sec\n",
      "\n",
      "Epoch 111 Batch 0 Loss 0.2003\n",
      "Epoch 111 Loss 0.2003\n",
      "Time taken for 1 epoch 0.0740211009979248 sec\n",
      "\n",
      "Epoch 112 Batch 0 Loss 0.1953\n",
      "Epoch 112 Loss 0.1953\n",
      "Time taken for 1 epoch 0.15214085578918457 sec\n",
      "\n",
      "Epoch 113 Batch 0 Loss 0.1945\n",
      "Epoch 113 Loss 0.1945\n",
      "Time taken for 1 epoch 0.07121896743774414 sec\n",
      "\n",
      "Epoch 114 Batch 0 Loss 0.1933\n",
      "Epoch 114 Loss 0.1933\n",
      "Time taken for 1 epoch 0.1506669521331787 sec\n",
      "\n",
      "Epoch 115 Batch 0 Loss 0.1966\n",
      "Epoch 115 Loss 0.1966\n",
      "Time taken for 1 epoch 0.07294321060180664 sec\n",
      "\n",
      "Epoch 116 Batch 0 Loss 0.1931\n",
      "Epoch 116 Loss 0.1931\n",
      "Time taken for 1 epoch 0.15156817436218262 sec\n",
      "\n",
      "Epoch 117 Batch 0 Loss 0.1956\n",
      "Epoch 117 Loss 0.1956\n",
      "Time taken for 1 epoch 0.07364702224731445 sec\n",
      "\n",
      "Epoch 118 Batch 0 Loss 0.1985\n",
      "Epoch 118 Loss 0.1985\n",
      "Time taken for 1 epoch 0.15396380424499512 sec\n",
      "\n",
      "Epoch 119 Batch 0 Loss 0.1964\n",
      "Epoch 119 Loss 0.1964\n",
      "Time taken for 1 epoch 0.07274198532104492 sec\n",
      "\n",
      "Epoch 120 Batch 0 Loss 0.1973\n",
      "Epoch 120 Loss 0.1973\n",
      "Time taken for 1 epoch 0.1553819179534912 sec\n",
      "\n",
      "Epoch 121 Batch 0 Loss 0.1932\n",
      "Epoch 121 Loss 0.1932\n",
      "Time taken for 1 epoch 0.07930898666381836 sec\n",
      "\n",
      "Epoch 122 Batch 0 Loss 0.1826\n",
      "Epoch 122 Loss 0.1826\n",
      "Time taken for 1 epoch 0.1621708869934082 sec\n",
      "\n",
      "Epoch 123 Batch 0 Loss 0.1866\n",
      "Epoch 123 Loss 0.1866\n",
      "Time taken for 1 epoch 0.07366776466369629 sec\n",
      "\n",
      "Epoch 124 Batch 0 Loss 0.1918\n",
      "Epoch 124 Loss 0.1918\n",
      "Time taken for 1 epoch 0.15242385864257812 sec\n",
      "\n",
      "Epoch 125 Batch 0 Loss 0.1837\n",
      "Epoch 125 Loss 0.1837\n",
      "Time taken for 1 epoch 0.07287192344665527 sec\n",
      "\n",
      "Epoch 126 Batch 0 Loss 0.1911\n",
      "Epoch 126 Loss 0.1911\n",
      "Time taken for 1 epoch 0.15082716941833496 sec\n",
      "\n",
      "Epoch 127 Batch 0 Loss 0.1934\n",
      "Epoch 127 Loss 0.1934\n",
      "Time taken for 1 epoch 0.0716090202331543 sec\n",
      "\n",
      "Epoch 128 Batch 0 Loss 0.1828\n",
      "Epoch 128 Loss 0.1828\n",
      "Time taken for 1 epoch 0.1523880958557129 sec\n",
      "\n",
      "Epoch 129 Batch 0 Loss 0.1878\n",
      "Epoch 129 Loss 0.1878\n",
      "Time taken for 1 epoch 0.07338905334472656 sec\n",
      "\n",
      "Epoch 130 Batch 0 Loss 0.1840\n",
      "Epoch 130 Loss 0.1840\n",
      "Time taken for 1 epoch 0.14995718002319336 sec\n",
      "\n",
      "Epoch 131 Batch 0 Loss 0.1852\n",
      "Epoch 131 Loss 0.1852\n",
      "Time taken for 1 epoch 0.07270503044128418 sec\n",
      "\n",
      "Epoch 132 Batch 0 Loss 0.1862\n",
      "Epoch 132 Loss 0.1862\n",
      "Time taken for 1 epoch 0.15262389183044434 sec\n",
      "\n",
      "Epoch 133 Batch 0 Loss 0.1827\n",
      "Epoch 133 Loss 0.1827\n",
      "Time taken for 1 epoch 0.07255077362060547 sec\n",
      "\n",
      "Epoch 134 Batch 0 Loss 0.1742\n",
      "Epoch 134 Loss 0.1742\n",
      "Time taken for 1 epoch 0.14905762672424316 sec\n",
      "\n",
      "Epoch 135 Batch 0 Loss 0.1826\n",
      "Epoch 135 Loss 0.1826\n",
      "Time taken for 1 epoch 0.07719993591308594 sec\n",
      "\n",
      "Epoch 136 Batch 0 Loss 0.1782\n",
      "Epoch 136 Loss 0.1782\n",
      "Time taken for 1 epoch 0.14858603477478027 sec\n",
      "\n",
      "Epoch 137 Batch 0 Loss 0.1825\n",
      "Epoch 137 Loss 0.1825\n",
      "Time taken for 1 epoch 0.07241010665893555 sec\n",
      "\n",
      "Epoch 138 Batch 0 Loss 0.1796\n",
      "Epoch 138 Loss 0.1796\n",
      "Time taken for 1 epoch 0.1537611484527588 sec\n",
      "\n",
      "Epoch 139 Batch 0 Loss 0.1802\n",
      "Epoch 139 Loss 0.1802\n",
      "Time taken for 1 epoch 0.07312417030334473 sec\n",
      "\n",
      "Epoch 140 Batch 0 Loss 0.1772\n",
      "Epoch 140 Loss 0.1772\n",
      "Time taken for 1 epoch 0.15087199211120605 sec\n",
      "\n",
      "Epoch 141 Batch 0 Loss 0.1790\n",
      "Epoch 141 Loss 0.1790\n",
      "Time taken for 1 epoch 0.07202410697937012 sec\n",
      "\n",
      "Epoch 142 Batch 0 Loss 0.1808\n",
      "Epoch 142 Loss 0.1808\n",
      "Time taken for 1 epoch 0.1516709327697754 sec\n",
      "\n",
      "Epoch 143 Batch 0 Loss 0.1700\n",
      "Epoch 143 Loss 0.1700\n",
      "Time taken for 1 epoch 0.07326912879943848 sec\n",
      "\n",
      "Epoch 144 Batch 0 Loss 0.1785\n",
      "Epoch 144 Loss 0.1785\n",
      "Time taken for 1 epoch 0.14953017234802246 sec\n",
      "\n",
      "Epoch 145 Batch 0 Loss 0.1707\n",
      "Epoch 145 Loss 0.1707\n",
      "Time taken for 1 epoch 0.07216882705688477 sec\n",
      "\n",
      "Epoch 146 Batch 0 Loss 0.1758\n",
      "Epoch 146 Loss 0.1758\n",
      "Time taken for 1 epoch 0.15097999572753906 sec\n",
      "\n",
      "Epoch 147 Batch 0 Loss 0.1742\n",
      "Epoch 147 Loss 0.1742\n",
      "Time taken for 1 epoch 0.07151365280151367 sec\n",
      "\n",
      "Epoch 148 Batch 0 Loss 0.1697\n",
      "Epoch 148 Loss 0.1697\n",
      "Time taken for 1 epoch 0.15259385108947754 sec\n",
      "\n",
      "Epoch 149 Batch 0 Loss 0.1712\n",
      "Epoch 149 Loss 0.1712\n",
      "Time taken for 1 epoch 0.07241320610046387 sec\n",
      "\n",
      "Epoch 150 Batch 0 Loss 0.1732\n",
      "Epoch 150 Loss 0.1732\n",
      "Time taken for 1 epoch 0.1515800952911377 sec\n",
      "\n",
      "Epoch 151 Batch 0 Loss 0.1730\n",
      "Epoch 151 Loss 0.1730\n",
      "Time taken for 1 epoch 0.07540202140808105 sec\n",
      "\n",
      "Epoch 152 Batch 0 Loss 0.1703\n",
      "Epoch 152 Loss 0.1703\n",
      "Time taken for 1 epoch 0.15111279487609863 sec\n",
      "\n",
      "Epoch 153 Batch 0 Loss 0.1686\n",
      "Epoch 153 Loss 0.1686\n",
      "Time taken for 1 epoch 0.07237100601196289 sec\n",
      "\n",
      "Epoch 154 Batch 0 Loss 0.1716\n",
      "Epoch 154 Loss 0.1716\n",
      "Time taken for 1 epoch 0.14951014518737793 sec\n",
      "\n",
      "Epoch 155 Batch 0 Loss 0.1726\n",
      "Epoch 155 Loss 0.1726\n",
      "Time taken for 1 epoch 0.07250523567199707 sec\n",
      "\n",
      "Epoch 156 Batch 0 Loss 0.1686\n",
      "Epoch 156 Loss 0.1686\n",
      "Time taken for 1 epoch 0.14862513542175293 sec\n",
      "\n",
      "Epoch 157 Batch 0 Loss 0.1629\n",
      "Epoch 157 Loss 0.1629\n",
      "Time taken for 1 epoch 0.0719759464263916 sec\n",
      "\n",
      "Epoch 158 Batch 0 Loss 0.1614\n",
      "Epoch 158 Loss 0.1614\n",
      "Time taken for 1 epoch 0.15156197547912598 sec\n",
      "\n",
      "Epoch 159 Batch 0 Loss 0.1667\n",
      "Epoch 159 Loss 0.1667\n",
      "Time taken for 1 epoch 0.07310914993286133 sec\n",
      "\n",
      "Epoch 160 Batch 0 Loss 0.1645\n",
      "Epoch 160 Loss 0.1645\n",
      "Time taken for 1 epoch 0.1473710536956787 sec\n",
      "\n",
      "Epoch 161 Batch 0 Loss 0.1717\n",
      "Epoch 161 Loss 0.1717\n",
      "Time taken for 1 epoch 0.07332420349121094 sec\n",
      "\n",
      "Epoch 162 Batch 0 Loss 0.1548\n",
      "Epoch 162 Loss 0.1548\n",
      "Time taken for 1 epoch 0.15639090538024902 sec\n",
      "\n",
      "Epoch 163 Batch 0 Loss 0.1595\n",
      "Epoch 163 Loss 0.1595\n",
      "Time taken for 1 epoch 0.07166290283203125 sec\n",
      "\n",
      "Epoch 164 Batch 0 Loss 0.1602\n",
      "Epoch 164 Loss 0.1602\n",
      "Time taken for 1 epoch 0.1538069248199463 sec\n",
      "\n",
      "Epoch 165 Batch 0 Loss 0.1611\n",
      "Epoch 165 Loss 0.1611\n",
      "Time taken for 1 epoch 0.07503986358642578 sec\n",
      "\n",
      "Epoch 166 Batch 0 Loss 0.1519\n",
      "Epoch 166 Loss 0.1519\n",
      "Time taken for 1 epoch 0.14866995811462402 sec\n",
      "\n",
      "Epoch 167 Batch 0 Loss 0.1753\n",
      "Epoch 167 Loss 0.1753\n",
      "Time taken for 1 epoch 0.0703887939453125 sec\n",
      "\n",
      "Epoch 168 Batch 0 Loss 0.1571\n",
      "Epoch 168 Loss 0.1571\n",
      "Time taken for 1 epoch 0.14812207221984863 sec\n",
      "\n",
      "Epoch 169 Batch 0 Loss 0.1635\n",
      "Epoch 169 Loss 0.1635\n",
      "Time taken for 1 epoch 0.07573390007019043 sec\n",
      "\n",
      "Epoch 170 Batch 0 Loss 0.1609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170 Loss 0.1609\n",
      "Time taken for 1 epoch 0.14916586875915527 sec\n",
      "\n",
      "Epoch 171 Batch 0 Loss 0.1543\n",
      "Epoch 171 Loss 0.1543\n",
      "Time taken for 1 epoch 0.07287788391113281 sec\n",
      "\n",
      "Epoch 172 Batch 0 Loss 0.1640\n",
      "Epoch 172 Loss 0.1640\n",
      "Time taken for 1 epoch 0.1502211093902588 sec\n",
      "\n",
      "Epoch 173 Batch 0 Loss 0.1567\n",
      "Epoch 173 Loss 0.1567\n",
      "Time taken for 1 epoch 0.07272195816040039 sec\n",
      "\n",
      "Epoch 174 Batch 0 Loss 0.1614\n",
      "Epoch 174 Loss 0.1614\n",
      "Time taken for 1 epoch 0.15229320526123047 sec\n",
      "\n",
      "Epoch 175 Batch 0 Loss 0.1513\n",
      "Epoch 175 Loss 0.1513\n",
      "Time taken for 1 epoch 0.0713191032409668 sec\n",
      "\n",
      "Epoch 176 Batch 0 Loss 0.1568\n",
      "Epoch 176 Loss 0.1568\n",
      "Time taken for 1 epoch 0.15540409088134766 sec\n",
      "\n",
      "Epoch 177 Batch 0 Loss 0.1583\n",
      "Epoch 177 Loss 0.1583\n",
      "Time taken for 1 epoch 0.08236479759216309 sec\n",
      "\n",
      "Epoch 178 Batch 0 Loss 0.1589\n",
      "Epoch 178 Loss 0.1589\n",
      "Time taken for 1 epoch 0.15497398376464844 sec\n",
      "\n",
      "Epoch 179 Batch 0 Loss 0.1601\n",
      "Epoch 179 Loss 0.1601\n",
      "Time taken for 1 epoch 0.07504534721374512 sec\n",
      "\n",
      "Epoch 180 Batch 0 Loss 0.1505\n",
      "Epoch 180 Loss 0.1505\n",
      "Time taken for 1 epoch 0.15250110626220703 sec\n",
      "\n",
      "Epoch 181 Batch 0 Loss 0.1554\n",
      "Epoch 181 Loss 0.1554\n",
      "Time taken for 1 epoch 0.0809481143951416 sec\n",
      "\n",
      "Epoch 182 Batch 0 Loss 0.1516\n",
      "Epoch 182 Loss 0.1516\n",
      "Time taken for 1 epoch 0.1844182014465332 sec\n",
      "\n",
      "Epoch 183 Batch 0 Loss 0.1483\n",
      "Epoch 183 Loss 0.1483\n",
      "Time taken for 1 epoch 0.11577486991882324 sec\n",
      "\n",
      "Epoch 184 Batch 0 Loss 0.1527\n",
      "Epoch 184 Loss 0.1527\n",
      "Time taken for 1 epoch 0.26863789558410645 sec\n",
      "\n",
      "Epoch 185 Batch 0 Loss 0.1472\n",
      "Epoch 185 Loss 0.1472\n",
      "Time taken for 1 epoch 0.11228632926940918 sec\n",
      "\n",
      "Epoch 186 Batch 0 Loss 0.1523\n",
      "Epoch 186 Loss 0.1523\n",
      "Time taken for 1 epoch 0.20902204513549805 sec\n",
      "\n",
      "Epoch 187 Batch 0 Loss 0.1586\n",
      "Epoch 187 Loss 0.1586\n",
      "Time taken for 1 epoch 0.08164501190185547 sec\n",
      "\n",
      "Epoch 188 Batch 0 Loss 0.1507\n",
      "Epoch 188 Loss 0.1507\n",
      "Time taken for 1 epoch 0.16792774200439453 sec\n",
      "\n",
      "Epoch 189 Batch 0 Loss 0.1508\n",
      "Epoch 189 Loss 0.1508\n",
      "Time taken for 1 epoch 0.07578182220458984 sec\n",
      "\n",
      "Epoch 190 Batch 0 Loss 0.1532\n",
      "Epoch 190 Loss 0.1532\n",
      "Time taken for 1 epoch 0.15803170204162598 sec\n",
      "\n",
      "Epoch 191 Batch 0 Loss 0.1503\n",
      "Epoch 191 Loss 0.1503\n",
      "Time taken for 1 epoch 0.07561087608337402 sec\n",
      "\n",
      "Epoch 192 Batch 0 Loss 0.1523\n",
      "Epoch 192 Loss 0.1523\n",
      "Time taken for 1 epoch 0.1482560634613037 sec\n",
      "\n",
      "Epoch 193 Batch 0 Loss 0.1504\n",
      "Epoch 193 Loss 0.1504\n",
      "Time taken for 1 epoch 0.07171320915222168 sec\n",
      "\n",
      "Epoch 194 Batch 0 Loss 0.1430\n",
      "Epoch 194 Loss 0.1430\n",
      "Time taken for 1 epoch 0.1485137939453125 sec\n",
      "\n",
      "Epoch 195 Batch 0 Loss 0.1405\n",
      "Epoch 195 Loss 0.1405\n",
      "Time taken for 1 epoch 0.07389116287231445 sec\n",
      "\n",
      "Epoch 196 Batch 0 Loss 0.1447\n",
      "Epoch 196 Loss 0.1447\n",
      "Time taken for 1 epoch 0.15523982048034668 sec\n",
      "\n",
      "Epoch 197 Batch 0 Loss 0.1539\n",
      "Epoch 197 Loss 0.1539\n",
      "Time taken for 1 epoch 0.07128405570983887 sec\n",
      "\n",
      "Epoch 198 Batch 0 Loss 0.1416\n",
      "Epoch 198 Loss 0.1416\n",
      "Time taken for 1 epoch 0.15291333198547363 sec\n",
      "\n",
      "Epoch 199 Batch 0 Loss 0.1424\n",
      "Epoch 199 Loss 0.1424\n",
      "Time taken for 1 epoch 0.09969902038574219 sec\n",
      "\n",
      "Epoch 200 Batch 0 Loss 0.1473\n",
      "Epoch 200 Loss 0.1473\n",
      "Time taken for 1 epoch 0.1725301742553711 sec\n",
      "\n",
      "Epoch 201 Batch 0 Loss 0.1494\n",
      "Epoch 201 Loss 0.1494\n",
      "Time taken for 1 epoch 0.07407617568969727 sec\n",
      "\n",
      "Epoch 202 Batch 0 Loss 0.1400\n",
      "Epoch 202 Loss 0.1400\n",
      "Time taken for 1 epoch 0.15401506423950195 sec\n",
      "\n",
      "Epoch 203 Batch 0 Loss 0.1474\n",
      "Epoch 203 Loss 0.1474\n",
      "Time taken for 1 epoch 0.07945704460144043 sec\n",
      "\n",
      "Epoch 204 Batch 0 Loss 0.1430\n",
      "Epoch 204 Loss 0.1430\n",
      "Time taken for 1 epoch 0.15163183212280273 sec\n",
      "\n",
      "Epoch 205 Batch 0 Loss 0.1319\n",
      "Epoch 205 Loss 0.1319\n",
      "Time taken for 1 epoch 0.07390284538269043 sec\n",
      "\n",
      "Epoch 206 Batch 0 Loss 0.1331\n",
      "Epoch 206 Loss 0.1331\n",
      "Time taken for 1 epoch 0.15079689025878906 sec\n",
      "\n",
      "Epoch 207 Batch 0 Loss 0.1382\n",
      "Epoch 207 Loss 0.1382\n",
      "Time taken for 1 epoch 0.07216095924377441 sec\n",
      "\n",
      "Epoch 208 Batch 0 Loss 0.1361\n",
      "Epoch 208 Loss 0.1361\n",
      "Time taken for 1 epoch 0.15380024909973145 sec\n",
      "\n",
      "Epoch 209 Batch 0 Loss 0.1469\n",
      "Epoch 209 Loss 0.1469\n",
      "Time taken for 1 epoch 0.07444930076599121 sec\n",
      "\n",
      "Epoch 210 Batch 0 Loss 0.1393\n",
      "Epoch 210 Loss 0.1393\n",
      "Time taken for 1 epoch 0.15145587921142578 sec\n",
      "\n",
      "Epoch 211 Batch 0 Loss 0.1391\n",
      "Epoch 211 Loss 0.1391\n",
      "Time taken for 1 epoch 0.07380199432373047 sec\n",
      "\n",
      "Epoch 212 Batch 0 Loss 0.1343\n",
      "Epoch 212 Loss 0.1343\n",
      "Time taken for 1 epoch 0.15001606941223145 sec\n",
      "\n",
      "Epoch 213 Batch 0 Loss 0.1392\n",
      "Epoch 213 Loss 0.1392\n",
      "Time taken for 1 epoch 0.07207012176513672 sec\n",
      "\n",
      "Epoch 214 Batch 0 Loss 0.1343\n",
      "Epoch 214 Loss 0.1343\n",
      "Time taken for 1 epoch 0.15121197700500488 sec\n",
      "\n",
      "Epoch 215 Batch 0 Loss 0.1294\n",
      "Epoch 215 Loss 0.1294\n",
      "Time taken for 1 epoch 0.07068109512329102 sec\n",
      "\n",
      "Epoch 216 Batch 0 Loss 0.1369\n",
      "Epoch 216 Loss 0.1369\n",
      "Time taken for 1 epoch 0.1533510684967041 sec\n",
      "\n",
      "Epoch 217 Batch 0 Loss 0.1360\n",
      "Epoch 217 Loss 0.1360\n",
      "Time taken for 1 epoch 0.07155704498291016 sec\n",
      "\n",
      "Epoch 218 Batch 0 Loss 0.1294\n",
      "Epoch 218 Loss 0.1294\n",
      "Time taken for 1 epoch 0.14805912971496582 sec\n",
      "\n",
      "Epoch 219 Batch 0 Loss 0.1312\n",
      "Epoch 219 Loss 0.1312\n",
      "Time taken for 1 epoch 0.07271623611450195 sec\n",
      "\n",
      "Epoch 220 Batch 0 Loss 0.1358\n",
      "Epoch 220 Loss 0.1358\n",
      "Time taken for 1 epoch 0.1512758731842041 sec\n",
      "\n",
      "Epoch 221 Batch 0 Loss 0.1279\n",
      "Epoch 221 Loss 0.1279\n",
      "Time taken for 1 epoch 0.07154512405395508 sec\n",
      "\n",
      "Epoch 222 Batch 0 Loss 0.1313\n",
      "Epoch 222 Loss 0.1313\n",
      "Time taken for 1 epoch 0.15032601356506348 sec\n",
      "\n",
      "Epoch 223 Batch 0 Loss 0.1281\n",
      "Epoch 223 Loss 0.1281\n",
      "Time taken for 1 epoch 0.07408618927001953 sec\n",
      "\n",
      "Epoch 224 Batch 0 Loss 0.1290\n",
      "Epoch 224 Loss 0.1290\n",
      "Time taken for 1 epoch 0.14928412437438965 sec\n",
      "\n",
      "Epoch 225 Batch 0 Loss 0.1313\n",
      "Epoch 225 Loss 0.1313\n",
      "Time taken for 1 epoch 0.0719761848449707 sec\n",
      "\n",
      "Epoch 226 Batch 0 Loss 0.1220\n",
      "Epoch 226 Loss 0.1220\n",
      "Time taken for 1 epoch 0.16074895858764648 sec\n",
      "\n",
      "Epoch 227 Batch 0 Loss 0.1249\n",
      "Epoch 227 Loss 0.1249\n",
      "Time taken for 1 epoch 0.07253909111022949 sec\n",
      "\n",
      "Epoch 228 Batch 0 Loss 0.1312\n",
      "Epoch 228 Loss 0.1312\n",
      "Time taken for 1 epoch 0.14810538291931152 sec\n",
      "\n",
      "Epoch 229 Batch 0 Loss 0.1281\n",
      "Epoch 229 Loss 0.1281\n",
      "Time taken for 1 epoch 0.0732731819152832 sec\n",
      "\n",
      "Epoch 230 Batch 0 Loss 0.1213\n",
      "Epoch 230 Loss 0.1213\n",
      "Time taken for 1 epoch 0.15023493766784668 sec\n",
      "\n",
      "Epoch 231 Batch 0 Loss 0.1252\n",
      "Epoch 231 Loss 0.1252\n",
      "Time taken for 1 epoch 0.07180309295654297 sec\n",
      "\n",
      "Epoch 232 Batch 0 Loss 0.1275\n",
      "Epoch 232 Loss 0.1275\n",
      "Time taken for 1 epoch 0.14854073524475098 sec\n",
      "\n",
      "Epoch 233 Batch 0 Loss 0.1155\n",
      "Epoch 233 Loss 0.1155\n",
      "Time taken for 1 epoch 0.07262706756591797 sec\n",
      "\n",
      "Epoch 234 Batch 0 Loss 0.1233\n",
      "Epoch 234 Loss 0.1233\n",
      "Time taken for 1 epoch 0.14986324310302734 sec\n",
      "\n",
      "Epoch 235 Batch 0 Loss 0.1258\n",
      "Epoch 235 Loss 0.1258\n",
      "Time taken for 1 epoch 0.07349801063537598 sec\n",
      "\n",
      "Epoch 236 Batch 0 Loss 0.1153\n",
      "Epoch 236 Loss 0.1153\n",
      "Time taken for 1 epoch 0.14688706398010254 sec\n",
      "\n",
      "Epoch 237 Batch 0 Loss 0.1221\n",
      "Epoch 237 Loss 0.1221\n",
      "Time taken for 1 epoch 0.07263898849487305 sec\n",
      "\n",
      "Epoch 238 Batch 0 Loss 0.1242\n",
      "Epoch 238 Loss 0.1242\n",
      "Time taken for 1 epoch 0.14956378936767578 sec\n",
      "\n",
      "Epoch 239 Batch 0 Loss 0.1181\n",
      "Epoch 239 Loss 0.1181\n",
      "Time taken for 1 epoch 0.0736229419708252 sec\n",
      "\n",
      "Epoch 240 Batch 0 Loss 0.1155\n",
      "Epoch 240 Loss 0.1155\n",
      "Time taken for 1 epoch 0.1483898162841797 sec\n",
      "\n",
      "Epoch 241 Batch 0 Loss 0.1206\n",
      "Epoch 241 Loss 0.1206\n",
      "Time taken for 1 epoch 0.0711066722869873 sec\n",
      "\n",
      "Epoch 242 Batch 0 Loss 0.1181\n",
      "Epoch 242 Loss 0.1181\n",
      "Time taken for 1 epoch 0.14999079704284668 sec\n",
      "\n",
      "Epoch 243 Batch 0 Loss 0.1330\n",
      "Epoch 243 Loss 0.1330\n",
      "Time taken for 1 epoch 0.07131290435791016 sec\n",
      "\n",
      "Epoch 244 Batch 0 Loss 0.1207\n",
      "Epoch 244 Loss 0.1207\n",
      "Time taken for 1 epoch 0.15118408203125 sec\n",
      "\n",
      "Epoch 245 Batch 0 Loss 0.1180\n",
      "Epoch 245 Loss 0.1180\n",
      "Time taken for 1 epoch 0.07294392585754395 sec\n",
      "\n",
      "Epoch 246 Batch 0 Loss 0.1175\n",
      "Epoch 246 Loss 0.1175\n",
      "Time taken for 1 epoch 0.15162897109985352 sec\n",
      "\n",
      "Epoch 247 Batch 0 Loss 0.1105\n",
      "Epoch 247 Loss 0.1105\n",
      "Time taken for 1 epoch 0.07221674919128418 sec\n",
      "\n",
      "Epoch 248 Batch 0 Loss 0.1180\n",
      "Epoch 248 Loss 0.1180\n",
      "Time taken for 1 epoch 0.1505279541015625 sec\n",
      "\n",
      "Epoch 249 Batch 0 Loss 0.1106\n",
      "Epoch 249 Loss 0.1106\n",
      "Time taken for 1 epoch 0.07199716567993164 sec\n",
      "\n",
      "Epoch 250 Batch 0 Loss 0.1131\n",
      "Epoch 250 Loss 0.1131\n",
      "Time taken for 1 epoch 0.15052103996276855 sec\n",
      "\n",
      "Epoch 251 Batch 0 Loss 0.1164\n",
      "Epoch 251 Loss 0.1164\n",
      "Time taken for 1 epoch 0.07297778129577637 sec\n",
      "\n",
      "Epoch 252 Batch 0 Loss 0.1170\n",
      "Epoch 252 Loss 0.1170\n",
      "Time taken for 1 epoch 0.15290498733520508 sec\n",
      "\n",
      "Epoch 253 Batch 0 Loss 0.1187\n",
      "Epoch 253 Loss 0.1187\n",
      "Time taken for 1 epoch 0.07154202461242676 sec\n",
      "\n",
      "Epoch 254 Batch 0 Loss 0.1107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254 Loss 0.1107\n",
      "Time taken for 1 epoch 0.14899396896362305 sec\n",
      "\n",
      "Epoch 255 Batch 0 Loss 0.1088\n",
      "Epoch 255 Loss 0.1088\n",
      "Time taken for 1 epoch 0.07377099990844727 sec\n",
      "\n",
      "Epoch 256 Batch 0 Loss 0.1080\n",
      "Epoch 256 Loss 0.1080\n",
      "Time taken for 1 epoch 0.15171575546264648 sec\n",
      "\n",
      "Epoch 257 Batch 0 Loss 0.1069\n",
      "Epoch 257 Loss 0.1069\n",
      "Time taken for 1 epoch 0.0728607177734375 sec\n",
      "\n",
      "Epoch 258 Batch 0 Loss 0.1128\n",
      "Epoch 258 Loss 0.1128\n",
      "Time taken for 1 epoch 0.15148305892944336 sec\n",
      "\n",
      "Epoch 259 Batch 0 Loss 0.1114\n",
      "Epoch 259 Loss 0.1114\n",
      "Time taken for 1 epoch 0.07353615760803223 sec\n",
      "\n",
      "Epoch 260 Batch 0 Loss 0.1119\n",
      "Epoch 260 Loss 0.1119\n",
      "Time taken for 1 epoch 0.14883995056152344 sec\n",
      "\n",
      "Epoch 261 Batch 0 Loss 0.1092\n",
      "Epoch 261 Loss 0.1092\n",
      "Time taken for 1 epoch 0.07154273986816406 sec\n",
      "\n",
      "Epoch 262 Batch 0 Loss 0.1092\n",
      "Epoch 262 Loss 0.1092\n",
      "Time taken for 1 epoch 0.14907193183898926 sec\n",
      "\n",
      "Epoch 263 Batch 0 Loss 0.1068\n",
      "Epoch 263 Loss 0.1068\n",
      "Time taken for 1 epoch 0.07131719589233398 sec\n",
      "\n",
      "Epoch 264 Batch 0 Loss 0.1116\n",
      "Epoch 264 Loss 0.1116\n",
      "Time taken for 1 epoch 0.14933204650878906 sec\n",
      "\n",
      "Epoch 265 Batch 0 Loss 0.1046\n",
      "Epoch 265 Loss 0.1046\n",
      "Time taken for 1 epoch 0.07262063026428223 sec\n",
      "\n",
      "Epoch 266 Batch 0 Loss 0.1096\n",
      "Epoch 266 Loss 0.1096\n",
      "Time taken for 1 epoch 0.1489100456237793 sec\n",
      "\n",
      "Epoch 267 Batch 0 Loss 0.1059\n",
      "Epoch 267 Loss 0.1059\n",
      "Time taken for 1 epoch 0.07169795036315918 sec\n",
      "\n",
      "Epoch 268 Batch 0 Loss 0.1064\n",
      "Epoch 268 Loss 0.1064\n",
      "Time taken for 1 epoch 0.1552562713623047 sec\n",
      "\n",
      "Epoch 269 Batch 0 Loss 0.1090\n",
      "Epoch 269 Loss 0.1090\n",
      "Time taken for 1 epoch 0.07781505584716797 sec\n",
      "\n",
      "Epoch 270 Batch 0 Loss 0.1064\n",
      "Epoch 270 Loss 0.1064\n",
      "Time taken for 1 epoch 0.1564631462097168 sec\n",
      "\n",
      "Epoch 271 Batch 0 Loss 0.1019\n",
      "Epoch 271 Loss 0.1019\n",
      "Time taken for 1 epoch 0.0748443603515625 sec\n",
      "\n",
      "Epoch 272 Batch 0 Loss 0.1022\n",
      "Epoch 272 Loss 0.1022\n",
      "Time taken for 1 epoch 0.16283512115478516 sec\n",
      "\n",
      "Epoch 273 Batch 0 Loss 0.0985\n",
      "Epoch 273 Loss 0.0985\n",
      "Time taken for 1 epoch 0.08186888694763184 sec\n",
      "\n",
      "Epoch 274 Batch 0 Loss 0.1092\n",
      "Epoch 274 Loss 0.1092\n",
      "Time taken for 1 epoch 0.2413020133972168 sec\n",
      "\n",
      "Epoch 275 Batch 0 Loss 0.1033\n",
      "Epoch 275 Loss 0.1033\n",
      "Time taken for 1 epoch 0.12182307243347168 sec\n",
      "\n",
      "Epoch 276 Batch 0 Loss 0.1040\n",
      "Epoch 276 Loss 0.1040\n",
      "Time taken for 1 epoch 0.2338869571685791 sec\n",
      "\n",
      "Epoch 277 Batch 0 Loss 0.1018\n",
      "Epoch 277 Loss 0.1018\n",
      "Time taken for 1 epoch 0.11227107048034668 sec\n",
      "\n",
      "Epoch 278 Batch 0 Loss 0.1053\n",
      "Epoch 278 Loss 0.1053\n",
      "Time taken for 1 epoch 0.22974729537963867 sec\n",
      "\n",
      "Epoch 279 Batch 0 Loss 0.1042\n",
      "Epoch 279 Loss 0.1042\n",
      "Time taken for 1 epoch 0.08415102958679199 sec\n",
      "\n",
      "Epoch 280 Batch 0 Loss 0.0965\n",
      "Epoch 280 Loss 0.0965\n",
      "Time taken for 1 epoch 0.1838080883026123 sec\n",
      "\n",
      "Epoch 281 Batch 0 Loss 0.1072\n",
      "Epoch 281 Loss 0.1072\n",
      "Time taken for 1 epoch 0.08643198013305664 sec\n",
      "\n",
      "Epoch 282 Batch 0 Loss 0.1043\n",
      "Epoch 282 Loss 0.1043\n",
      "Time taken for 1 epoch 0.18658208847045898 sec\n",
      "\n",
      "Epoch 283 Batch 0 Loss 0.0916\n",
      "Epoch 283 Loss 0.0916\n",
      "Time taken for 1 epoch 0.08344793319702148 sec\n",
      "\n",
      "Epoch 284 Batch 0 Loss 0.1007\n",
      "Epoch 284 Loss 0.1007\n",
      "Time taken for 1 epoch 0.16062402725219727 sec\n",
      "\n",
      "Epoch 285 Batch 0 Loss 0.0939\n",
      "Epoch 285 Loss 0.0939\n",
      "Time taken for 1 epoch 0.07453227043151855 sec\n",
      "\n",
      "Epoch 286 Batch 0 Loss 0.1050\n",
      "Epoch 286 Loss 0.1050\n",
      "Time taken for 1 epoch 0.1520991325378418 sec\n",
      "\n",
      "Epoch 287 Batch 0 Loss 0.0988\n",
      "Epoch 287 Loss 0.0988\n",
      "Time taken for 1 epoch 0.07201600074768066 sec\n",
      "\n",
      "Epoch 288 Batch 0 Loss 0.0996\n",
      "Epoch 288 Loss 0.0996\n",
      "Time taken for 1 epoch 0.15174198150634766 sec\n",
      "\n",
      "Epoch 289 Batch 0 Loss 0.0927\n",
      "Epoch 289 Loss 0.0927\n",
      "Time taken for 1 epoch 0.0733180046081543 sec\n",
      "\n",
      "Epoch 290 Batch 0 Loss 0.0957\n",
      "Epoch 290 Loss 0.0957\n",
      "Time taken for 1 epoch 0.14904212951660156 sec\n",
      "\n",
      "Epoch 291 Batch 0 Loss 0.0964\n",
      "Epoch 291 Loss 0.0964\n",
      "Time taken for 1 epoch 0.07010722160339355 sec\n",
      "\n",
      "Epoch 292 Batch 0 Loss 0.0920\n",
      "Epoch 292 Loss 0.0920\n",
      "Time taken for 1 epoch 0.1445612907409668 sec\n",
      "\n",
      "Epoch 293 Batch 0 Loss 0.0970\n",
      "Epoch 293 Loss 0.0970\n",
      "Time taken for 1 epoch 0.07390904426574707 sec\n",
      "\n",
      "Epoch 294 Batch 0 Loss 0.0930\n",
      "Epoch 294 Loss 0.0930\n",
      "Time taken for 1 epoch 0.15372538566589355 sec\n",
      "\n",
      "Epoch 295 Batch 0 Loss 0.0898\n",
      "Epoch 295 Loss 0.0898\n",
      "Time taken for 1 epoch 0.07065391540527344 sec\n",
      "\n",
      "Epoch 296 Batch 0 Loss 0.0888\n",
      "Epoch 296 Loss 0.0888\n",
      "Time taken for 1 epoch 0.15282011032104492 sec\n",
      "\n",
      "Epoch 297 Batch 0 Loss 0.0915\n",
      "Epoch 297 Loss 0.0915\n",
      "Time taken for 1 epoch 0.07117104530334473 sec\n",
      "\n",
      "Epoch 298 Batch 0 Loss 0.0900\n",
      "Epoch 298 Loss 0.0900\n",
      "Time taken for 1 epoch 0.1510181427001953 sec\n",
      "\n",
      "Epoch 299 Batch 0 Loss 0.0977\n",
      "Epoch 299 Loss 0.0977\n",
      "Time taken for 1 epoch 0.0734870433807373 sec\n",
      "\n",
      "Epoch 300 Batch 0 Loss 0.0908\n",
      "Epoch 300 Loss 0.0908\n",
      "Time taken for 1 epoch 0.15143895149230957 sec\n",
      "\n",
      "Epoch 301 Batch 0 Loss 0.0934\n",
      "Epoch 301 Loss 0.0934\n",
      "Time taken for 1 epoch 0.07224798202514648 sec\n",
      "\n",
      "Epoch 302 Batch 0 Loss 0.0895\n",
      "Epoch 302 Loss 0.0895\n",
      "Time taken for 1 epoch 0.1519172191619873 sec\n",
      "\n",
      "Epoch 303 Batch 0 Loss 0.0963\n",
      "Epoch 303 Loss 0.0963\n",
      "Time taken for 1 epoch 0.07377481460571289 sec\n",
      "\n",
      "Epoch 304 Batch 0 Loss 0.0972\n",
      "Epoch 304 Loss 0.0972\n",
      "Time taken for 1 epoch 0.149796724319458 sec\n",
      "\n",
      "Epoch 305 Batch 0 Loss 0.0887\n",
      "Epoch 305 Loss 0.0887\n",
      "Time taken for 1 epoch 0.07183694839477539 sec\n",
      "\n",
      "Epoch 306 Batch 0 Loss 0.0851\n",
      "Epoch 306 Loss 0.0851\n",
      "Time taken for 1 epoch 0.14780735969543457 sec\n",
      "\n",
      "Epoch 307 Batch 0 Loss 0.0866\n",
      "Epoch 307 Loss 0.0866\n",
      "Time taken for 1 epoch 0.07055091857910156 sec\n",
      "\n",
      "Epoch 308 Batch 0 Loss 0.0846\n",
      "Epoch 308 Loss 0.0846\n",
      "Time taken for 1 epoch 0.1503148078918457 sec\n",
      "\n",
      "Epoch 309 Batch 0 Loss 0.0876\n",
      "Epoch 309 Loss 0.0876\n",
      "Time taken for 1 epoch 0.07084918022155762 sec\n",
      "\n",
      "Epoch 310 Batch 0 Loss 0.0904\n",
      "Epoch 310 Loss 0.0904\n",
      "Time taken for 1 epoch 0.15085911750793457 sec\n",
      "\n",
      "Epoch 311 Batch 0 Loss 0.0896\n",
      "Epoch 311 Loss 0.0896\n",
      "Time taken for 1 epoch 0.07273411750793457 sec\n",
      "\n",
      "Epoch 312 Batch 0 Loss 0.0886\n",
      "Epoch 312 Loss 0.0886\n",
      "Time taken for 1 epoch 0.15313315391540527 sec\n",
      "\n",
      "Epoch 313 Batch 0 Loss 0.0834\n",
      "Epoch 313 Loss 0.0834\n",
      "Time taken for 1 epoch 0.07083487510681152 sec\n",
      "\n",
      "Epoch 314 Batch 0 Loss 0.0943\n",
      "Epoch 314 Loss 0.0943\n",
      "Time taken for 1 epoch 0.1530160903930664 sec\n",
      "\n",
      "Epoch 315 Batch 0 Loss 0.0888\n",
      "Epoch 315 Loss 0.0888\n",
      "Time taken for 1 epoch 0.07140970230102539 sec\n",
      "\n",
      "Epoch 316 Batch 0 Loss 0.0807\n",
      "Epoch 316 Loss 0.0807\n",
      "Time taken for 1 epoch 0.14885401725769043 sec\n",
      "\n",
      "Epoch 317 Batch 0 Loss 0.0833\n",
      "Epoch 317 Loss 0.0833\n",
      "Time taken for 1 epoch 0.07196903228759766 sec\n",
      "\n",
      "Epoch 318 Batch 0 Loss 0.0852\n",
      "Epoch 318 Loss 0.0852\n",
      "Time taken for 1 epoch 0.14792323112487793 sec\n",
      "\n",
      "Epoch 319 Batch 0 Loss 0.0842\n",
      "Epoch 319 Loss 0.0842\n",
      "Time taken for 1 epoch 0.0711979866027832 sec\n",
      "\n",
      "Epoch 320 Batch 0 Loss 0.0847\n",
      "Epoch 320 Loss 0.0847\n",
      "Time taken for 1 epoch 0.1486191749572754 sec\n",
      "\n",
      "Epoch 321 Batch 0 Loss 0.0802\n",
      "Epoch 321 Loss 0.0802\n",
      "Time taken for 1 epoch 0.07386207580566406 sec\n",
      "\n",
      "Epoch 322 Batch 0 Loss 0.0858\n",
      "Epoch 322 Loss 0.0858\n",
      "Time taken for 1 epoch 0.147064208984375 sec\n",
      "\n",
      "Epoch 323 Batch 0 Loss 0.0828\n",
      "Epoch 323 Loss 0.0828\n",
      "Time taken for 1 epoch 0.07119917869567871 sec\n",
      "\n",
      "Epoch 324 Batch 0 Loss 0.0861\n",
      "Epoch 324 Loss 0.0861\n",
      "Time taken for 1 epoch 0.1499021053314209 sec\n",
      "\n",
      "Epoch 325 Batch 0 Loss 0.0817\n",
      "Epoch 325 Loss 0.0817\n",
      "Time taken for 1 epoch 0.07172703742980957 sec\n",
      "\n",
      "Epoch 326 Batch 0 Loss 0.0832\n",
      "Epoch 326 Loss 0.0832\n",
      "Time taken for 1 epoch 0.15409517288208008 sec\n",
      "\n",
      "Epoch 327 Batch 0 Loss 0.0751\n",
      "Epoch 327 Loss 0.0751\n",
      "Time taken for 1 epoch 0.07182431221008301 sec\n",
      "\n",
      "Epoch 328 Batch 0 Loss 0.0784\n",
      "Epoch 328 Loss 0.0784\n",
      "Time taken for 1 epoch 0.14922213554382324 sec\n",
      "\n",
      "Epoch 329 Batch 0 Loss 0.0774\n",
      "Epoch 329 Loss 0.0774\n",
      "Time taken for 1 epoch 0.07265114784240723 sec\n",
      "\n",
      "Epoch 330 Batch 0 Loss 0.0792\n",
      "Epoch 330 Loss 0.0792\n",
      "Time taken for 1 epoch 0.1526501178741455 sec\n",
      "\n",
      "Epoch 331 Batch 0 Loss 0.0751\n",
      "Epoch 331 Loss 0.0751\n",
      "Time taken for 1 epoch 0.0700979232788086 sec\n",
      "\n",
      "Epoch 332 Batch 0 Loss 0.0797\n",
      "Epoch 332 Loss 0.0797\n",
      "Time taken for 1 epoch 0.14994573593139648 sec\n",
      "\n",
      "Epoch 333 Batch 0 Loss 0.0823\n",
      "Epoch 333 Loss 0.0823\n",
      "Time taken for 1 epoch 0.07277393341064453 sec\n",
      "\n",
      "Epoch 334 Batch 0 Loss 0.0758\n",
      "Epoch 334 Loss 0.0758\n",
      "Time taken for 1 epoch 0.1518568992614746 sec\n",
      "\n",
      "Epoch 335 Batch 0 Loss 0.0749\n",
      "Epoch 335 Loss 0.0749\n",
      "Time taken for 1 epoch 0.07095217704772949 sec\n",
      "\n",
      "Epoch 336 Batch 0 Loss 0.0771\n",
      "Epoch 336 Loss 0.0771\n",
      "Time taken for 1 epoch 0.14992523193359375 sec\n",
      "\n",
      "Epoch 337 Batch 0 Loss 0.0778\n",
      "Epoch 337 Loss 0.0778\n",
      "Time taken for 1 epoch 0.07479715347290039 sec\n",
      "\n",
      "Epoch 338 Batch 0 Loss 0.0784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338 Loss 0.0784\n",
      "Time taken for 1 epoch 0.15041494369506836 sec\n",
      "\n",
      "Epoch 339 Batch 0 Loss 0.0711\n",
      "Epoch 339 Loss 0.0711\n",
      "Time taken for 1 epoch 0.07291793823242188 sec\n",
      "\n",
      "Epoch 340 Batch 0 Loss 0.0700\n",
      "Epoch 340 Loss 0.0700\n",
      "Time taken for 1 epoch 0.14847278594970703 sec\n",
      "\n",
      "Epoch 341 Batch 0 Loss 0.0796\n",
      "Epoch 341 Loss 0.0796\n",
      "Time taken for 1 epoch 0.0709681510925293 sec\n",
      "\n",
      "Epoch 342 Batch 0 Loss 0.0834\n",
      "Epoch 342 Loss 0.0834\n",
      "Time taken for 1 epoch 0.15108895301818848 sec\n",
      "\n",
      "Epoch 343 Batch 0 Loss 0.0752\n",
      "Epoch 343 Loss 0.0752\n",
      "Time taken for 1 epoch 0.07147598266601562 sec\n",
      "\n",
      "Epoch 344 Batch 0 Loss 0.0738\n",
      "Epoch 344 Loss 0.0738\n",
      "Time taken for 1 epoch 0.15106797218322754 sec\n",
      "\n",
      "Epoch 345 Batch 0 Loss 0.0722\n",
      "Epoch 345 Loss 0.0722\n",
      "Time taken for 1 epoch 0.07056713104248047 sec\n",
      "\n",
      "Epoch 346 Batch 0 Loss 0.0752\n",
      "Epoch 346 Loss 0.0752\n",
      "Time taken for 1 epoch 0.1516869068145752 sec\n",
      "\n",
      "Epoch 347 Batch 0 Loss 0.0748\n",
      "Epoch 347 Loss 0.0748\n",
      "Time taken for 1 epoch 0.07290196418762207 sec\n",
      "\n",
      "Epoch 348 Batch 0 Loss 0.0697\n",
      "Epoch 348 Loss 0.0697\n",
      "Time taken for 1 epoch 0.14997220039367676 sec\n",
      "\n",
      "Epoch 349 Batch 0 Loss 0.0735\n",
      "Epoch 349 Loss 0.0735\n",
      "Time taken for 1 epoch 0.07089710235595703 sec\n",
      "\n",
      "Epoch 350 Batch 0 Loss 0.0667\n",
      "Epoch 350 Loss 0.0667\n",
      "Time taken for 1 epoch 0.15322399139404297 sec\n",
      "\n",
      "Epoch 351 Batch 0 Loss 0.0729\n",
      "Epoch 351 Loss 0.0729\n",
      "Time taken for 1 epoch 0.07042694091796875 sec\n",
      "\n",
      "Epoch 352 Batch 0 Loss 0.0727\n",
      "Epoch 352 Loss 0.0727\n",
      "Time taken for 1 epoch 0.1536698341369629 sec\n",
      "\n",
      "Epoch 353 Batch 0 Loss 0.0745\n",
      "Epoch 353 Loss 0.0745\n",
      "Time taken for 1 epoch 0.07048511505126953 sec\n",
      "\n",
      "Epoch 354 Batch 0 Loss 0.0667\n",
      "Epoch 354 Loss 0.0667\n",
      "Time taken for 1 epoch 0.14647412300109863 sec\n",
      "\n",
      "Epoch 355 Batch 0 Loss 0.0739\n",
      "Epoch 355 Loss 0.0739\n",
      "Time taken for 1 epoch 0.06995201110839844 sec\n",
      "\n",
      "Epoch 356 Batch 0 Loss 0.0672\n",
      "Epoch 356 Loss 0.0672\n",
      "Time taken for 1 epoch 0.15308713912963867 sec\n",
      "\n",
      "Epoch 357 Batch 0 Loss 0.0735\n",
      "Epoch 357 Loss 0.0735\n",
      "Time taken for 1 epoch 0.0894010066986084 sec\n",
      "\n",
      "Epoch 358 Batch 0 Loss 0.0699\n",
      "Epoch 358 Loss 0.0699\n",
      "Time taken for 1 epoch 0.15981292724609375 sec\n",
      "\n",
      "Epoch 359 Batch 0 Loss 0.0703\n",
      "Epoch 359 Loss 0.0703\n",
      "Time taken for 1 epoch 0.07222104072570801 sec\n",
      "\n",
      "Epoch 360 Batch 0 Loss 0.0703\n",
      "Epoch 360 Loss 0.0703\n",
      "Time taken for 1 epoch 0.15213632583618164 sec\n",
      "\n",
      "Epoch 361 Batch 0 Loss 0.0724\n",
      "Epoch 361 Loss 0.0724\n",
      "Time taken for 1 epoch 0.0761258602142334 sec\n",
      "\n",
      "Epoch 362 Batch 0 Loss 0.0648\n",
      "Epoch 362 Loss 0.0648\n",
      "Time taken for 1 epoch 0.15356183052062988 sec\n",
      "\n",
      "Epoch 363 Batch 0 Loss 0.0683\n",
      "Epoch 363 Loss 0.0683\n",
      "Time taken for 1 epoch 0.07381987571716309 sec\n",
      "\n",
      "Epoch 364 Batch 0 Loss 0.0663\n",
      "Epoch 364 Loss 0.0663\n",
      "Time taken for 1 epoch 0.16750502586364746 sec\n",
      "\n",
      "Epoch 365 Batch 0 Loss 0.0661\n",
      "Epoch 365 Loss 0.0661\n",
      "Time taken for 1 epoch 0.08289885520935059 sec\n",
      "\n",
      "Epoch 366 Batch 0 Loss 0.0635\n",
      "Epoch 366 Loss 0.0635\n",
      "Time taken for 1 epoch 0.26891493797302246 sec\n",
      "\n",
      "Epoch 367 Batch 0 Loss 0.0630\n",
      "Epoch 367 Loss 0.0630\n",
      "Time taken for 1 epoch 0.10961484909057617 sec\n",
      "\n",
      "Epoch 368 Batch 0 Loss 0.0689\n",
      "Epoch 368 Loss 0.0689\n",
      "Time taken for 1 epoch 0.23408269882202148 sec\n",
      "\n",
      "Epoch 369 Batch 0 Loss 0.0656\n",
      "Epoch 369 Loss 0.0656\n",
      "Time taken for 1 epoch 0.09703207015991211 sec\n",
      "\n",
      "Epoch 370 Batch 0 Loss 0.0661\n",
      "Epoch 370 Loss 0.0661\n",
      "Time taken for 1 epoch 0.2325758934020996 sec\n",
      "\n",
      "Epoch 371 Batch 0 Loss 0.0615\n",
      "Epoch 371 Loss 0.0615\n",
      "Time taken for 1 epoch 0.10349297523498535 sec\n",
      "\n",
      "Epoch 372 Batch 0 Loss 0.0648\n",
      "Epoch 372 Loss 0.0648\n",
      "Time taken for 1 epoch 0.19533586502075195 sec\n",
      "\n",
      "Epoch 373 Batch 0 Loss 0.0608\n",
      "Epoch 373 Loss 0.0608\n",
      "Time taken for 1 epoch 0.0827491283416748 sec\n",
      "\n",
      "Epoch 374 Batch 0 Loss 0.0650\n",
      "Epoch 374 Loss 0.0650\n",
      "Time taken for 1 epoch 0.16056013107299805 sec\n",
      "\n",
      "Epoch 375 Batch 0 Loss 0.0675\n",
      "Epoch 375 Loss 0.0675\n",
      "Time taken for 1 epoch 0.07291102409362793 sec\n",
      "\n",
      "Epoch 376 Batch 0 Loss 0.0662\n",
      "Epoch 376 Loss 0.0662\n",
      "Time taken for 1 epoch 0.1504981517791748 sec\n",
      "\n",
      "Epoch 377 Batch 0 Loss 0.0658\n",
      "Epoch 377 Loss 0.0658\n",
      "Time taken for 1 epoch 0.07255911827087402 sec\n",
      "\n",
      "Epoch 378 Batch 0 Loss 0.0586\n",
      "Epoch 378 Loss 0.0586\n",
      "Time taken for 1 epoch 0.15085697174072266 sec\n",
      "\n",
      "Epoch 379 Batch 0 Loss 0.0686\n",
      "Epoch 379 Loss 0.0686\n",
      "Time taken for 1 epoch 0.07151484489440918 sec\n",
      "\n",
      "Epoch 380 Batch 0 Loss 0.0563\n",
      "Epoch 380 Loss 0.0563\n",
      "Time taken for 1 epoch 0.14948511123657227 sec\n",
      "\n",
      "Epoch 381 Batch 0 Loss 0.0597\n",
      "Epoch 381 Loss 0.0597\n",
      "Time taken for 1 epoch 0.07200503349304199 sec\n",
      "\n",
      "Epoch 382 Batch 0 Loss 0.0615\n",
      "Epoch 382 Loss 0.0615\n",
      "Time taken for 1 epoch 0.15203189849853516 sec\n",
      "\n",
      "Epoch 383 Batch 0 Loss 0.0596\n",
      "Epoch 383 Loss 0.0596\n",
      "Time taken for 1 epoch 0.07302331924438477 sec\n",
      "\n",
      "Epoch 384 Batch 0 Loss 0.0553\n",
      "Epoch 384 Loss 0.0553\n",
      "Time taken for 1 epoch 0.1550149917602539 sec\n",
      "\n",
      "Epoch 385 Batch 0 Loss 0.0576\n",
      "Epoch 385 Loss 0.0576\n",
      "Time taken for 1 epoch 0.07227611541748047 sec\n",
      "\n",
      "Epoch 386 Batch 0 Loss 0.0613\n",
      "Epoch 386 Loss 0.0613\n",
      "Time taken for 1 epoch 0.15090394020080566 sec\n",
      "\n",
      "Epoch 387 Batch 0 Loss 0.0614\n",
      "Epoch 387 Loss 0.0614\n",
      "Time taken for 1 epoch 0.07121515274047852 sec\n",
      "\n",
      "Epoch 388 Batch 0 Loss 0.0588\n",
      "Epoch 388 Loss 0.0588\n",
      "Time taken for 1 epoch 0.15072011947631836 sec\n",
      "\n",
      "Epoch 389 Batch 0 Loss 0.0600\n",
      "Epoch 389 Loss 0.0600\n",
      "Time taken for 1 epoch 0.07050204277038574 sec\n",
      "\n",
      "Epoch 390 Batch 0 Loss 0.0655\n",
      "Epoch 390 Loss 0.0655\n",
      "Time taken for 1 epoch 0.14863896369934082 sec\n",
      "\n",
      "Epoch 391 Batch 0 Loss 0.0513\n",
      "Epoch 391 Loss 0.0513\n",
      "Time taken for 1 epoch 0.07192683219909668 sec\n",
      "\n",
      "Epoch 392 Batch 0 Loss 0.0544\n",
      "Epoch 392 Loss 0.0544\n",
      "Time taken for 1 epoch 0.15349292755126953 sec\n",
      "\n",
      "Epoch 393 Batch 0 Loss 0.0578\n",
      "Epoch 393 Loss 0.0578\n",
      "Time taken for 1 epoch 0.06997299194335938 sec\n",
      "\n",
      "Epoch 394 Batch 0 Loss 0.0584\n",
      "Epoch 394 Loss 0.0584\n",
      "Time taken for 1 epoch 0.1535189151763916 sec\n",
      "\n",
      "Epoch 395 Batch 0 Loss 0.0515\n",
      "Epoch 395 Loss 0.0515\n",
      "Time taken for 1 epoch 0.07269978523254395 sec\n",
      "\n",
      "Epoch 396 Batch 0 Loss 0.0533\n",
      "Epoch 396 Loss 0.0533\n",
      "Time taken for 1 epoch 0.15086698532104492 sec\n",
      "\n",
      "Epoch 397 Batch 0 Loss 0.0571\n",
      "Epoch 397 Loss 0.0571\n",
      "Time taken for 1 epoch 0.07142901420593262 sec\n",
      "\n",
      "Epoch 398 Batch 0 Loss 0.0566\n",
      "Epoch 398 Loss 0.0566\n",
      "Time taken for 1 epoch 0.15023088455200195 sec\n",
      "\n",
      "Epoch 399 Batch 0 Loss 0.0482\n",
      "Epoch 399 Loss 0.0482\n",
      "Time taken for 1 epoch 0.07248187065124512 sec\n",
      "\n",
      "Epoch 400 Batch 0 Loss 0.0544\n",
      "Epoch 400 Loss 0.0544\n",
      "Time taken for 1 epoch 0.1524369716644287 sec\n",
      "\n",
      "Epoch 401 Batch 0 Loss 0.0548\n",
      "Epoch 401 Loss 0.0548\n",
      "Time taken for 1 epoch 0.07290911674499512 sec\n",
      "\n",
      "Epoch 402 Batch 0 Loss 0.0541\n",
      "Epoch 402 Loss 0.0541\n",
      "Time taken for 1 epoch 0.1494898796081543 sec\n",
      "\n",
      "Epoch 403 Batch 0 Loss 0.0582\n",
      "Epoch 403 Loss 0.0582\n",
      "Time taken for 1 epoch 0.0721430778503418 sec\n",
      "\n",
      "Epoch 404 Batch 0 Loss 0.0497\n",
      "Epoch 404 Loss 0.0497\n",
      "Time taken for 1 epoch 0.14940309524536133 sec\n",
      "\n",
      "Epoch 405 Batch 0 Loss 0.0523\n",
      "Epoch 405 Loss 0.0523\n",
      "Time taken for 1 epoch 0.07253599166870117 sec\n",
      "\n",
      "Epoch 406 Batch 0 Loss 0.0510\n",
      "Epoch 406 Loss 0.0510\n",
      "Time taken for 1 epoch 0.15254783630371094 sec\n",
      "\n",
      "Epoch 407 Batch 0 Loss 0.0547\n",
      "Epoch 407 Loss 0.0547\n",
      "Time taken for 1 epoch 0.07190465927124023 sec\n",
      "\n",
      "Epoch 408 Batch 0 Loss 0.0582\n",
      "Epoch 408 Loss 0.0582\n",
      "Time taken for 1 epoch 0.1506509780883789 sec\n",
      "\n",
      "Epoch 409 Batch 0 Loss 0.0549\n",
      "Epoch 409 Loss 0.0549\n",
      "Time taken for 1 epoch 0.07259511947631836 sec\n",
      "\n",
      "Epoch 410 Batch 0 Loss 0.0520\n",
      "Epoch 410 Loss 0.0520\n",
      "Time taken for 1 epoch 0.14896297454833984 sec\n",
      "\n",
      "Epoch 411 Batch 0 Loss 0.0531\n",
      "Epoch 411 Loss 0.0531\n",
      "Time taken for 1 epoch 0.0708317756652832 sec\n",
      "\n",
      "Epoch 412 Batch 0 Loss 0.0473\n",
      "Epoch 412 Loss 0.0473\n",
      "Time taken for 1 epoch 0.15626192092895508 sec\n",
      "\n",
      "Epoch 413 Batch 0 Loss 0.0503\n",
      "Epoch 413 Loss 0.0503\n",
      "Time taken for 1 epoch 0.07407093048095703 sec\n",
      "\n",
      "Epoch 414 Batch 0 Loss 0.0531\n",
      "Epoch 414 Loss 0.0531\n",
      "Time taken for 1 epoch 0.15193605422973633 sec\n",
      "\n",
      "Epoch 415 Batch 0 Loss 0.0507\n",
      "Epoch 415 Loss 0.0507\n",
      "Time taken for 1 epoch 0.07092809677124023 sec\n",
      "\n",
      "Epoch 416 Batch 0 Loss 0.0537\n",
      "Epoch 416 Loss 0.0537\n",
      "Time taken for 1 epoch 0.14966511726379395 sec\n",
      "\n",
      "Epoch 417 Batch 0 Loss 0.0512\n",
      "Epoch 417 Loss 0.0512\n",
      "Time taken for 1 epoch 0.07157325744628906 sec\n",
      "\n",
      "Epoch 418 Batch 0 Loss 0.0461\n",
      "Epoch 418 Loss 0.0461\n",
      "Time taken for 1 epoch 0.1480848789215088 sec\n",
      "\n",
      "Epoch 419 Batch 0 Loss 0.0474\n",
      "Epoch 419 Loss 0.0474\n",
      "Time taken for 1 epoch 0.07348299026489258 sec\n",
      "\n",
      "Epoch 420 Batch 0 Loss 0.0485\n",
      "Epoch 420 Loss 0.0485\n",
      "Time taken for 1 epoch 0.14882493019104004 sec\n",
      "\n",
      "Epoch 421 Batch 0 Loss 0.0482\n",
      "Epoch 421 Loss 0.0482\n",
      "Time taken for 1 epoch 0.07234501838684082 sec\n",
      "\n",
      "Epoch 422 Batch 0 Loss 0.0504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422 Loss 0.0504\n",
      "Time taken for 1 epoch 0.15027499198913574 sec\n",
      "\n",
      "Epoch 423 Batch 0 Loss 0.0535\n",
      "Epoch 423 Loss 0.0535\n",
      "Time taken for 1 epoch 0.07241582870483398 sec\n",
      "\n",
      "Epoch 424 Batch 0 Loss 0.0489\n",
      "Epoch 424 Loss 0.0489\n",
      "Time taken for 1 epoch 0.14715003967285156 sec\n",
      "\n",
      "Epoch 425 Batch 0 Loss 0.0491\n",
      "Epoch 425 Loss 0.0491\n",
      "Time taken for 1 epoch 0.07011103630065918 sec\n",
      "\n",
      "Epoch 426 Batch 0 Loss 0.0453\n",
      "Epoch 426 Loss 0.0453\n",
      "Time taken for 1 epoch 0.14715290069580078 sec\n",
      "\n",
      "Epoch 427 Batch 0 Loss 0.0514\n",
      "Epoch 427 Loss 0.0514\n",
      "Time taken for 1 epoch 0.07131409645080566 sec\n",
      "\n",
      "Epoch 428 Batch 0 Loss 0.0450\n",
      "Epoch 428 Loss 0.0450\n",
      "Time taken for 1 epoch 0.15179705619812012 sec\n",
      "\n",
      "Epoch 429 Batch 0 Loss 0.0491\n",
      "Epoch 429 Loss 0.0491\n",
      "Time taken for 1 epoch 0.07278323173522949 sec\n",
      "\n",
      "Epoch 430 Batch 0 Loss 0.0462\n",
      "Epoch 430 Loss 0.0462\n",
      "Time taken for 1 epoch 0.15030312538146973 sec\n",
      "\n",
      "Epoch 431 Batch 0 Loss 0.0488\n",
      "Epoch 431 Loss 0.0488\n",
      "Time taken for 1 epoch 0.07114696502685547 sec\n",
      "\n",
      "Epoch 432 Batch 0 Loss 0.0545\n",
      "Epoch 432 Loss 0.0545\n",
      "Time taken for 1 epoch 0.15147709846496582 sec\n",
      "\n",
      "Epoch 433 Batch 0 Loss 0.0504\n",
      "Epoch 433 Loss 0.0504\n",
      "Time taken for 1 epoch 0.0720829963684082 sec\n",
      "\n",
      "Epoch 434 Batch 0 Loss 0.0492\n",
      "Epoch 434 Loss 0.0492\n",
      "Time taken for 1 epoch 0.1501140594482422 sec\n",
      "\n",
      "Epoch 435 Batch 0 Loss 0.0436\n",
      "Epoch 435 Loss 0.0436\n",
      "Time taken for 1 epoch 0.07182693481445312 sec\n",
      "\n",
      "Epoch 436 Batch 0 Loss 0.0475\n",
      "Epoch 436 Loss 0.0475\n",
      "Time taken for 1 epoch 0.15005016326904297 sec\n",
      "\n",
      "Epoch 437 Batch 0 Loss 0.0474\n",
      "Epoch 437 Loss 0.0474\n",
      "Time taken for 1 epoch 0.07173299789428711 sec\n",
      "\n",
      "Epoch 438 Batch 0 Loss 0.0525\n",
      "Epoch 438 Loss 0.0525\n",
      "Time taken for 1 epoch 0.1596527099609375 sec\n",
      "\n",
      "Epoch 439 Batch 0 Loss 0.0502\n",
      "Epoch 439 Loss 0.0502\n",
      "Time taken for 1 epoch 0.08091068267822266 sec\n",
      "\n",
      "Epoch 440 Batch 0 Loss 0.0444\n",
      "Epoch 440 Loss 0.0444\n",
      "Time taken for 1 epoch 0.19211196899414062 sec\n",
      "\n",
      "Epoch 441 Batch 0 Loss 0.0432\n",
      "Epoch 441 Loss 0.0432\n",
      "Time taken for 1 epoch 0.08273577690124512 sec\n",
      "\n",
      "Epoch 442 Batch 0 Loss 0.0479\n",
      "Epoch 442 Loss 0.0479\n",
      "Time taken for 1 epoch 0.15954899787902832 sec\n",
      "\n",
      "Epoch 443 Batch 0 Loss 0.0478\n",
      "Epoch 443 Loss 0.0478\n",
      "Time taken for 1 epoch 0.07340407371520996 sec\n",
      "\n",
      "Epoch 444 Batch 0 Loss 0.0453\n",
      "Epoch 444 Loss 0.0453\n",
      "Time taken for 1 epoch 0.15669012069702148 sec\n",
      "\n",
      "Epoch 445 Batch 0 Loss 0.0475\n",
      "Epoch 445 Loss 0.0475\n",
      "Time taken for 1 epoch 0.07193374633789062 sec\n",
      "\n",
      "Epoch 446 Batch 0 Loss 0.0487\n",
      "Epoch 446 Loss 0.0487\n",
      "Time taken for 1 epoch 0.15169000625610352 sec\n",
      "\n",
      "Epoch 447 Batch 0 Loss 0.0402\n",
      "Epoch 447 Loss 0.0402\n",
      "Time taken for 1 epoch 0.07034707069396973 sec\n",
      "\n",
      "Epoch 448 Batch 0 Loss 0.0477\n",
      "Epoch 448 Loss 0.0477\n",
      "Time taken for 1 epoch 0.1505107879638672 sec\n",
      "\n",
      "Epoch 449 Batch 0 Loss 0.0466\n",
      "Epoch 449 Loss 0.0466\n",
      "Time taken for 1 epoch 0.07119297981262207 sec\n",
      "\n",
      "Epoch 450 Batch 0 Loss 0.0441\n",
      "Epoch 450 Loss 0.0441\n",
      "Time taken for 1 epoch 0.14853692054748535 sec\n",
      "\n",
      "Epoch 451 Batch 0 Loss 0.0490\n",
      "Epoch 451 Loss 0.0490\n",
      "Time taken for 1 epoch 0.07490706443786621 sec\n",
      "\n",
      "Epoch 452 Batch 0 Loss 0.0404\n",
      "Epoch 452 Loss 0.0404\n",
      "Time taken for 1 epoch 0.14954400062561035 sec\n",
      "\n",
      "Epoch 453 Batch 0 Loss 0.0453\n",
      "Epoch 453 Loss 0.0453\n",
      "Time taken for 1 epoch 0.07199621200561523 sec\n",
      "\n",
      "Epoch 454 Batch 0 Loss 0.0382\n",
      "Epoch 454 Loss 0.0382\n",
      "Time taken for 1 epoch 0.1571190357208252 sec\n",
      "\n",
      "Epoch 455 Batch 0 Loss 0.0465\n",
      "Epoch 455 Loss 0.0465\n",
      "Time taken for 1 epoch 0.07183265686035156 sec\n",
      "\n",
      "Epoch 456 Batch 0 Loss 0.0418\n",
      "Epoch 456 Loss 0.0418\n",
      "Time taken for 1 epoch 0.15888690948486328 sec\n",
      "\n",
      "Epoch 457 Batch 0 Loss 0.0471\n",
      "Epoch 457 Loss 0.0471\n",
      "Time taken for 1 epoch 0.08012509346008301 sec\n",
      "\n",
      "Epoch 458 Batch 0 Loss 0.0425\n",
      "Epoch 458 Loss 0.0425\n",
      "Time taken for 1 epoch 0.1907970905303955 sec\n",
      "\n",
      "Epoch 459 Batch 0 Loss 0.0421\n",
      "Epoch 459 Loss 0.0421\n",
      "Time taken for 1 epoch 0.12805509567260742 sec\n",
      "\n",
      "Epoch 460 Batch 0 Loss 0.0400\n",
      "Epoch 460 Loss 0.0400\n",
      "Time taken for 1 epoch 0.27106213569641113 sec\n",
      "\n",
      "Epoch 461 Batch 0 Loss 0.0443\n",
      "Epoch 461 Loss 0.0443\n",
      "Time taken for 1 epoch 0.10652399063110352 sec\n",
      "\n",
      "Epoch 462 Batch 0 Loss 0.0372\n",
      "Epoch 462 Loss 0.0372\n",
      "Time taken for 1 epoch 0.1888420581817627 sec\n",
      "\n",
      "Epoch 463 Batch 0 Loss 0.0388\n",
      "Epoch 463 Loss 0.0388\n",
      "Time taken for 1 epoch 0.09791207313537598 sec\n",
      "\n",
      "Epoch 464 Batch 0 Loss 0.0383\n",
      "Epoch 464 Loss 0.0383\n",
      "Time taken for 1 epoch 0.21011781692504883 sec\n",
      "\n",
      "Epoch 465 Batch 0 Loss 0.0463\n",
      "Epoch 465 Loss 0.0463\n",
      "Time taken for 1 epoch 0.08291316032409668 sec\n",
      "\n",
      "Epoch 466 Batch 0 Loss 0.0439\n",
      "Epoch 466 Loss 0.0439\n",
      "Time taken for 1 epoch 0.1687321662902832 sec\n",
      "\n",
      "Epoch 467 Batch 0 Loss 0.0411\n",
      "Epoch 467 Loss 0.0411\n",
      "Time taken for 1 epoch 0.07565116882324219 sec\n",
      "\n",
      "Epoch 468 Batch 0 Loss 0.0415\n",
      "Epoch 468 Loss 0.0415\n",
      "Time taken for 1 epoch 0.1523449420928955 sec\n",
      "\n",
      "Epoch 469 Batch 0 Loss 0.0396\n",
      "Epoch 469 Loss 0.0396\n",
      "Time taken for 1 epoch 0.069915771484375 sec\n",
      "\n",
      "Epoch 470 Batch 0 Loss 0.0376\n",
      "Epoch 470 Loss 0.0376\n",
      "Time taken for 1 epoch 0.14849591255187988 sec\n",
      "\n",
      "Epoch 471 Batch 0 Loss 0.0408\n",
      "Epoch 471 Loss 0.0408\n",
      "Time taken for 1 epoch 0.07167220115661621 sec\n",
      "\n",
      "Epoch 472 Batch 0 Loss 0.0397\n",
      "Epoch 472 Loss 0.0397\n",
      "Time taken for 1 epoch 0.15139102935791016 sec\n",
      "\n",
      "Epoch 473 Batch 0 Loss 0.0415\n",
      "Epoch 473 Loss 0.0415\n",
      "Time taken for 1 epoch 0.07285594940185547 sec\n",
      "\n",
      "Epoch 474 Batch 0 Loss 0.0381\n",
      "Epoch 474 Loss 0.0381\n",
      "Time taken for 1 epoch 0.14940595626831055 sec\n",
      "\n",
      "Epoch 475 Batch 0 Loss 0.0369\n",
      "Epoch 475 Loss 0.0369\n",
      "Time taken for 1 epoch 0.07427382469177246 sec\n",
      "\n",
      "Epoch 476 Batch 0 Loss 0.0376\n",
      "Epoch 476 Loss 0.0376\n",
      "Time taken for 1 epoch 0.15137219429016113 sec\n",
      "\n",
      "Epoch 477 Batch 0 Loss 0.0378\n",
      "Epoch 477 Loss 0.0378\n",
      "Time taken for 1 epoch 0.06960225105285645 sec\n",
      "\n",
      "Epoch 478 Batch 0 Loss 0.0418\n",
      "Epoch 478 Loss 0.0418\n",
      "Time taken for 1 epoch 0.15249419212341309 sec\n",
      "\n",
      "Epoch 479 Batch 0 Loss 0.0395\n",
      "Epoch 479 Loss 0.0395\n",
      "Time taken for 1 epoch 0.07174897193908691 sec\n",
      "\n",
      "Epoch 480 Batch 0 Loss 0.0430\n",
      "Epoch 480 Loss 0.0430\n",
      "Time taken for 1 epoch 0.14923524856567383 sec\n",
      "\n",
      "Epoch 481 Batch 0 Loss 0.0421\n",
      "Epoch 481 Loss 0.0421\n",
      "Time taken for 1 epoch 0.07194805145263672 sec\n",
      "\n",
      "Epoch 482 Batch 0 Loss 0.0403\n",
      "Epoch 482 Loss 0.0403\n",
      "Time taken for 1 epoch 0.1510939598083496 sec\n",
      "\n",
      "Epoch 483 Batch 0 Loss 0.0363\n",
      "Epoch 483 Loss 0.0363\n",
      "Time taken for 1 epoch 0.0708768367767334 sec\n",
      "\n",
      "Epoch 484 Batch 0 Loss 0.0328\n",
      "Epoch 484 Loss 0.0328\n",
      "Time taken for 1 epoch 0.1492927074432373 sec\n",
      "\n",
      "Epoch 485 Batch 0 Loss 0.0369\n",
      "Epoch 485 Loss 0.0369\n",
      "Time taken for 1 epoch 0.07379889488220215 sec\n",
      "\n",
      "Epoch 486 Batch 0 Loss 0.0404\n",
      "Epoch 486 Loss 0.0404\n",
      "Time taken for 1 epoch 0.1475968360900879 sec\n",
      "\n",
      "Epoch 487 Batch 0 Loss 0.0419\n",
      "Epoch 487 Loss 0.0419\n",
      "Time taken for 1 epoch 0.07168793678283691 sec\n",
      "\n",
      "Epoch 488 Batch 0 Loss 0.0407\n",
      "Epoch 488 Loss 0.0407\n",
      "Time taken for 1 epoch 0.1515967845916748 sec\n",
      "\n",
      "Epoch 489 Batch 0 Loss 0.0376\n",
      "Epoch 489 Loss 0.0376\n",
      "Time taken for 1 epoch 0.0725259780883789 sec\n",
      "\n",
      "Epoch 490 Batch 0 Loss 0.0340\n",
      "Epoch 490 Loss 0.0340\n",
      "Time taken for 1 epoch 0.1508347988128662 sec\n",
      "\n",
      "Epoch 491 Batch 0 Loss 0.0384\n",
      "Epoch 491 Loss 0.0384\n",
      "Time taken for 1 epoch 0.07147884368896484 sec\n",
      "\n",
      "Epoch 492 Batch 0 Loss 0.0380\n",
      "Epoch 492 Loss 0.0380\n",
      "Time taken for 1 epoch 0.14937281608581543 sec\n",
      "\n",
      "Epoch 493 Batch 0 Loss 0.0376\n",
      "Epoch 493 Loss 0.0376\n",
      "Time taken for 1 epoch 0.07217979431152344 sec\n",
      "\n",
      "Epoch 494 Batch 0 Loss 0.0336\n",
      "Epoch 494 Loss 0.0336\n",
      "Time taken for 1 epoch 0.15095210075378418 sec\n",
      "\n",
      "Epoch 495 Batch 0 Loss 0.0363\n",
      "Epoch 495 Loss 0.0363\n",
      "Time taken for 1 epoch 0.07189106941223145 sec\n",
      "\n",
      "Epoch 496 Batch 0 Loss 0.0362\n",
      "Epoch 496 Loss 0.0362\n",
      "Time taken for 1 epoch 0.1523270606994629 sec\n",
      "\n",
      "Epoch 497 Batch 0 Loss 0.0376\n",
      "Epoch 497 Loss 0.0376\n",
      "Time taken for 1 epoch 0.07223892211914062 sec\n",
      "\n",
      "Epoch 498 Batch 0 Loss 0.0388\n",
      "Epoch 498 Loss 0.0388\n",
      "Time taken for 1 epoch 0.1527080535888672 sec\n",
      "\n",
      "Epoch 499 Batch 0 Loss 0.0350\n",
      "Epoch 499 Loss 0.0350\n",
      "Time taken for 1 epoch 0.07256293296813965 sec\n",
      "\n",
      "Epoch 500 Batch 0 Loss 0.0337\n",
      "Epoch 500 Loss 0.0337\n",
      "Time taken for 1 epoch 0.15337610244750977 sec\n",
      "\n",
      "Epoch 501 Batch 0 Loss 0.0423\n",
      "Epoch 501 Loss 0.0423\n",
      "Time taken for 1 epoch 0.07103276252746582 sec\n",
      "\n",
      "Epoch 502 Batch 0 Loss 0.0343\n",
      "Epoch 502 Loss 0.0343\n",
      "Time taken for 1 epoch 0.14998793601989746 sec\n",
      "\n",
      "Epoch 503 Batch 0 Loss 0.0337\n",
      "Epoch 503 Loss 0.0337\n",
      "Time taken for 1 epoch 0.07179808616638184 sec\n",
      "\n",
      "Epoch 504 Batch 0 Loss 0.0358\n",
      "Epoch 504 Loss 0.0358\n",
      "Time taken for 1 epoch 0.14882588386535645 sec\n",
      "\n",
      "Epoch 505 Batch 0 Loss 0.0337\n",
      "Epoch 505 Loss 0.0337\n",
      "Time taken for 1 epoch 0.07154417037963867 sec\n",
      "\n",
      "Epoch 506 Batch 0 Loss 0.0384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 506 Loss 0.0384\n",
      "Time taken for 1 epoch 0.15035724639892578 sec\n",
      "\n",
      "Epoch 507 Batch 0 Loss 0.0368\n",
      "Epoch 507 Loss 0.0368\n",
      "Time taken for 1 epoch 0.07377886772155762 sec\n",
      "\n",
      "Epoch 508 Batch 0 Loss 0.0330\n",
      "Epoch 508 Loss 0.0330\n",
      "Time taken for 1 epoch 0.14926910400390625 sec\n",
      "\n",
      "Epoch 509 Batch 0 Loss 0.0335\n",
      "Epoch 509 Loss 0.0335\n",
      "Time taken for 1 epoch 0.07510995864868164 sec\n",
      "\n",
      "Epoch 510 Batch 0 Loss 0.0366\n",
      "Epoch 510 Loss 0.0366\n",
      "Time taken for 1 epoch 0.15085792541503906 sec\n",
      "\n",
      "Epoch 511 Batch 0 Loss 0.0299\n",
      "Epoch 511 Loss 0.0299\n",
      "Time taken for 1 epoch 0.07138180732727051 sec\n",
      "\n",
      "Epoch 512 Batch 0 Loss 0.0336\n",
      "Epoch 512 Loss 0.0336\n",
      "Time taken for 1 epoch 0.1488661766052246 sec\n",
      "\n",
      "Epoch 513 Batch 0 Loss 0.0370\n",
      "Epoch 513 Loss 0.0370\n",
      "Time taken for 1 epoch 0.08832812309265137 sec\n",
      "\n",
      "Epoch 514 Batch 0 Loss 0.0349\n",
      "Epoch 514 Loss 0.0349\n",
      "Time taken for 1 epoch 0.1489732265472412 sec\n",
      "\n",
      "Epoch 515 Batch 0 Loss 0.0342\n",
      "Epoch 515 Loss 0.0342\n",
      "Time taken for 1 epoch 0.06948399543762207 sec\n",
      "\n",
      "Epoch 516 Batch 0 Loss 0.0326\n",
      "Epoch 516 Loss 0.0326\n",
      "Time taken for 1 epoch 0.14940309524536133 sec\n",
      "\n",
      "Epoch 517 Batch 0 Loss 0.0340\n",
      "Epoch 517 Loss 0.0340\n",
      "Time taken for 1 epoch 0.07146406173706055 sec\n",
      "\n",
      "Epoch 518 Batch 0 Loss 0.0322\n",
      "Epoch 518 Loss 0.0322\n",
      "Time taken for 1 epoch 0.1504809856414795 sec\n",
      "\n",
      "Epoch 519 Batch 0 Loss 0.0315\n",
      "Epoch 519 Loss 0.0315\n",
      "Time taken for 1 epoch 0.07074904441833496 sec\n",
      "\n",
      "Epoch 520 Batch 0 Loss 0.0320\n",
      "Epoch 520 Loss 0.0320\n",
      "Time taken for 1 epoch 0.14895105361938477 sec\n",
      "\n",
      "Epoch 521 Batch 0 Loss 0.0334\n",
      "Epoch 521 Loss 0.0334\n",
      "Time taken for 1 epoch 0.07119488716125488 sec\n",
      "\n",
      "Epoch 522 Batch 0 Loss 0.0310\n",
      "Epoch 522 Loss 0.0310\n",
      "Time taken for 1 epoch 0.1512742042541504 sec\n",
      "\n",
      "Epoch 523 Batch 0 Loss 0.0308\n",
      "Epoch 523 Loss 0.0308\n",
      "Time taken for 1 epoch 0.07080674171447754 sec\n",
      "\n",
      "Epoch 524 Batch 0 Loss 0.0298\n",
      "Epoch 524 Loss 0.0298\n",
      "Time taken for 1 epoch 0.15009784698486328 sec\n",
      "\n",
      "Epoch 525 Batch 0 Loss 0.0293\n",
      "Epoch 525 Loss 0.0293\n",
      "Time taken for 1 epoch 0.07134222984313965 sec\n",
      "\n",
      "Epoch 526 Batch 0 Loss 0.0305\n",
      "Epoch 526 Loss 0.0305\n",
      "Time taken for 1 epoch 0.1514420509338379 sec\n",
      "\n",
      "Epoch 527 Batch 0 Loss 0.0340\n",
      "Epoch 527 Loss 0.0340\n",
      "Time taken for 1 epoch 0.07111716270446777 sec\n",
      "\n",
      "Epoch 528 Batch 0 Loss 0.0346\n",
      "Epoch 528 Loss 0.0346\n",
      "Time taken for 1 epoch 0.14934492111206055 sec\n",
      "\n",
      "Epoch 529 Batch 0 Loss 0.0300\n",
      "Epoch 529 Loss 0.0300\n",
      "Time taken for 1 epoch 0.07262492179870605 sec\n",
      "\n",
      "Epoch 530 Batch 0 Loss 0.0332\n",
      "Epoch 530 Loss 0.0332\n",
      "Time taken for 1 epoch 0.14835906028747559 sec\n",
      "\n",
      "Epoch 531 Batch 0 Loss 0.0290\n",
      "Epoch 531 Loss 0.0290\n",
      "Time taken for 1 epoch 0.07195901870727539 sec\n",
      "\n",
      "Epoch 532 Batch 0 Loss 0.0350\n",
      "Epoch 532 Loss 0.0350\n",
      "Time taken for 1 epoch 0.14841389656066895 sec\n",
      "\n",
      "Epoch 533 Batch 0 Loss 0.0324\n",
      "Epoch 533 Loss 0.0324\n",
      "Time taken for 1 epoch 0.07091188430786133 sec\n",
      "\n",
      "Epoch 534 Batch 0 Loss 0.0252\n",
      "Epoch 534 Loss 0.0252\n",
      "Time taken for 1 epoch 0.1489851474761963 sec\n",
      "\n",
      "Epoch 535 Batch 0 Loss 0.0256\n",
      "Epoch 535 Loss 0.0256\n",
      "Time taken for 1 epoch 0.0720529556274414 sec\n",
      "\n",
      "Epoch 536 Batch 0 Loss 0.0279\n",
      "Epoch 536 Loss 0.0279\n",
      "Time taken for 1 epoch 0.15089082717895508 sec\n",
      "\n",
      "Epoch 537 Batch 0 Loss 0.0286\n",
      "Epoch 537 Loss 0.0286\n",
      "Time taken for 1 epoch 0.07072591781616211 sec\n",
      "\n",
      "Epoch 538 Batch 0 Loss 0.0292\n",
      "Epoch 538 Loss 0.0292\n",
      "Time taken for 1 epoch 0.14959001541137695 sec\n",
      "\n",
      "Epoch 539 Batch 0 Loss 0.0311\n",
      "Epoch 539 Loss 0.0311\n",
      "Time taken for 1 epoch 0.07250809669494629 sec\n",
      "\n",
      "Epoch 540 Batch 0 Loss 0.0299\n",
      "Epoch 540 Loss 0.0299\n",
      "Time taken for 1 epoch 0.1501178741455078 sec\n",
      "\n",
      "Epoch 541 Batch 0 Loss 0.0276\n",
      "Epoch 541 Loss 0.0276\n",
      "Time taken for 1 epoch 0.0732569694519043 sec\n",
      "\n",
      "Epoch 542 Batch 0 Loss 0.0291\n",
      "Epoch 542 Loss 0.0291\n",
      "Time taken for 1 epoch 0.14856386184692383 sec\n",
      "\n",
      "Epoch 543 Batch 0 Loss 0.0291\n",
      "Epoch 543 Loss 0.0291\n",
      "Time taken for 1 epoch 0.07139086723327637 sec\n",
      "\n",
      "Epoch 544 Batch 0 Loss 0.0283\n",
      "Epoch 544 Loss 0.0283\n",
      "Time taken for 1 epoch 0.15244388580322266 sec\n",
      "\n",
      "Epoch 545 Batch 0 Loss 0.0270\n",
      "Epoch 545 Loss 0.0270\n",
      "Time taken for 1 epoch 0.07367420196533203 sec\n",
      "\n",
      "Epoch 546 Batch 0 Loss 0.0250\n",
      "Epoch 546 Loss 0.0250\n",
      "Time taken for 1 epoch 0.15603208541870117 sec\n",
      "\n",
      "Epoch 547 Batch 0 Loss 0.0268\n",
      "Epoch 547 Loss 0.0268\n",
      "Time taken for 1 epoch 0.07274317741394043 sec\n",
      "\n",
      "Epoch 548 Batch 0 Loss 0.0288\n",
      "Epoch 548 Loss 0.0288\n",
      "Time taken for 1 epoch 0.16340088844299316 sec\n",
      "\n",
      "Epoch 549 Batch 0 Loss 0.0262\n",
      "Epoch 549 Loss 0.0262\n",
      "Time taken for 1 epoch 0.07266092300415039 sec\n",
      "\n",
      "Epoch 550 Batch 0 Loss 0.0280\n",
      "Epoch 550 Loss 0.0280\n",
      "Time taken for 1 epoch 0.1565690040588379 sec\n",
      "\n",
      "Epoch 551 Batch 0 Loss 0.0250\n",
      "Epoch 551 Loss 0.0250\n",
      "Time taken for 1 epoch 0.07558012008666992 sec\n",
      "\n",
      "Epoch 552 Batch 0 Loss 0.0259\n",
      "Epoch 552 Loss 0.0259\n",
      "Time taken for 1 epoch 0.17741012573242188 sec\n",
      "\n",
      "Epoch 553 Batch 0 Loss 0.0282\n",
      "Epoch 553 Loss 0.0282\n",
      "Time taken for 1 epoch 0.12443113327026367 sec\n",
      "\n",
      "Epoch 554 Batch 0 Loss 0.0296\n",
      "Epoch 554 Loss 0.0296\n",
      "Time taken for 1 epoch 0.2634117603302002 sec\n",
      "\n",
      "Epoch 555 Batch 0 Loss 0.0258\n",
      "Epoch 555 Loss 0.0258\n",
      "Time taken for 1 epoch 0.09572005271911621 sec\n",
      "\n",
      "Epoch 556 Batch 0 Loss 0.0306\n",
      "Epoch 556 Loss 0.0306\n",
      "Time taken for 1 epoch 0.18703413009643555 sec\n",
      "\n",
      "Epoch 557 Batch 0 Loss 0.0275\n",
      "Epoch 557 Loss 0.0275\n",
      "Time taken for 1 epoch 0.08072900772094727 sec\n",
      "\n",
      "Epoch 558 Batch 0 Loss 0.0281\n",
      "Epoch 558 Loss 0.0281\n",
      "Time taken for 1 epoch 0.16717982292175293 sec\n",
      "\n",
      "Epoch 559 Batch 0 Loss 0.0249\n",
      "Epoch 559 Loss 0.0249\n",
      "Time taken for 1 epoch 0.07938313484191895 sec\n",
      "\n",
      "Epoch 560 Batch 0 Loss 0.0269\n",
      "Epoch 560 Loss 0.0269\n",
      "Time taken for 1 epoch 0.17084479331970215 sec\n",
      "\n",
      "Epoch 561 Batch 0 Loss 0.0257\n",
      "Epoch 561 Loss 0.0257\n",
      "Time taken for 1 epoch 0.07407379150390625 sec\n",
      "\n",
      "Epoch 562 Batch 0 Loss 0.0219\n",
      "Epoch 562 Loss 0.0219\n",
      "Time taken for 1 epoch 0.1509099006652832 sec\n",
      "\n",
      "Epoch 563 Batch 0 Loss 0.0247\n",
      "Epoch 563 Loss 0.0247\n",
      "Time taken for 1 epoch 0.07058501243591309 sec\n",
      "\n",
      "Epoch 564 Batch 0 Loss 0.0300\n",
      "Epoch 564 Loss 0.0300\n",
      "Time taken for 1 epoch 0.15188980102539062 sec\n",
      "\n",
      "Epoch 565 Batch 0 Loss 0.0261\n",
      "Epoch 565 Loss 0.0261\n",
      "Time taken for 1 epoch 0.07273221015930176 sec\n",
      "\n",
      "Epoch 566 Batch 0 Loss 0.0317\n",
      "Epoch 566 Loss 0.0317\n",
      "Time taken for 1 epoch 0.14910387992858887 sec\n",
      "\n",
      "Epoch 567 Batch 0 Loss 0.0261\n",
      "Epoch 567 Loss 0.0261\n",
      "Time taken for 1 epoch 0.07086896896362305 sec\n",
      "\n",
      "Epoch 568 Batch 0 Loss 0.0290\n",
      "Epoch 568 Loss 0.0290\n",
      "Time taken for 1 epoch 0.15038108825683594 sec\n",
      "\n",
      "Epoch 569 Batch 0 Loss 0.0260\n",
      "Epoch 569 Loss 0.0260\n",
      "Time taken for 1 epoch 0.07435989379882812 sec\n",
      "\n",
      "Epoch 570 Batch 0 Loss 0.0307\n",
      "Epoch 570 Loss 0.0307\n",
      "Time taken for 1 epoch 0.15137887001037598 sec\n",
      "\n",
      "Epoch 571 Batch 0 Loss 0.0267\n",
      "Epoch 571 Loss 0.0267\n",
      "Time taken for 1 epoch 0.07084488868713379 sec\n",
      "\n",
      "Epoch 572 Batch 0 Loss 0.0245\n",
      "Epoch 572 Loss 0.0245\n",
      "Time taken for 1 epoch 0.15037322044372559 sec\n",
      "\n",
      "Epoch 573 Batch 0 Loss 0.0256\n",
      "Epoch 573 Loss 0.0256\n",
      "Time taken for 1 epoch 0.0710439682006836 sec\n",
      "\n",
      "Epoch 574 Batch 0 Loss 0.0249\n",
      "Epoch 574 Loss 0.0249\n",
      "Time taken for 1 epoch 0.1512136459350586 sec\n",
      "\n",
      "Epoch 575 Batch 0 Loss 0.0274\n",
      "Epoch 575 Loss 0.0274\n",
      "Time taken for 1 epoch 0.07190871238708496 sec\n",
      "\n",
      "Epoch 576 Batch 0 Loss 0.0269\n",
      "Epoch 576 Loss 0.0269\n",
      "Time taken for 1 epoch 0.1507720947265625 sec\n",
      "\n",
      "Epoch 577 Batch 0 Loss 0.0294\n",
      "Epoch 577 Loss 0.0294\n",
      "Time taken for 1 epoch 0.07000422477722168 sec\n",
      "\n",
      "Epoch 578 Batch 0 Loss 0.0242\n",
      "Epoch 578 Loss 0.0242\n",
      "Time taken for 1 epoch 0.14772891998291016 sec\n",
      "\n",
      "Epoch 579 Batch 0 Loss 0.0236\n",
      "Epoch 579 Loss 0.0236\n",
      "Time taken for 1 epoch 0.07109713554382324 sec\n",
      "\n",
      "Epoch 580 Batch 0 Loss 0.0273\n",
      "Epoch 580 Loss 0.0273\n",
      "Time taken for 1 epoch 0.15189099311828613 sec\n",
      "\n",
      "Epoch 581 Batch 0 Loss 0.0243\n",
      "Epoch 581 Loss 0.0243\n",
      "Time taken for 1 epoch 0.06998395919799805 sec\n",
      "\n",
      "Epoch 582 Batch 0 Loss 0.0245\n",
      "Epoch 582 Loss 0.0245\n",
      "Time taken for 1 epoch 0.15029501914978027 sec\n",
      "\n",
      "Epoch 583 Batch 0 Loss 0.0245\n",
      "Epoch 583 Loss 0.0245\n",
      "Time taken for 1 epoch 0.0717308521270752 sec\n",
      "\n",
      "Epoch 584 Batch 0 Loss 0.0215\n",
      "Epoch 584 Loss 0.0215\n",
      "Time taken for 1 epoch 0.1545858383178711 sec\n",
      "\n",
      "Epoch 585 Batch 0 Loss 0.0240\n",
      "Epoch 585 Loss 0.0240\n",
      "Time taken for 1 epoch 0.07102012634277344 sec\n",
      "\n",
      "Epoch 586 Batch 0 Loss 0.0236\n",
      "Epoch 586 Loss 0.0236\n",
      "Time taken for 1 epoch 0.15009212493896484 sec\n",
      "\n",
      "Epoch 587 Batch 0 Loss 0.0210\n",
      "Epoch 587 Loss 0.0210\n",
      "Time taken for 1 epoch 0.07111907005310059 sec\n",
      "\n",
      "Epoch 588 Batch 0 Loss 0.0237\n",
      "Epoch 588 Loss 0.0237\n",
      "Time taken for 1 epoch 0.15192389488220215 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589 Batch 0 Loss 0.0251\n",
      "Epoch 589 Loss 0.0251\n",
      "Time taken for 1 epoch 0.07158827781677246 sec\n",
      "\n",
      "Epoch 590 Batch 0 Loss 0.0246\n",
      "Epoch 590 Loss 0.0246\n",
      "Time taken for 1 epoch 0.1508631706237793 sec\n",
      "\n",
      "Epoch 591 Batch 0 Loss 0.0236\n",
      "Epoch 591 Loss 0.0236\n",
      "Time taken for 1 epoch 0.07259392738342285 sec\n",
      "\n",
      "Epoch 592 Batch 0 Loss 0.0229\n",
      "Epoch 592 Loss 0.0229\n",
      "Time taken for 1 epoch 0.15047979354858398 sec\n",
      "\n",
      "Epoch 593 Batch 0 Loss 0.0257\n",
      "Epoch 593 Loss 0.0257\n",
      "Time taken for 1 epoch 0.07172107696533203 sec\n",
      "\n",
      "Epoch 594 Batch 0 Loss 0.0227\n",
      "Epoch 594 Loss 0.0227\n",
      "Time taken for 1 epoch 0.15022611618041992 sec\n",
      "\n",
      "Epoch 595 Batch 0 Loss 0.0240\n",
      "Epoch 595 Loss 0.0240\n",
      "Time taken for 1 epoch 0.07042098045349121 sec\n",
      "\n",
      "Epoch 596 Batch 0 Loss 0.0229\n",
      "Epoch 596 Loss 0.0229\n",
      "Time taken for 1 epoch 0.14950084686279297 sec\n",
      "\n",
      "Epoch 597 Batch 0 Loss 0.0244\n",
      "Epoch 597 Loss 0.0244\n",
      "Time taken for 1 epoch 0.07096600532531738 sec\n",
      "\n",
      "Epoch 598 Batch 0 Loss 0.0213\n",
      "Epoch 598 Loss 0.0213\n",
      "Time taken for 1 epoch 0.1515810489654541 sec\n",
      "\n",
      "Epoch 599 Batch 0 Loss 0.0202\n",
      "Epoch 599 Loss 0.0202\n",
      "Time taken for 1 epoch 0.07189106941223145 sec\n",
      "\n",
      "Epoch 600 Batch 0 Loss 0.0224\n",
      "Epoch 600 Loss 0.0224\n",
      "Time taken for 1 epoch 0.15303921699523926 sec\n",
      "\n",
      "Epoch 601 Batch 0 Loss 0.0215\n",
      "Epoch 601 Loss 0.0215\n",
      "Time taken for 1 epoch 0.0703880786895752 sec\n",
      "\n",
      "Epoch 602 Batch 0 Loss 0.0236\n",
      "Epoch 602 Loss 0.0236\n",
      "Time taken for 1 epoch 0.1498730182647705 sec\n",
      "\n",
      "Epoch 603 Batch 0 Loss 0.0219\n",
      "Epoch 603 Loss 0.0219\n",
      "Time taken for 1 epoch 0.07104301452636719 sec\n",
      "\n",
      "Epoch 604 Batch 0 Loss 0.0247\n",
      "Epoch 604 Loss 0.0247\n",
      "Time taken for 1 epoch 0.1505730152130127 sec\n",
      "\n",
      "Epoch 605 Batch 0 Loss 0.0212\n",
      "Epoch 605 Loss 0.0212\n",
      "Time taken for 1 epoch 0.07154679298400879 sec\n",
      "\n",
      "Epoch 606 Batch 0 Loss 0.0222\n",
      "Epoch 606 Loss 0.0222\n",
      "Time taken for 1 epoch 0.1524357795715332 sec\n",
      "\n",
      "Epoch 607 Batch 0 Loss 0.0240\n",
      "Epoch 607 Loss 0.0240\n",
      "Time taken for 1 epoch 0.07205390930175781 sec\n",
      "\n",
      "Epoch 608 Batch 0 Loss 0.0205\n",
      "Epoch 608 Loss 0.0205\n",
      "Time taken for 1 epoch 0.1492629051208496 sec\n",
      "\n",
      "Epoch 609 Batch 0 Loss 0.0213\n",
      "Epoch 609 Loss 0.0213\n",
      "Time taken for 1 epoch 0.07150506973266602 sec\n",
      "\n",
      "Epoch 610 Batch 0 Loss 0.0245\n",
      "Epoch 610 Loss 0.0245\n",
      "Time taken for 1 epoch 0.1522529125213623 sec\n",
      "\n",
      "Epoch 611 Batch 0 Loss 0.0262\n",
      "Epoch 611 Loss 0.0262\n",
      "Time taken for 1 epoch 0.0706026554107666 sec\n",
      "\n",
      "Epoch 612 Batch 0 Loss 0.0216\n",
      "Epoch 612 Loss 0.0216\n",
      "Time taken for 1 epoch 0.1494460105895996 sec\n",
      "\n",
      "Epoch 613 Batch 0 Loss 0.0268\n",
      "Epoch 613 Loss 0.0268\n",
      "Time taken for 1 epoch 0.07228708267211914 sec\n",
      "\n",
      "Epoch 614 Batch 0 Loss 0.0197\n",
      "Epoch 614 Loss 0.0197\n",
      "Time taken for 1 epoch 0.1497659683227539 sec\n",
      "\n",
      "Epoch 615 Batch 0 Loss 0.0214\n",
      "Epoch 615 Loss 0.0214\n",
      "Time taken for 1 epoch 0.07173299789428711 sec\n",
      "\n",
      "Epoch 616 Batch 0 Loss 0.0208\n",
      "Epoch 616 Loss 0.0208\n",
      "Time taken for 1 epoch 0.1537189483642578 sec\n",
      "\n",
      "Epoch 617 Batch 0 Loss 0.0181\n",
      "Epoch 617 Loss 0.0181\n",
      "Time taken for 1 epoch 0.0708777904510498 sec\n",
      "\n",
      "Epoch 618 Batch 0 Loss 0.0215\n",
      "Epoch 618 Loss 0.0215\n",
      "Time taken for 1 epoch 0.15091514587402344 sec\n",
      "\n",
      "Epoch 619 Batch 0 Loss 0.0230\n",
      "Epoch 619 Loss 0.0230\n",
      "Time taken for 1 epoch 0.07174324989318848 sec\n",
      "\n",
      "Epoch 620 Batch 0 Loss 0.0202\n",
      "Epoch 620 Loss 0.0202\n",
      "Time taken for 1 epoch 0.15082597732543945 sec\n",
      "\n",
      "Epoch 621 Batch 0 Loss 0.0184\n",
      "Epoch 621 Loss 0.0184\n",
      "Time taken for 1 epoch 0.07012391090393066 sec\n",
      "\n",
      "Epoch 622 Batch 0 Loss 0.0222\n",
      "Epoch 622 Loss 0.0222\n",
      "Time taken for 1 epoch 0.15130186080932617 sec\n",
      "\n",
      "Epoch 623 Batch 0 Loss 0.0181\n",
      "Epoch 623 Loss 0.0181\n",
      "Time taken for 1 epoch 0.07144808769226074 sec\n",
      "\n",
      "Epoch 624 Batch 0 Loss 0.0201\n",
      "Epoch 624 Loss 0.0201\n",
      "Time taken for 1 epoch 0.15062975883483887 sec\n",
      "\n",
      "Epoch 625 Batch 0 Loss 0.0201\n",
      "Epoch 625 Loss 0.0201\n",
      "Time taken for 1 epoch 0.07436585426330566 sec\n",
      "\n",
      "Epoch 626 Batch 0 Loss 0.0208\n",
      "Epoch 626 Loss 0.0208\n",
      "Time taken for 1 epoch 0.14885973930358887 sec\n",
      "\n",
      "Epoch 627 Batch 0 Loss 0.0165\n",
      "Epoch 627 Loss 0.0165\n",
      "Time taken for 1 epoch 0.06912994384765625 sec\n",
      "\n",
      "Epoch 628 Batch 0 Loss 0.0241\n",
      "Epoch 628 Loss 0.0241\n",
      "Time taken for 1 epoch 0.15123987197875977 sec\n",
      "\n",
      "Epoch 629 Batch 0 Loss 0.0207\n",
      "Epoch 629 Loss 0.0207\n",
      "Time taken for 1 epoch 0.07107305526733398 sec\n",
      "\n",
      "Epoch 630 Batch 0 Loss 0.0184\n",
      "Epoch 630 Loss 0.0184\n",
      "Time taken for 1 epoch 0.14923501014709473 sec\n",
      "\n",
      "Epoch 631 Batch 0 Loss 0.0197\n",
      "Epoch 631 Loss 0.0197\n",
      "Time taken for 1 epoch 0.07192277908325195 sec\n",
      "\n",
      "Epoch 632 Batch 0 Loss 0.0193\n",
      "Epoch 632 Loss 0.0193\n",
      "Time taken for 1 epoch 0.15043187141418457 sec\n",
      "\n",
      "Epoch 633 Batch 0 Loss 0.0213\n",
      "Epoch 633 Loss 0.0213\n",
      "Time taken for 1 epoch 0.06961202621459961 sec\n",
      "\n",
      "Epoch 634 Batch 0 Loss 0.0185\n",
      "Epoch 634 Loss 0.0185\n",
      "Time taken for 1 epoch 0.15318822860717773 sec\n",
      "\n",
      "Epoch 635 Batch 0 Loss 0.0196\n",
      "Epoch 635 Loss 0.0196\n",
      "Time taken for 1 epoch 0.07198691368103027 sec\n",
      "\n",
      "Epoch 636 Batch 0 Loss 0.0171\n",
      "Epoch 636 Loss 0.0171\n",
      "Time taken for 1 epoch 0.15337014198303223 sec\n",
      "\n",
      "Epoch 637 Batch 0 Loss 0.0202\n",
      "Epoch 637 Loss 0.0202\n",
      "Time taken for 1 epoch 0.07368135452270508 sec\n",
      "\n",
      "Epoch 638 Batch 0 Loss 0.0188\n",
      "Epoch 638 Loss 0.0188\n",
      "Time taken for 1 epoch 0.15284514427185059 sec\n",
      "\n",
      "Epoch 639 Batch 0 Loss 0.0197\n",
      "Epoch 639 Loss 0.0197\n",
      "Time taken for 1 epoch 0.07347798347473145 sec\n",
      "\n",
      "Epoch 640 Batch 0 Loss 0.0178\n",
      "Epoch 640 Loss 0.0178\n",
      "Time taken for 1 epoch 0.1568899154663086 sec\n",
      "\n",
      "Epoch 641 Batch 0 Loss 0.0208\n",
      "Epoch 641 Loss 0.0208\n",
      "Time taken for 1 epoch 0.07247114181518555 sec\n",
      "\n",
      "Epoch 642 Batch 0 Loss 0.0205\n",
      "Epoch 642 Loss 0.0205\n",
      "Time taken for 1 epoch 0.15071487426757812 sec\n",
      "\n",
      "Epoch 643 Batch 0 Loss 0.0191\n",
      "Epoch 643 Loss 0.0191\n",
      "Time taken for 1 epoch 0.07476210594177246 sec\n",
      "\n",
      "Epoch 644 Batch 0 Loss 0.0235\n",
      "Epoch 644 Loss 0.0235\n",
      "Time taken for 1 epoch 0.15444302558898926 sec\n",
      "\n",
      "Epoch 645 Batch 0 Loss 0.0211\n",
      "Epoch 645 Loss 0.0211\n",
      "Time taken for 1 epoch 0.0885932445526123 sec\n",
      "\n",
      "Epoch 646 Batch 0 Loss 0.0216\n",
      "Epoch 646 Loss 0.0216\n",
      "Time taken for 1 epoch 0.18585705757141113 sec\n",
      "\n",
      "Epoch 647 Batch 0 Loss 0.0169\n",
      "Epoch 647 Loss 0.0169\n",
      "Time taken for 1 epoch 0.10227465629577637 sec\n",
      "\n",
      "Epoch 648 Batch 0 Loss 0.0193\n",
      "Epoch 648 Loss 0.0193\n",
      "Time taken for 1 epoch 0.2350330352783203 sec\n",
      "\n",
      "Epoch 649 Batch 0 Loss 0.0197\n",
      "Epoch 649 Loss 0.0197\n",
      "Time taken for 1 epoch 0.0930182933807373 sec\n",
      "\n",
      "Epoch 650 Batch 0 Loss 0.0166\n",
      "Epoch 650 Loss 0.0166\n",
      "Time taken for 1 epoch 0.20729804039001465 sec\n",
      "\n",
      "Epoch 651 Batch 0 Loss 0.0187\n",
      "Epoch 651 Loss 0.0187\n",
      "Time taken for 1 epoch 0.09029722213745117 sec\n",
      "\n",
      "Epoch 652 Batch 0 Loss 0.0200\n",
      "Epoch 652 Loss 0.0200\n",
      "Time taken for 1 epoch 0.17281818389892578 sec\n",
      "\n",
      "Epoch 653 Batch 0 Loss 0.0186\n",
      "Epoch 653 Loss 0.0186\n",
      "Time taken for 1 epoch 0.07704591751098633 sec\n",
      "\n",
      "Epoch 654 Batch 0 Loss 0.0162\n",
      "Epoch 654 Loss 0.0162\n",
      "Time taken for 1 epoch 0.1517329216003418 sec\n",
      "\n",
      "Epoch 655 Batch 0 Loss 0.0194\n",
      "Epoch 655 Loss 0.0194\n",
      "Time taken for 1 epoch 0.07090210914611816 sec\n",
      "\n",
      "Epoch 656 Batch 0 Loss 0.0172\n",
      "Epoch 656 Loss 0.0172\n",
      "Time taken for 1 epoch 0.15170621871948242 sec\n",
      "\n",
      "Epoch 657 Batch 0 Loss 0.0209\n",
      "Epoch 657 Loss 0.0209\n",
      "Time taken for 1 epoch 0.07203412055969238 sec\n",
      "\n",
      "Epoch 658 Batch 0 Loss 0.0195\n",
      "Epoch 658 Loss 0.0195\n",
      "Time taken for 1 epoch 0.15057587623596191 sec\n",
      "\n",
      "Epoch 659 Batch 0 Loss 0.0196\n",
      "Epoch 659 Loss 0.0196\n",
      "Time taken for 1 epoch 0.07090115547180176 sec\n",
      "\n",
      "Epoch 660 Batch 0 Loss 0.0210\n",
      "Epoch 660 Loss 0.0210\n",
      "Time taken for 1 epoch 0.15250086784362793 sec\n",
      "\n",
      "Epoch 661 Batch 0 Loss 0.0187\n",
      "Epoch 661 Loss 0.0187\n",
      "Time taken for 1 epoch 0.07155394554138184 sec\n",
      "\n",
      "Epoch 662 Batch 0 Loss 0.0204\n",
      "Epoch 662 Loss 0.0204\n",
      "Time taken for 1 epoch 0.15284013748168945 sec\n",
      "\n",
      "Epoch 663 Batch 0 Loss 0.0187\n",
      "Epoch 663 Loss 0.0187\n",
      "Time taken for 1 epoch 0.07410097122192383 sec\n",
      "\n",
      "Epoch 664 Batch 0 Loss 0.0173\n",
      "Epoch 664 Loss 0.0173\n",
      "Time taken for 1 epoch 0.15036797523498535 sec\n",
      "\n",
      "Epoch 665 Batch 0 Loss 0.0184\n",
      "Epoch 665 Loss 0.0184\n",
      "Time taken for 1 epoch 0.07339024543762207 sec\n",
      "\n",
      "Epoch 666 Batch 0 Loss 0.0191\n",
      "Epoch 666 Loss 0.0191\n",
      "Time taken for 1 epoch 0.14958596229553223 sec\n",
      "\n",
      "Epoch 667 Batch 0 Loss 0.0174\n",
      "Epoch 667 Loss 0.0174\n",
      "Time taken for 1 epoch 0.07265615463256836 sec\n",
      "\n",
      "Epoch 668 Batch 0 Loss 0.0183\n",
      "Epoch 668 Loss 0.0183\n",
      "Time taken for 1 epoch 0.15215516090393066 sec\n",
      "\n",
      "Epoch 669 Batch 0 Loss 0.0143\n",
      "Epoch 669 Loss 0.0143\n",
      "Time taken for 1 epoch 0.07238507270812988 sec\n",
      "\n",
      "Epoch 670 Batch 0 Loss 0.0196\n",
      "Epoch 670 Loss 0.0196\n",
      "Time taken for 1 epoch 0.1525430679321289 sec\n",
      "\n",
      "Epoch 671 Batch 0 Loss 0.0213\n",
      "Epoch 671 Loss 0.0213\n",
      "Time taken for 1 epoch 0.07188606262207031 sec\n",
      "\n",
      "Epoch 672 Batch 0 Loss 0.0153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672 Loss 0.0153\n",
      "Time taken for 1 epoch 0.15277695655822754 sec\n",
      "\n",
      "Epoch 673 Batch 0 Loss 0.0166\n",
      "Epoch 673 Loss 0.0166\n",
      "Time taken for 1 epoch 0.07787513732910156 sec\n",
      "\n",
      "Epoch 674 Batch 0 Loss 0.0176\n",
      "Epoch 674 Loss 0.0176\n",
      "Time taken for 1 epoch 0.14922213554382324 sec\n",
      "\n",
      "Epoch 675 Batch 0 Loss 0.0173\n",
      "Epoch 675 Loss 0.0173\n",
      "Time taken for 1 epoch 0.07046794891357422 sec\n",
      "\n",
      "Epoch 676 Batch 0 Loss 0.0157\n",
      "Epoch 676 Loss 0.0157\n",
      "Time taken for 1 epoch 0.15015220642089844 sec\n",
      "\n",
      "Epoch 677 Batch 0 Loss 0.0154\n",
      "Epoch 677 Loss 0.0154\n",
      "Time taken for 1 epoch 0.07043099403381348 sec\n",
      "\n",
      "Epoch 678 Batch 0 Loss 0.0152\n",
      "Epoch 678 Loss 0.0152\n",
      "Time taken for 1 epoch 0.14995908737182617 sec\n",
      "\n",
      "Epoch 679 Batch 0 Loss 0.0194\n",
      "Epoch 679 Loss 0.0194\n",
      "Time taken for 1 epoch 0.07080602645874023 sec\n",
      "\n",
      "Epoch 680 Batch 0 Loss 0.0202\n",
      "Epoch 680 Loss 0.0202\n",
      "Time taken for 1 epoch 0.15211987495422363 sec\n",
      "\n",
      "Epoch 681 Batch 0 Loss 0.0205\n",
      "Epoch 681 Loss 0.0205\n",
      "Time taken for 1 epoch 0.07129979133605957 sec\n",
      "\n",
      "Epoch 682 Batch 0 Loss 0.0166\n",
      "Epoch 682 Loss 0.0166\n",
      "Time taken for 1 epoch 0.1541600227355957 sec\n",
      "\n",
      "Epoch 683 Batch 0 Loss 0.0187\n",
      "Epoch 683 Loss 0.0187\n",
      "Time taken for 1 epoch 0.07114100456237793 sec\n",
      "\n",
      "Epoch 684 Batch 0 Loss 0.0196\n",
      "Epoch 684 Loss 0.0196\n",
      "Time taken for 1 epoch 0.15055465698242188 sec\n",
      "\n",
      "Epoch 685 Batch 0 Loss 0.0160\n",
      "Epoch 685 Loss 0.0160\n",
      "Time taken for 1 epoch 0.07145977020263672 sec\n",
      "\n",
      "Epoch 686 Batch 0 Loss 0.0151\n",
      "Epoch 686 Loss 0.0151\n",
      "Time taken for 1 epoch 0.15123295783996582 sec\n",
      "\n",
      "Epoch 687 Batch 0 Loss 0.0164\n",
      "Epoch 687 Loss 0.0164\n",
      "Time taken for 1 epoch 0.07041597366333008 sec\n",
      "\n",
      "Epoch 688 Batch 0 Loss 0.0160\n",
      "Epoch 688 Loss 0.0160\n",
      "Time taken for 1 epoch 0.15014004707336426 sec\n",
      "\n",
      "Epoch 689 Batch 0 Loss 0.0163\n",
      "Epoch 689 Loss 0.0163\n",
      "Time taken for 1 epoch 0.07227182388305664 sec\n",
      "\n",
      "Epoch 690 Batch 0 Loss 0.0153\n",
      "Epoch 690 Loss 0.0153\n",
      "Time taken for 1 epoch 0.15054583549499512 sec\n",
      "\n",
      "Epoch 691 Batch 0 Loss 0.0176\n",
      "Epoch 691 Loss 0.0176\n",
      "Time taken for 1 epoch 0.07129979133605957 sec\n",
      "\n",
      "Epoch 692 Batch 0 Loss 0.0158\n",
      "Epoch 692 Loss 0.0158\n",
      "Time taken for 1 epoch 0.15061187744140625 sec\n",
      "\n",
      "Epoch 693 Batch 0 Loss 0.0182\n",
      "Epoch 693 Loss 0.0182\n",
      "Time taken for 1 epoch 0.06969428062438965 sec\n",
      "\n",
      "Epoch 694 Batch 0 Loss 0.0186\n",
      "Epoch 694 Loss 0.0186\n",
      "Time taken for 1 epoch 0.1522672176361084 sec\n",
      "\n",
      "Epoch 695 Batch 0 Loss 0.0175\n",
      "Epoch 695 Loss 0.0175\n",
      "Time taken for 1 epoch 0.07106804847717285 sec\n",
      "\n",
      "Epoch 696 Batch 0 Loss 0.0169\n",
      "Epoch 696 Loss 0.0169\n",
      "Time taken for 1 epoch 0.15024995803833008 sec\n",
      "\n",
      "Epoch 697 Batch 0 Loss 0.0141\n",
      "Epoch 697 Loss 0.0141\n",
      "Time taken for 1 epoch 0.07049989700317383 sec\n",
      "\n",
      "Epoch 698 Batch 0 Loss 0.0156\n",
      "Epoch 698 Loss 0.0156\n",
      "Time taken for 1 epoch 0.15145015716552734 sec\n",
      "\n",
      "Epoch 699 Batch 0 Loss 0.0185\n",
      "Epoch 699 Loss 0.0185\n",
      "Time taken for 1 epoch 0.07068276405334473 sec\n",
      "\n",
      "Epoch 700 Batch 0 Loss 0.0166\n",
      "Epoch 700 Loss 0.0166\n",
      "Time taken for 1 epoch 0.15390491485595703 sec\n",
      "\n",
      "Epoch 701 Batch 0 Loss 0.0140\n",
      "Epoch 701 Loss 0.0140\n",
      "Time taken for 1 epoch 0.07152199745178223 sec\n",
      "\n",
      "Epoch 702 Batch 0 Loss 0.0149\n",
      "Epoch 702 Loss 0.0149\n",
      "Time taken for 1 epoch 0.14899706840515137 sec\n",
      "\n",
      "Epoch 703 Batch 0 Loss 0.0139\n",
      "Epoch 703 Loss 0.0139\n",
      "Time taken for 1 epoch 0.07206988334655762 sec\n",
      "\n",
      "Epoch 704 Batch 0 Loss 0.0149\n",
      "Epoch 704 Loss 0.0149\n",
      "Time taken for 1 epoch 0.15161800384521484 sec\n",
      "\n",
      "Epoch 705 Batch 0 Loss 0.0177\n",
      "Epoch 705 Loss 0.0177\n",
      "Time taken for 1 epoch 0.07083702087402344 sec\n",
      "\n",
      "Epoch 706 Batch 0 Loss 0.0168\n",
      "Epoch 706 Loss 0.0168\n",
      "Time taken for 1 epoch 0.15027689933776855 sec\n",
      "\n",
      "Epoch 707 Batch 0 Loss 0.0137\n",
      "Epoch 707 Loss 0.0137\n",
      "Time taken for 1 epoch 0.0707099437713623 sec\n",
      "\n",
      "Epoch 708 Batch 0 Loss 0.0182\n",
      "Epoch 708 Loss 0.0182\n",
      "Time taken for 1 epoch 0.15025687217712402 sec\n",
      "\n",
      "Epoch 709 Batch 0 Loss 0.0143\n",
      "Epoch 709 Loss 0.0143\n",
      "Time taken for 1 epoch 0.07091784477233887 sec\n",
      "\n",
      "Epoch 710 Batch 0 Loss 0.0161\n",
      "Epoch 710 Loss 0.0161\n",
      "Time taken for 1 epoch 0.1504199504852295 sec\n",
      "\n",
      "Epoch 711 Batch 0 Loss 0.0144\n",
      "Epoch 711 Loss 0.0144\n",
      "Time taken for 1 epoch 0.0714101791381836 sec\n",
      "\n",
      "Epoch 712 Batch 0 Loss 0.0152\n",
      "Epoch 712 Loss 0.0152\n",
      "Time taken for 1 epoch 0.15216302871704102 sec\n",
      "\n",
      "Epoch 713 Batch 0 Loss 0.0154\n",
      "Epoch 713 Loss 0.0154\n",
      "Time taken for 1 epoch 0.07065916061401367 sec\n",
      "\n",
      "Epoch 714 Batch 0 Loss 0.0165\n",
      "Epoch 714 Loss 0.0165\n",
      "Time taken for 1 epoch 0.15369224548339844 sec\n",
      "\n",
      "Epoch 715 Batch 0 Loss 0.0157\n",
      "Epoch 715 Loss 0.0157\n",
      "Time taken for 1 epoch 0.0701901912689209 sec\n",
      "\n",
      "Epoch 716 Batch 0 Loss 0.0151\n",
      "Epoch 716 Loss 0.0151\n",
      "Time taken for 1 epoch 0.15238118171691895 sec\n",
      "\n",
      "Epoch 717 Batch 0 Loss 0.0148\n",
      "Epoch 717 Loss 0.0148\n",
      "Time taken for 1 epoch 0.07190203666687012 sec\n",
      "\n",
      "Epoch 718 Batch 0 Loss 0.0143\n",
      "Epoch 718 Loss 0.0143\n",
      "Time taken for 1 epoch 0.1500711441040039 sec\n",
      "\n",
      "Epoch 719 Batch 0 Loss 0.0157\n",
      "Epoch 719 Loss 0.0157\n",
      "Time taken for 1 epoch 0.0719609260559082 sec\n",
      "\n",
      "Epoch 720 Batch 0 Loss 0.0148\n",
      "Epoch 720 Loss 0.0148\n",
      "Time taken for 1 epoch 0.15142297744750977 sec\n",
      "\n",
      "Epoch 721 Batch 0 Loss 0.0159\n",
      "Epoch 721 Loss 0.0159\n",
      "Time taken for 1 epoch 0.07229495048522949 sec\n",
      "\n",
      "Epoch 722 Batch 0 Loss 0.0127\n",
      "Epoch 722 Loss 0.0127\n",
      "Time taken for 1 epoch 0.15001797676086426 sec\n",
      "\n",
      "Epoch 723 Batch 0 Loss 0.0128\n",
      "Epoch 723 Loss 0.0128\n",
      "Time taken for 1 epoch 0.07132792472839355 sec\n",
      "\n",
      "Epoch 724 Batch 0 Loss 0.0130\n",
      "Epoch 724 Loss 0.0130\n",
      "Time taken for 1 epoch 0.15119099617004395 sec\n",
      "\n",
      "Epoch 725 Batch 0 Loss 0.0174\n",
      "Epoch 725 Loss 0.0174\n",
      "Time taken for 1 epoch 0.07503294944763184 sec\n",
      "\n",
      "Epoch 726 Batch 0 Loss 0.0167\n",
      "Epoch 726 Loss 0.0167\n",
      "Time taken for 1 epoch 0.14981985092163086 sec\n",
      "\n",
      "Epoch 727 Batch 0 Loss 0.0144\n",
      "Epoch 727 Loss 0.0144\n",
      "Time taken for 1 epoch 0.07162213325500488 sec\n",
      "\n",
      "Epoch 728 Batch 0 Loss 0.0105\n",
      "Epoch 728 Loss 0.0105\n",
      "Time taken for 1 epoch 0.15378499031066895 sec\n",
      "\n",
      "Epoch 729 Batch 0 Loss 0.0124\n",
      "Epoch 729 Loss 0.0124\n",
      "Time taken for 1 epoch 0.0758059024810791 sec\n",
      "\n",
      "Epoch 730 Batch 0 Loss 0.0104\n",
      "Epoch 730 Loss 0.0104\n",
      "Time taken for 1 epoch 0.15436792373657227 sec\n",
      "\n",
      "Epoch 731 Batch 0 Loss 0.0136\n",
      "Epoch 731 Loss 0.0136\n",
      "Time taken for 1 epoch 0.07156801223754883 sec\n",
      "\n",
      "Epoch 732 Batch 0 Loss 0.0162\n",
      "Epoch 732 Loss 0.0162\n",
      "Time taken for 1 epoch 0.1557610034942627 sec\n",
      "\n",
      "Epoch 733 Batch 0 Loss 0.0181\n",
      "Epoch 733 Loss 0.0181\n",
      "Time taken for 1 epoch 0.07362103462219238 sec\n",
      "\n",
      "Epoch 734 Batch 0 Loss 0.0121\n",
      "Epoch 734 Loss 0.0121\n",
      "Time taken for 1 epoch 0.15733790397644043 sec\n",
      "\n",
      "Epoch 735 Batch 0 Loss 0.0163\n",
      "Epoch 735 Loss 0.0163\n",
      "Time taken for 1 epoch 0.07749390602111816 sec\n",
      "\n",
      "Epoch 736 Batch 0 Loss 0.0153\n",
      "Epoch 736 Loss 0.0153\n",
      "Time taken for 1 epoch 0.16642999649047852 sec\n",
      "\n",
      "Epoch 737 Batch 0 Loss 0.0176\n",
      "Epoch 737 Loss 0.0176\n",
      "Time taken for 1 epoch 0.08393406867980957 sec\n",
      "\n",
      "Epoch 738 Batch 0 Loss 0.0159\n",
      "Epoch 738 Loss 0.0159\n",
      "Time taken for 1 epoch 0.2471001148223877 sec\n",
      "\n",
      "Epoch 739 Batch 0 Loss 0.0136\n",
      "Epoch 739 Loss 0.0136\n",
      "Time taken for 1 epoch 0.10759496688842773 sec\n",
      "\n",
      "Epoch 740 Batch 0 Loss 0.0152\n",
      "Epoch 740 Loss 0.0152\n",
      "Time taken for 1 epoch 0.1932849884033203 sec\n",
      "\n",
      "Epoch 741 Batch 0 Loss 0.0168\n",
      "Epoch 741 Loss 0.0168\n",
      "Time taken for 1 epoch 0.08976221084594727 sec\n",
      "\n",
      "Epoch 742 Batch 0 Loss 0.0155\n",
      "Epoch 742 Loss 0.0155\n",
      "Time taken for 1 epoch 0.20366406440734863 sec\n",
      "\n",
      "Epoch 743 Batch 0 Loss 0.0122\n",
      "Epoch 743 Loss 0.0122\n",
      "Time taken for 1 epoch 0.08339524269104004 sec\n",
      "\n",
      "Epoch 744 Batch 0 Loss 0.0146\n",
      "Epoch 744 Loss 0.0146\n",
      "Time taken for 1 epoch 0.42458105087280273 sec\n",
      "\n",
      "Epoch 745 Batch 0 Loss 0.0156\n",
      "Epoch 745 Loss 0.0156\n",
      "Time taken for 1 epoch 0.07043814659118652 sec\n",
      "\n",
      "Epoch 746 Batch 0 Loss 0.0164\n",
      "Epoch 746 Loss 0.0164\n",
      "Time taken for 1 epoch 0.15274286270141602 sec\n",
      "\n",
      "Epoch 747 Batch 0 Loss 0.0137\n",
      "Epoch 747 Loss 0.0137\n",
      "Time taken for 1 epoch 0.07221102714538574 sec\n",
      "\n",
      "Epoch 748 Batch 0 Loss 0.0153\n",
      "Epoch 748 Loss 0.0153\n",
      "Time taken for 1 epoch 0.15061378479003906 sec\n",
      "\n",
      "Epoch 749 Batch 0 Loss 0.0144\n",
      "Epoch 749 Loss 0.0144\n",
      "Time taken for 1 epoch 0.0740208625793457 sec\n",
      "\n",
      "Epoch 750 Batch 0 Loss 0.0137\n",
      "Epoch 750 Loss 0.0137\n",
      "Time taken for 1 epoch 0.15195989608764648 sec\n",
      "\n",
      "Epoch 751 Batch 0 Loss 0.0139\n",
      "Epoch 751 Loss 0.0139\n",
      "Time taken for 1 epoch 0.07140111923217773 sec\n",
      "\n",
      "Epoch 752 Batch 0 Loss 0.0142\n",
      "Epoch 752 Loss 0.0142\n",
      "Time taken for 1 epoch 0.1514272689819336 sec\n",
      "\n",
      "Epoch 753 Batch 0 Loss 0.0141\n",
      "Epoch 753 Loss 0.0141\n",
      "Time taken for 1 epoch 0.07148909568786621 sec\n",
      "\n",
      "Epoch 754 Batch 0 Loss 0.0160\n",
      "Epoch 754 Loss 0.0160\n",
      "Time taken for 1 epoch 0.15339016914367676 sec\n",
      "\n",
      "Epoch 755 Batch 0 Loss 0.0128\n",
      "Epoch 755 Loss 0.0128\n",
      "Time taken for 1 epoch 0.07201886177062988 sec\n",
      "\n",
      "Epoch 756 Batch 0 Loss 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 756 Loss 0.0155\n",
      "Time taken for 1 epoch 0.15108299255371094 sec\n",
      "\n",
      "Epoch 757 Batch 0 Loss 0.0150\n",
      "Epoch 757 Loss 0.0150\n",
      "Time taken for 1 epoch 0.07419204711914062 sec\n",
      "\n",
      "Epoch 758 Batch 0 Loss 0.0109\n",
      "Epoch 758 Loss 0.0109\n",
      "Time taken for 1 epoch 0.15004587173461914 sec\n",
      "\n",
      "Epoch 759 Batch 0 Loss 0.0146\n",
      "Epoch 759 Loss 0.0146\n",
      "Time taken for 1 epoch 0.0713498592376709 sec\n",
      "\n",
      "Epoch 760 Batch 0 Loss 0.0112\n",
      "Epoch 760 Loss 0.0112\n",
      "Time taken for 1 epoch 0.15061593055725098 sec\n",
      "\n",
      "Epoch 761 Batch 0 Loss 0.0123\n",
      "Epoch 761 Loss 0.0123\n",
      "Time taken for 1 epoch 0.07236981391906738 sec\n",
      "\n",
      "Epoch 762 Batch 0 Loss 0.0120\n",
      "Epoch 762 Loss 0.0120\n",
      "Time taken for 1 epoch 0.15028905868530273 sec\n",
      "\n",
      "Epoch 763 Batch 0 Loss 0.0133\n",
      "Epoch 763 Loss 0.0133\n",
      "Time taken for 1 epoch 0.07136416435241699 sec\n",
      "\n",
      "Epoch 764 Batch 0 Loss 0.0118\n",
      "Epoch 764 Loss 0.0118\n",
      "Time taken for 1 epoch 0.15413594245910645 sec\n",
      "\n",
      "Epoch 765 Batch 0 Loss 0.0140\n",
      "Epoch 765 Loss 0.0140\n",
      "Time taken for 1 epoch 0.0710608959197998 sec\n",
      "\n",
      "Epoch 766 Batch 0 Loss 0.0118\n",
      "Epoch 766 Loss 0.0118\n",
      "Time taken for 1 epoch 0.15365004539489746 sec\n",
      "\n",
      "Epoch 767 Batch 0 Loss 0.0143\n",
      "Epoch 767 Loss 0.0143\n",
      "Time taken for 1 epoch 0.07206082344055176 sec\n",
      "\n",
      "Epoch 768 Batch 0 Loss 0.0134\n",
      "Epoch 768 Loss 0.0134\n",
      "Time taken for 1 epoch 0.15317416191101074 sec\n",
      "\n",
      "Epoch 769 Batch 0 Loss 0.0148\n",
      "Epoch 769 Loss 0.0148\n",
      "Time taken for 1 epoch 0.07247710227966309 sec\n",
      "\n",
      "Epoch 770 Batch 0 Loss 0.0157\n",
      "Epoch 770 Loss 0.0157\n",
      "Time taken for 1 epoch 0.1531660556793213 sec\n",
      "\n",
      "Epoch 771 Batch 0 Loss 0.0138\n",
      "Epoch 771 Loss 0.0138\n",
      "Time taken for 1 epoch 0.07127904891967773 sec\n",
      "\n",
      "Epoch 772 Batch 0 Loss 0.0134\n",
      "Epoch 772 Loss 0.0134\n",
      "Time taken for 1 epoch 0.15268802642822266 sec\n",
      "\n",
      "Epoch 773 Batch 0 Loss 0.0138\n",
      "Epoch 773 Loss 0.0138\n",
      "Time taken for 1 epoch 0.07016396522521973 sec\n",
      "\n",
      "Epoch 774 Batch 0 Loss 0.0151\n",
      "Epoch 774 Loss 0.0151\n",
      "Time taken for 1 epoch 0.15192389488220215 sec\n",
      "\n",
      "Epoch 775 Batch 0 Loss 0.0139\n",
      "Epoch 775 Loss 0.0139\n",
      "Time taken for 1 epoch 0.07220816612243652 sec\n",
      "\n",
      "Epoch 776 Batch 0 Loss 0.0123\n",
      "Epoch 776 Loss 0.0123\n",
      "Time taken for 1 epoch 0.15313506126403809 sec\n",
      "\n",
      "Epoch 777 Batch 0 Loss 0.0142\n",
      "Epoch 777 Loss 0.0142\n",
      "Time taken for 1 epoch 0.07420015335083008 sec\n",
      "\n",
      "Epoch 778 Batch 0 Loss 0.0119\n",
      "Epoch 778 Loss 0.0119\n",
      "Time taken for 1 epoch 0.15029501914978027 sec\n",
      "\n",
      "Epoch 779 Batch 0 Loss 0.0104\n",
      "Epoch 779 Loss 0.0104\n",
      "Time taken for 1 epoch 0.07246589660644531 sec\n",
      "\n",
      "Epoch 780 Batch 0 Loss 0.0151\n",
      "Epoch 780 Loss 0.0151\n",
      "Time taken for 1 epoch 0.14987587928771973 sec\n",
      "\n",
      "Epoch 781 Batch 0 Loss 0.0140\n",
      "Epoch 781 Loss 0.0140\n",
      "Time taken for 1 epoch 0.0712730884552002 sec\n",
      "\n",
      "Epoch 782 Batch 0 Loss 0.0121\n",
      "Epoch 782 Loss 0.0121\n",
      "Time taken for 1 epoch 0.1513051986694336 sec\n",
      "\n",
      "Epoch 783 Batch 0 Loss 0.0148\n",
      "Epoch 783 Loss 0.0148\n",
      "Time taken for 1 epoch 0.07062506675720215 sec\n",
      "\n",
      "Epoch 784 Batch 0 Loss 0.0127\n",
      "Epoch 784 Loss 0.0127\n",
      "Time taken for 1 epoch 0.1489579677581787 sec\n",
      "\n",
      "Epoch 785 Batch 0 Loss 0.0124\n",
      "Epoch 785 Loss 0.0124\n",
      "Time taken for 1 epoch 0.07051372528076172 sec\n",
      "\n",
      "Epoch 786 Batch 0 Loss 0.0123\n",
      "Epoch 786 Loss 0.0123\n",
      "Time taken for 1 epoch 0.1510910987854004 sec\n",
      "\n",
      "Epoch 787 Batch 0 Loss 0.0129\n",
      "Epoch 787 Loss 0.0129\n",
      "Time taken for 1 epoch 0.07396697998046875 sec\n",
      "\n",
      "Epoch 788 Batch 0 Loss 0.0113\n",
      "Epoch 788 Loss 0.0113\n",
      "Time taken for 1 epoch 0.15917205810546875 sec\n",
      "\n",
      "Epoch 789 Batch 0 Loss 0.0117\n",
      "Epoch 789 Loss 0.0117\n",
      "Time taken for 1 epoch 0.07482695579528809 sec\n",
      "\n",
      "Epoch 790 Batch 0 Loss 0.0098\n",
      "Epoch 790 Loss 0.0098\n",
      "Time taken for 1 epoch 0.16068482398986816 sec\n",
      "\n",
      "Epoch 791 Batch 0 Loss 0.0154\n",
      "Epoch 791 Loss 0.0154\n",
      "Time taken for 1 epoch 0.0753939151763916 sec\n",
      "\n",
      "Epoch 792 Batch 0 Loss 0.0099\n",
      "Epoch 792 Loss 0.0099\n",
      "Time taken for 1 epoch 0.15728211402893066 sec\n",
      "\n",
      "Epoch 793 Batch 0 Loss 0.0158\n",
      "Epoch 793 Loss 0.0158\n",
      "Time taken for 1 epoch 0.09142208099365234 sec\n",
      "\n",
      "Epoch 794 Batch 0 Loss 0.0153\n",
      "Epoch 794 Loss 0.0153\n",
      "Time taken for 1 epoch 0.15823984146118164 sec\n",
      "\n",
      "Epoch 795 Batch 0 Loss 0.0132\n",
      "Epoch 795 Loss 0.0132\n",
      "Time taken for 1 epoch 0.07555818557739258 sec\n",
      "\n",
      "Epoch 796 Batch 0 Loss 0.0125\n",
      "Epoch 796 Loss 0.0125\n",
      "Time taken for 1 epoch 0.16301298141479492 sec\n",
      "\n",
      "Epoch 797 Batch 0 Loss 0.0125\n",
      "Epoch 797 Loss 0.0125\n",
      "Time taken for 1 epoch 0.07340121269226074 sec\n",
      "\n",
      "Epoch 798 Batch 0 Loss 0.0112\n",
      "Epoch 798 Loss 0.0112\n",
      "Time taken for 1 epoch 0.15794730186462402 sec\n",
      "\n",
      "Epoch 799 Batch 0 Loss 0.0136\n",
      "Epoch 799 Loss 0.0136\n",
      "Time taken for 1 epoch 0.07218623161315918 sec\n",
      "\n",
      "Epoch 800 Batch 0 Loss 0.0110\n",
      "Epoch 800 Loss 0.0110\n",
      "Time taken for 1 epoch 0.15299320220947266 sec\n",
      "\n",
      "Epoch 801 Batch 0 Loss 0.0119\n",
      "Epoch 801 Loss 0.0119\n",
      "Time taken for 1 epoch 0.071990966796875 sec\n",
      "\n",
      "Epoch 802 Batch 0 Loss 0.0118\n",
      "Epoch 802 Loss 0.0118\n",
      "Time taken for 1 epoch 0.15298891067504883 sec\n",
      "\n",
      "Epoch 803 Batch 0 Loss 0.0125\n",
      "Epoch 803 Loss 0.0125\n",
      "Time taken for 1 epoch 0.07067322731018066 sec\n",
      "\n",
      "Epoch 804 Batch 0 Loss 0.0118\n",
      "Epoch 804 Loss 0.0118\n",
      "Time taken for 1 epoch 0.15537405014038086 sec\n",
      "\n",
      "Epoch 805 Batch 0 Loss 0.0122\n",
      "Epoch 805 Loss 0.0122\n",
      "Time taken for 1 epoch 0.07444000244140625 sec\n",
      "\n",
      "Epoch 806 Batch 0 Loss 0.0124\n",
      "Epoch 806 Loss 0.0124\n",
      "Time taken for 1 epoch 0.15859508514404297 sec\n",
      "\n",
      "Epoch 807 Batch 0 Loss 0.0111\n",
      "Epoch 807 Loss 0.0111\n",
      "Time taken for 1 epoch 0.07268142700195312 sec\n",
      "\n",
      "Epoch 808 Batch 0 Loss 0.0137\n",
      "Epoch 808 Loss 0.0137\n",
      "Time taken for 1 epoch 0.15550017356872559 sec\n",
      "\n",
      "Epoch 809 Batch 0 Loss 0.0130\n",
      "Epoch 809 Loss 0.0130\n",
      "Time taken for 1 epoch 0.07296323776245117 sec\n",
      "\n",
      "Epoch 810 Batch 0 Loss 0.0140\n",
      "Epoch 810 Loss 0.0140\n",
      "Time taken for 1 epoch 0.1568460464477539 sec\n",
      "\n",
      "Epoch 811 Batch 0 Loss 0.0153\n",
      "Epoch 811 Loss 0.0153\n",
      "Time taken for 1 epoch 0.07448792457580566 sec\n",
      "\n",
      "Epoch 812 Batch 0 Loss 0.0126\n",
      "Epoch 812 Loss 0.0126\n",
      "Time taken for 1 epoch 0.15454387664794922 sec\n",
      "\n",
      "Epoch 813 Batch 0 Loss 0.0107\n",
      "Epoch 813 Loss 0.0107\n",
      "Time taken for 1 epoch 0.07231903076171875 sec\n",
      "\n",
      "Epoch 814 Batch 0 Loss 0.0152\n",
      "Epoch 814 Loss 0.0152\n",
      "Time taken for 1 epoch 0.1523740291595459 sec\n",
      "\n",
      "Epoch 815 Batch 0 Loss 0.0128\n",
      "Epoch 815 Loss 0.0128\n",
      "Time taken for 1 epoch 0.07199597358703613 sec\n",
      "\n",
      "Epoch 816 Batch 0 Loss 0.0109\n",
      "Epoch 816 Loss 0.0109\n",
      "Time taken for 1 epoch 0.15673208236694336 sec\n",
      "\n",
      "Epoch 817 Batch 0 Loss 0.0151\n",
      "Epoch 817 Loss 0.0151\n",
      "Time taken for 1 epoch 0.07331085205078125 sec\n",
      "\n",
      "Epoch 818 Batch 0 Loss 0.0127\n",
      "Epoch 818 Loss 0.0127\n",
      "Time taken for 1 epoch 0.17237091064453125 sec\n",
      "\n",
      "Epoch 819 Batch 0 Loss 0.0132\n",
      "Epoch 819 Loss 0.0132\n",
      "Time taken for 1 epoch 0.09555935859680176 sec\n",
      "\n",
      "Epoch 820 Batch 0 Loss 0.0149\n",
      "Epoch 820 Loss 0.0149\n",
      "Time taken for 1 epoch 0.20212888717651367 sec\n",
      "\n",
      "Epoch 821 Batch 0 Loss 0.0124\n",
      "Epoch 821 Loss 0.0124\n",
      "Time taken for 1 epoch 0.15779376029968262 sec\n",
      "\n",
      "Epoch 822 Batch 0 Loss 0.0115\n",
      "Epoch 822 Loss 0.0115\n",
      "Time taken for 1 epoch 0.2941122055053711 sec\n",
      "\n",
      "Epoch 823 Batch 0 Loss 0.0113\n",
      "Epoch 823 Loss 0.0113\n",
      "Time taken for 1 epoch 0.1295621395111084 sec\n",
      "\n",
      "Epoch 824 Batch 0 Loss 0.0102\n",
      "Epoch 824 Loss 0.0102\n",
      "Time taken for 1 epoch 0.24929285049438477 sec\n",
      "\n",
      "Epoch 825 Batch 0 Loss 0.0133\n",
      "Epoch 825 Loss 0.0133\n",
      "Time taken for 1 epoch 0.12037992477416992 sec\n",
      "\n",
      "Epoch 826 Batch 0 Loss 0.0111\n",
      "Epoch 826 Loss 0.0111\n",
      "Time taken for 1 epoch 0.239091157913208 sec\n",
      "\n",
      "Epoch 827 Batch 0 Loss 0.0111\n",
      "Epoch 827 Loss 0.0111\n",
      "Time taken for 1 epoch 0.08994197845458984 sec\n",
      "\n",
      "Epoch 828 Batch 0 Loss 0.0116\n",
      "Epoch 828 Loss 0.0116\n",
      "Time taken for 1 epoch 0.20729804039001465 sec\n",
      "\n",
      "Epoch 829 Batch 0 Loss 0.0088\n",
      "Epoch 829 Loss 0.0088\n",
      "Time taken for 1 epoch 0.10043501853942871 sec\n",
      "\n",
      "Epoch 830 Batch 0 Loss 0.0130\n",
      "Epoch 830 Loss 0.0130\n",
      "Time taken for 1 epoch 0.2109999656677246 sec\n",
      "\n",
      "Epoch 831 Batch 0 Loss 0.0117\n",
      "Epoch 831 Loss 0.0117\n",
      "Time taken for 1 epoch 0.10237503051757812 sec\n",
      "\n",
      "Epoch 832 Batch 0 Loss 0.0139\n",
      "Epoch 832 Loss 0.0139\n",
      "Time taken for 1 epoch 0.2388920783996582 sec\n",
      "\n",
      "Epoch 833 Batch 0 Loss 0.0123\n",
      "Epoch 833 Loss 0.0123\n",
      "Time taken for 1 epoch 0.0894620418548584 sec\n",
      "\n",
      "Epoch 834 Batch 0 Loss 0.0091\n",
      "Epoch 834 Loss 0.0091\n",
      "Time taken for 1 epoch 0.16167688369750977 sec\n",
      "\n",
      "Epoch 835 Batch 0 Loss 0.0106\n",
      "Epoch 835 Loss 0.0106\n",
      "Time taken for 1 epoch 0.07468008995056152 sec\n",
      "\n",
      "Epoch 836 Batch 0 Loss 0.0096\n",
      "Epoch 836 Loss 0.0096\n",
      "Time taken for 1 epoch 0.1524062156677246 sec\n",
      "\n",
      "Epoch 837 Batch 0 Loss 0.0130\n",
      "Epoch 837 Loss 0.0130\n",
      "Time taken for 1 epoch 0.07157301902770996 sec\n",
      "\n",
      "Epoch 838 Batch 0 Loss 0.0128\n",
      "Epoch 838 Loss 0.0128\n",
      "Time taken for 1 epoch 0.15570402145385742 sec\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839 Batch 0 Loss 0.0105\n",
      "Epoch 839 Loss 0.0105\n",
      "Time taken for 1 epoch 0.07169389724731445 sec\n",
      "\n",
      "Epoch 840 Batch 0 Loss 0.0122\n",
      "Epoch 840 Loss 0.0122\n",
      "Time taken for 1 epoch 0.15364408493041992 sec\n",
      "\n",
      "Epoch 841 Batch 0 Loss 0.0091\n",
      "Epoch 841 Loss 0.0091\n",
      "Time taken for 1 epoch 0.07257795333862305 sec\n",
      "\n",
      "Epoch 842 Batch 0 Loss 0.0115\n",
      "Epoch 842 Loss 0.0115\n",
      "Time taken for 1 epoch 0.15463805198669434 sec\n",
      "\n",
      "Epoch 843 Batch 0 Loss 0.0138\n",
      "Epoch 843 Loss 0.0138\n",
      "Time taken for 1 epoch 0.07201385498046875 sec\n",
      "\n",
      "Epoch 844 Batch 0 Loss 0.0126\n",
      "Epoch 844 Loss 0.0126\n",
      "Time taken for 1 epoch 0.15090370178222656 sec\n",
      "\n",
      "Epoch 845 Batch 0 Loss 0.0112\n",
      "Epoch 845 Loss 0.0112\n",
      "Time taken for 1 epoch 0.07092714309692383 sec\n",
      "\n",
      "Epoch 846 Batch 0 Loss 0.0112\n",
      "Epoch 846 Loss 0.0112\n",
      "Time taken for 1 epoch 0.1507279872894287 sec\n",
      "\n",
      "Epoch 847 Batch 0 Loss 0.0125\n",
      "Epoch 847 Loss 0.0125\n",
      "Time taken for 1 epoch 0.07429885864257812 sec\n",
      "\n",
      "Epoch 848 Batch 0 Loss 0.0115\n",
      "Epoch 848 Loss 0.0115\n",
      "Time taken for 1 epoch 0.1527407169342041 sec\n",
      "\n",
      "Epoch 849 Batch 0 Loss 0.0086\n",
      "Epoch 849 Loss 0.0086\n",
      "Time taken for 1 epoch 0.07007193565368652 sec\n",
      "\n",
      "Epoch 850 Batch 0 Loss 0.0088\n",
      "Epoch 850 Loss 0.0088\n",
      "Time taken for 1 epoch 0.15146589279174805 sec\n",
      "\n",
      "Epoch 851 Batch 0 Loss 0.0107\n",
      "Epoch 851 Loss 0.0107\n",
      "Time taken for 1 epoch 0.07072901725769043 sec\n",
      "\n",
      "Epoch 852 Batch 0 Loss 0.0082\n",
      "Epoch 852 Loss 0.0082\n",
      "Time taken for 1 epoch 0.15446996688842773 sec\n",
      "\n",
      "Epoch 853 Batch 0 Loss 0.0110\n",
      "Epoch 853 Loss 0.0110\n",
      "Time taken for 1 epoch 0.07231998443603516 sec\n",
      "\n",
      "Epoch 854 Batch 0 Loss 0.0108\n",
      "Epoch 854 Loss 0.0108\n",
      "Time taken for 1 epoch 0.15245795249938965 sec\n",
      "\n",
      "Epoch 855 Batch 0 Loss 0.0142\n",
      "Epoch 855 Loss 0.0142\n",
      "Time taken for 1 epoch 0.07192611694335938 sec\n",
      "\n",
      "Epoch 856 Batch 0 Loss 0.0116\n",
      "Epoch 856 Loss 0.0116\n",
      "Time taken for 1 epoch 0.15027213096618652 sec\n",
      "\n",
      "Epoch 857 Batch 0 Loss 0.0131\n",
      "Epoch 857 Loss 0.0131\n",
      "Time taken for 1 epoch 0.07571601867675781 sec\n",
      "\n",
      "Epoch 858 Batch 0 Loss 0.0146\n",
      "Epoch 858 Loss 0.0146\n",
      "Time taken for 1 epoch 0.15143680572509766 sec\n",
      "\n",
      "Epoch 859 Batch 0 Loss 0.0096\n",
      "Epoch 859 Loss 0.0096\n",
      "Time taken for 1 epoch 0.07184004783630371 sec\n",
      "\n",
      "Epoch 860 Batch 0 Loss 0.0123\n",
      "Epoch 860 Loss 0.0123\n",
      "Time taken for 1 epoch 0.15668797492980957 sec\n",
      "\n",
      "Epoch 861 Batch 0 Loss 0.0098\n",
      "Epoch 861 Loss 0.0098\n",
      "Time taken for 1 epoch 0.0767660140991211 sec\n",
      "\n",
      "Epoch 862 Batch 0 Loss 0.0118\n",
      "Epoch 862 Loss 0.0118\n",
      "Time taken for 1 epoch 0.15131282806396484 sec\n",
      "\n",
      "Epoch 863 Batch 0 Loss 0.0126\n",
      "Epoch 863 Loss 0.0126\n",
      "Time taken for 1 epoch 0.07191705703735352 sec\n",
      "\n",
      "Epoch 864 Batch 0 Loss 0.0125\n",
      "Epoch 864 Loss 0.0125\n",
      "Time taken for 1 epoch 0.15502214431762695 sec\n",
      "\n",
      "Epoch 865 Batch 0 Loss 0.0121\n",
      "Epoch 865 Loss 0.0121\n",
      "Time taken for 1 epoch 0.07362890243530273 sec\n",
      "\n",
      "Epoch 866 Batch 0 Loss 0.0122\n",
      "Epoch 866 Loss 0.0122\n",
      "Time taken for 1 epoch 0.15332984924316406 sec\n",
      "\n",
      "Epoch 867 Batch 0 Loss 0.0091\n",
      "Epoch 867 Loss 0.0091\n",
      "Time taken for 1 epoch 0.07460570335388184 sec\n",
      "\n",
      "Epoch 868 Batch 0 Loss 0.0124\n",
      "Epoch 868 Loss 0.0124\n",
      "Time taken for 1 epoch 0.15112996101379395 sec\n",
      "\n",
      "Epoch 869 Batch 0 Loss 0.0104\n",
      "Epoch 869 Loss 0.0104\n",
      "Time taken for 1 epoch 0.0731961727142334 sec\n",
      "\n",
      "Epoch 870 Batch 0 Loss 0.0121\n",
      "Epoch 870 Loss 0.0121\n",
      "Time taken for 1 epoch 0.14895105361938477 sec\n",
      "\n",
      "Epoch 871 Batch 0 Loss 0.0096\n",
      "Epoch 871 Loss 0.0096\n",
      "Time taken for 1 epoch 0.06948685646057129 sec\n",
      "\n",
      "Epoch 872 Batch 0 Loss 0.0089\n",
      "Epoch 872 Loss 0.0089\n",
      "Time taken for 1 epoch 0.1492469310760498 sec\n",
      "\n",
      "Epoch 873 Batch 0 Loss 0.0102\n",
      "Epoch 873 Loss 0.0102\n",
      "Time taken for 1 epoch 0.0720970630645752 sec\n",
      "\n",
      "Epoch 874 Batch 0 Loss 0.0086\n",
      "Epoch 874 Loss 0.0086\n",
      "Time taken for 1 epoch 0.14907407760620117 sec\n",
      "\n",
      "Epoch 875 Batch 0 Loss 0.0143\n",
      "Epoch 875 Loss 0.0143\n",
      "Time taken for 1 epoch 0.07281112670898438 sec\n",
      "\n",
      "Epoch 876 Batch 0 Loss 0.0078\n",
      "Epoch 876 Loss 0.0078\n",
      "Time taken for 1 epoch 0.15270090103149414 sec\n",
      "\n",
      "Epoch 877 Batch 0 Loss 0.0083\n",
      "Epoch 877 Loss 0.0083\n",
      "Time taken for 1 epoch 0.07613778114318848 sec\n",
      "\n",
      "Epoch 878 Batch 0 Loss 0.0118\n",
      "Epoch 878 Loss 0.0118\n",
      "Time taken for 1 epoch 0.15769124031066895 sec\n",
      "\n",
      "Epoch 879 Batch 0 Loss 0.0080\n",
      "Epoch 879 Loss 0.0080\n",
      "Time taken for 1 epoch 0.07572197914123535 sec\n",
      "\n",
      "Epoch 880 Batch 0 Loss 0.0101\n",
      "Epoch 880 Loss 0.0101\n",
      "Time taken for 1 epoch 0.16269278526306152 sec\n",
      "\n",
      "Epoch 881 Batch 0 Loss 0.0117\n",
      "Epoch 881 Loss 0.0117\n",
      "Time taken for 1 epoch 0.07640504837036133 sec\n",
      "\n",
      "Epoch 882 Batch 0 Loss 0.0119\n",
      "Epoch 882 Loss 0.0119\n",
      "Time taken for 1 epoch 0.15499424934387207 sec\n",
      "\n",
      "Epoch 883 Batch 0 Loss 0.0109\n",
      "Epoch 883 Loss 0.0109\n",
      "Time taken for 1 epoch 0.07664203643798828 sec\n",
      "\n",
      "Epoch 884 Batch 0 Loss 0.0081\n",
      "Epoch 884 Loss 0.0081\n",
      "Time taken for 1 epoch 0.1539478302001953 sec\n",
      "\n",
      "Epoch 885 Batch 0 Loss 0.0110\n",
      "Epoch 885 Loss 0.0110\n",
      "Time taken for 1 epoch 0.07154607772827148 sec\n",
      "\n",
      "Epoch 886 Batch 0 Loss 0.0104\n",
      "Epoch 886 Loss 0.0104\n",
      "Time taken for 1 epoch 0.15482211112976074 sec\n",
      "\n",
      "Epoch 887 Batch 0 Loss 0.0081\n",
      "Epoch 887 Loss 0.0081\n",
      "Time taken for 1 epoch 0.07531213760375977 sec\n",
      "\n",
      "Epoch 888 Batch 0 Loss 0.0106\n",
      "Epoch 888 Loss 0.0106\n",
      "Time taken for 1 epoch 0.15101194381713867 sec\n",
      "\n",
      "Epoch 889 Batch 0 Loss 0.0086\n",
      "Epoch 889 Loss 0.0086\n",
      "Time taken for 1 epoch 0.07345914840698242 sec\n",
      "\n",
      "Epoch 890 Batch 0 Loss 0.0095\n",
      "Epoch 890 Loss 0.0095\n",
      "Time taken for 1 epoch 0.16028213500976562 sec\n",
      "\n",
      "Epoch 891 Batch 0 Loss 0.0116\n",
      "Epoch 891 Loss 0.0116\n",
      "Time taken for 1 epoch 0.0748591423034668 sec\n",
      "\n",
      "Epoch 892 Batch 0 Loss 0.0100\n",
      "Epoch 892 Loss 0.0100\n",
      "Time taken for 1 epoch 0.1549220085144043 sec\n",
      "\n",
      "Epoch 893 Batch 0 Loss 0.0111\n",
      "Epoch 893 Loss 0.0111\n",
      "Time taken for 1 epoch 0.07251095771789551 sec\n",
      "\n",
      "Epoch 894 Batch 0 Loss 0.0126\n",
      "Epoch 894 Loss 0.0126\n",
      "Time taken for 1 epoch 0.15483617782592773 sec\n",
      "\n",
      "Epoch 895 Batch 0 Loss 0.0105\n",
      "Epoch 895 Loss 0.0105\n",
      "Time taken for 1 epoch 0.07157707214355469 sec\n",
      "\n",
      "Epoch 896 Batch 0 Loss 0.0119\n",
      "Epoch 896 Loss 0.0119\n",
      "Time taken for 1 epoch 0.15594267845153809 sec\n",
      "\n",
      "Epoch 897 Batch 0 Loss 0.0121\n",
      "Epoch 897 Loss 0.0121\n",
      "Time taken for 1 epoch 0.0756080150604248 sec\n",
      "\n",
      "Epoch 898 Batch 0 Loss 0.0141\n",
      "Epoch 898 Loss 0.0141\n",
      "Time taken for 1 epoch 0.15096306800842285 sec\n",
      "\n",
      "Epoch 899 Batch 0 Loss 0.0102\n",
      "Epoch 899 Loss 0.0102\n",
      "Time taken for 1 epoch 0.0757451057434082 sec\n",
      "\n",
      "Epoch 900 Batch 0 Loss 0.0094\n",
      "Epoch 900 Loss 0.0094\n",
      "Time taken for 1 epoch 0.15405488014221191 sec\n",
      "\n",
      "Epoch 901 Batch 0 Loss 0.0106\n",
      "Epoch 901 Loss 0.0106\n",
      "Time taken for 1 epoch 0.07960224151611328 sec\n",
      "\n",
      "Epoch 902 Batch 0 Loss 0.0122\n",
      "Epoch 902 Loss 0.0122\n",
      "Time taken for 1 epoch 0.16118717193603516 sec\n",
      "\n",
      "Epoch 903 Batch 0 Loss 0.0115\n",
      "Epoch 903 Loss 0.0115\n",
      "Time taken for 1 epoch 0.07806015014648438 sec\n",
      "\n",
      "Epoch 904 Batch 0 Loss 0.0114\n",
      "Epoch 904 Loss 0.0114\n",
      "Time taken for 1 epoch 0.15743279457092285 sec\n",
      "\n",
      "Epoch 905 Batch 0 Loss 0.0105\n",
      "Epoch 905 Loss 0.0105\n",
      "Time taken for 1 epoch 0.07703399658203125 sec\n",
      "\n",
      "Epoch 906 Batch 0 Loss 0.0104\n",
      "Epoch 906 Loss 0.0104\n",
      "Time taken for 1 epoch 0.18441486358642578 sec\n",
      "\n",
      "Epoch 907 Batch 0 Loss 0.0107\n",
      "Epoch 907 Loss 0.0107\n",
      "Time taken for 1 epoch 0.08553910255432129 sec\n",
      "\n",
      "Epoch 908 Batch 0 Loss 0.0115\n",
      "Epoch 908 Loss 0.0115\n",
      "Time taken for 1 epoch 0.2376880645751953 sec\n",
      "\n",
      "Epoch 909 Batch 0 Loss 0.0105\n",
      "Epoch 909 Loss 0.0105\n",
      "Time taken for 1 epoch 0.12616991996765137 sec\n",
      "\n",
      "Epoch 910 Batch 0 Loss 0.0130\n",
      "Epoch 910 Loss 0.0130\n",
      "Time taken for 1 epoch 0.21319818496704102 sec\n",
      "\n",
      "Epoch 911 Batch 0 Loss 0.0120\n",
      "Epoch 911 Loss 0.0120\n",
      "Time taken for 1 epoch 0.08768892288208008 sec\n",
      "\n",
      "Epoch 912 Batch 0 Loss 0.0084\n",
      "Epoch 912 Loss 0.0084\n",
      "Time taken for 1 epoch 0.19730401039123535 sec\n",
      "\n",
      "Epoch 913 Batch 0 Loss 0.0102\n",
      "Epoch 913 Loss 0.0102\n",
      "Time taken for 1 epoch 0.10074305534362793 sec\n",
      "\n",
      "Epoch 914 Batch 0 Loss 0.0132\n",
      "Epoch 914 Loss 0.0132\n",
      "Time taken for 1 epoch 0.20180583000183105 sec\n",
      "\n",
      "Epoch 915 Batch 0 Loss 0.0110\n",
      "Epoch 915 Loss 0.0110\n",
      "Time taken for 1 epoch 0.09259510040283203 sec\n",
      "\n",
      "Epoch 916 Batch 0 Loss 0.0108\n",
      "Epoch 916 Loss 0.0108\n",
      "Time taken for 1 epoch 0.17816901206970215 sec\n",
      "\n",
      "Epoch 917 Batch 0 Loss 0.0082\n",
      "Epoch 917 Loss 0.0082\n",
      "Time taken for 1 epoch 0.08032798767089844 sec\n",
      "\n",
      "Epoch 918 Batch 0 Loss 0.0104\n",
      "Epoch 918 Loss 0.0104\n",
      "Time taken for 1 epoch 0.15051984786987305 sec\n",
      "\n",
      "Epoch 919 Batch 0 Loss 0.0091\n",
      "Epoch 919 Loss 0.0091\n",
      "Time taken for 1 epoch 0.07239413261413574 sec\n",
      "\n",
      "Epoch 920 Batch 0 Loss 0.0099\n",
      "Epoch 920 Loss 0.0099\n",
      "Time taken for 1 epoch 0.14945292472839355 sec\n",
      "\n",
      "Epoch 921 Batch 0 Loss 0.0106\n",
      "Epoch 921 Loss 0.0106\n",
      "Time taken for 1 epoch 0.07503390312194824 sec\n",
      "\n",
      "Epoch 922 Batch 0 Loss 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 922 Loss 0.0115\n",
      "Time taken for 1 epoch 0.15752315521240234 sec\n",
      "\n",
      "Epoch 923 Batch 0 Loss 0.0107\n",
      "Epoch 923 Loss 0.0107\n",
      "Time taken for 1 epoch 0.07538199424743652 sec\n",
      "\n",
      "Epoch 924 Batch 0 Loss 0.0085\n",
      "Epoch 924 Loss 0.0085\n",
      "Time taken for 1 epoch 0.1520380973815918 sec\n",
      "\n",
      "Epoch 925 Batch 0 Loss 0.0078\n",
      "Epoch 925 Loss 0.0078\n",
      "Time taken for 1 epoch 0.07395386695861816 sec\n",
      "\n",
      "Epoch 926 Batch 0 Loss 0.0113\n",
      "Epoch 926 Loss 0.0113\n",
      "Time taken for 1 epoch 0.1601710319519043 sec\n",
      "\n",
      "Epoch 927 Batch 0 Loss 0.0092\n",
      "Epoch 927 Loss 0.0092\n",
      "Time taken for 1 epoch 0.07892894744873047 sec\n",
      "\n",
      "Epoch 928 Batch 0 Loss 0.0135\n",
      "Epoch 928 Loss 0.0135\n",
      "Time taken for 1 epoch 0.1532139778137207 sec\n",
      "\n",
      "Epoch 929 Batch 0 Loss 0.0083\n",
      "Epoch 929 Loss 0.0083\n",
      "Time taken for 1 epoch 0.07306814193725586 sec\n",
      "\n",
      "Epoch 930 Batch 0 Loss 0.0111\n",
      "Epoch 930 Loss 0.0111\n",
      "Time taken for 1 epoch 0.1566789150238037 sec\n",
      "\n",
      "Epoch 931 Batch 0 Loss 0.0100\n",
      "Epoch 931 Loss 0.0100\n",
      "Time taken for 1 epoch 0.07250714302062988 sec\n",
      "\n",
      "Epoch 932 Batch 0 Loss 0.0123\n",
      "Epoch 932 Loss 0.0123\n",
      "Time taken for 1 epoch 0.15064001083374023 sec\n",
      "\n",
      "Epoch 933 Batch 0 Loss 0.0096\n",
      "Epoch 933 Loss 0.0096\n",
      "Time taken for 1 epoch 0.07215404510498047 sec\n",
      "\n",
      "Epoch 934 Batch 0 Loss 0.0124\n",
      "Epoch 934 Loss 0.0124\n",
      "Time taken for 1 epoch 0.14995718002319336 sec\n",
      "\n",
      "Epoch 935 Batch 0 Loss 0.0105\n",
      "Epoch 935 Loss 0.0105\n",
      "Time taken for 1 epoch 0.07130694389343262 sec\n",
      "\n",
      "Epoch 936 Batch 0 Loss 0.0087\n",
      "Epoch 936 Loss 0.0087\n",
      "Time taken for 1 epoch 0.15859508514404297 sec\n",
      "\n",
      "Epoch 937 Batch 0 Loss 0.0083\n",
      "Epoch 937 Loss 0.0083\n",
      "Time taken for 1 epoch 0.07655501365661621 sec\n",
      "\n",
      "Epoch 938 Batch 0 Loss 0.0090\n",
      "Epoch 938 Loss 0.0090\n",
      "Time taken for 1 epoch 0.1627182960510254 sec\n",
      "\n",
      "Epoch 939 Batch 0 Loss 0.0106\n",
      "Epoch 939 Loss 0.0106\n",
      "Time taken for 1 epoch 0.07415390014648438 sec\n",
      "\n",
      "Epoch 940 Batch 0 Loss 0.0100\n",
      "Epoch 940 Loss 0.0100\n",
      "Time taken for 1 epoch 0.15636014938354492 sec\n",
      "\n",
      "Epoch 941 Batch 0 Loss 0.0118\n",
      "Epoch 941 Loss 0.0118\n",
      "Time taken for 1 epoch 0.07464909553527832 sec\n",
      "\n",
      "Epoch 942 Batch 0 Loss 0.0089\n",
      "Epoch 942 Loss 0.0089\n",
      "Time taken for 1 epoch 0.15662431716918945 sec\n",
      "\n",
      "Epoch 943 Batch 0 Loss 0.0072\n",
      "Epoch 943 Loss 0.0072\n",
      "Time taken for 1 epoch 0.07304692268371582 sec\n",
      "\n",
      "Epoch 944 Batch 0 Loss 0.0083\n",
      "Epoch 944 Loss 0.0083\n",
      "Time taken for 1 epoch 0.1529231071472168 sec\n",
      "\n",
      "Epoch 945 Batch 0 Loss 0.0105\n",
      "Epoch 945 Loss 0.0105\n",
      "Time taken for 1 epoch 0.07297396659851074 sec\n",
      "\n",
      "Epoch 946 Batch 0 Loss 0.0077\n",
      "Epoch 946 Loss 0.0077\n",
      "Time taken for 1 epoch 0.1544191837310791 sec\n",
      "\n",
      "Epoch 947 Batch 0 Loss 0.0123\n",
      "Epoch 947 Loss 0.0123\n",
      "Time taken for 1 epoch 0.0737147331237793 sec\n",
      "\n",
      "Epoch 948 Batch 0 Loss 0.0090\n",
      "Epoch 948 Loss 0.0090\n",
      "Time taken for 1 epoch 0.15412187576293945 sec\n",
      "\n",
      "Epoch 949 Batch 0 Loss 0.0104\n",
      "Epoch 949 Loss 0.0104\n",
      "Time taken for 1 epoch 0.07990813255310059 sec\n",
      "\n",
      "Epoch 950 Batch 0 Loss 0.0107\n",
      "Epoch 950 Loss 0.0107\n",
      "Time taken for 1 epoch 0.16183710098266602 sec\n",
      "\n",
      "Epoch 951 Batch 0 Loss 0.0137\n",
      "Epoch 951 Loss 0.0137\n",
      "Time taken for 1 epoch 0.07076025009155273 sec\n",
      "\n",
      "Epoch 952 Batch 0 Loss 0.0132\n",
      "Epoch 952 Loss 0.0132\n",
      "Time taken for 1 epoch 0.15433478355407715 sec\n",
      "\n",
      "Epoch 953 Batch 0 Loss 0.0119\n",
      "Epoch 953 Loss 0.0119\n",
      "Time taken for 1 epoch 0.07312989234924316 sec\n",
      "\n",
      "Epoch 954 Batch 0 Loss 0.0099\n",
      "Epoch 954 Loss 0.0099\n",
      "Time taken for 1 epoch 0.15350103378295898 sec\n",
      "\n",
      "Epoch 955 Batch 0 Loss 0.0074\n",
      "Epoch 955 Loss 0.0074\n",
      "Time taken for 1 epoch 0.07090306282043457 sec\n",
      "\n",
      "Epoch 956 Batch 0 Loss 0.0119\n",
      "Epoch 956 Loss 0.0119\n",
      "Time taken for 1 epoch 0.15364408493041992 sec\n",
      "\n",
      "Epoch 957 Batch 0 Loss 0.0083\n",
      "Epoch 957 Loss 0.0083\n",
      "Time taken for 1 epoch 0.07413792610168457 sec\n",
      "\n",
      "Epoch 958 Batch 0 Loss 0.0073\n",
      "Epoch 958 Loss 0.0073\n",
      "Time taken for 1 epoch 0.14852476119995117 sec\n",
      "\n",
      "Epoch 959 Batch 0 Loss 0.0080\n",
      "Epoch 959 Loss 0.0080\n",
      "Time taken for 1 epoch 0.07631587982177734 sec\n",
      "\n",
      "Epoch 960 Batch 0 Loss 0.0095\n",
      "Epoch 960 Loss 0.0095\n",
      "Time taken for 1 epoch 0.15467476844787598 sec\n",
      "\n",
      "Epoch 961 Batch 0 Loss 0.0088\n",
      "Epoch 961 Loss 0.0088\n",
      "Time taken for 1 epoch 0.07838106155395508 sec\n",
      "\n",
      "Epoch 962 Batch 0 Loss 0.0125\n",
      "Epoch 962 Loss 0.0125\n",
      "Time taken for 1 epoch 0.15658283233642578 sec\n",
      "\n",
      "Epoch 963 Batch 0 Loss 0.0065\n",
      "Epoch 963 Loss 0.0065\n",
      "Time taken for 1 epoch 0.0725700855255127 sec\n",
      "\n",
      "Epoch 964 Batch 0 Loss 0.0116\n",
      "Epoch 964 Loss 0.0116\n",
      "Time taken for 1 epoch 0.15719914436340332 sec\n",
      "\n",
      "Epoch 965 Batch 0 Loss 0.0090\n",
      "Epoch 965 Loss 0.0090\n",
      "Time taken for 1 epoch 0.07248306274414062 sec\n",
      "\n",
      "Epoch 966 Batch 0 Loss 0.0095\n",
      "Epoch 966 Loss 0.0095\n",
      "Time taken for 1 epoch 0.15096306800842285 sec\n",
      "\n",
      "Epoch 967 Batch 0 Loss 0.0062\n",
      "Epoch 967 Loss 0.0062\n",
      "Time taken for 1 epoch 0.07326483726501465 sec\n",
      "\n",
      "Epoch 968 Batch 0 Loss 0.0081\n",
      "Epoch 968 Loss 0.0081\n",
      "Time taken for 1 epoch 0.15772676467895508 sec\n",
      "\n",
      "Epoch 969 Batch 0 Loss 0.0087\n",
      "Epoch 969 Loss 0.0087\n",
      "Time taken for 1 epoch 0.07137513160705566 sec\n",
      "\n",
      "Epoch 970 Batch 0 Loss 0.0101\n",
      "Epoch 970 Loss 0.0101\n",
      "Time taken for 1 epoch 0.14971399307250977 sec\n",
      "\n",
      "Epoch 971 Batch 0 Loss 0.0101\n",
      "Epoch 971 Loss 0.0101\n",
      "Time taken for 1 epoch 0.07491922378540039 sec\n",
      "\n",
      "Epoch 972 Batch 0 Loss 0.0117\n",
      "Epoch 972 Loss 0.0117\n",
      "Time taken for 1 epoch 0.1588268280029297 sec\n",
      "\n",
      "Epoch 973 Batch 0 Loss 0.0097\n",
      "Epoch 973 Loss 0.0097\n",
      "Time taken for 1 epoch 0.07374405860900879 sec\n",
      "\n",
      "Epoch 974 Batch 0 Loss 0.0105\n",
      "Epoch 974 Loss 0.0105\n",
      "Time taken for 1 epoch 0.15115618705749512 sec\n",
      "\n",
      "Epoch 975 Batch 0 Loss 0.0091\n",
      "Epoch 975 Loss 0.0091\n",
      "Time taken for 1 epoch 0.06958317756652832 sec\n",
      "\n",
      "Epoch 976 Batch 0 Loss 0.0107\n",
      "Epoch 976 Loss 0.0107\n",
      "Time taken for 1 epoch 0.15720415115356445 sec\n",
      "\n",
      "Epoch 977 Batch 0 Loss 0.0118\n",
      "Epoch 977 Loss 0.0118\n",
      "Time taken for 1 epoch 0.07248592376708984 sec\n",
      "\n",
      "Epoch 978 Batch 0 Loss 0.0123\n",
      "Epoch 978 Loss 0.0123\n",
      "Time taken for 1 epoch 0.15196681022644043 sec\n",
      "\n",
      "Epoch 979 Batch 0 Loss 0.0091\n",
      "Epoch 979 Loss 0.0091\n",
      "Time taken for 1 epoch 0.07253026962280273 sec\n",
      "\n",
      "Epoch 980 Batch 0 Loss 0.0098\n",
      "Epoch 980 Loss 0.0098\n",
      "Time taken for 1 epoch 0.15168523788452148 sec\n",
      "\n",
      "Epoch 981 Batch 0 Loss 0.0110\n",
      "Epoch 981 Loss 0.0110\n",
      "Time taken for 1 epoch 0.07712411880493164 sec\n",
      "\n",
      "Epoch 982 Batch 0 Loss 0.0108\n",
      "Epoch 982 Loss 0.0108\n",
      "Time taken for 1 epoch 0.1505122184753418 sec\n",
      "\n",
      "Epoch 983 Batch 0 Loss 0.0099\n",
      "Epoch 983 Loss 0.0099\n",
      "Time taken for 1 epoch 0.07405781745910645 sec\n",
      "\n",
      "Epoch 984 Batch 0 Loss 0.0089\n",
      "Epoch 984 Loss 0.0089\n",
      "Time taken for 1 epoch 0.16783380508422852 sec\n",
      "\n",
      "Epoch 985 Batch 0 Loss 0.0094\n",
      "Epoch 985 Loss 0.0094\n",
      "Time taken for 1 epoch 0.0796518325805664 sec\n",
      "\n",
      "Epoch 986 Batch 0 Loss 0.0102\n",
      "Epoch 986 Loss 0.0102\n",
      "Time taken for 1 epoch 0.1547069549560547 sec\n",
      "\n",
      "Epoch 987 Batch 0 Loss 0.0072\n",
      "Epoch 987 Loss 0.0072\n",
      "Time taken for 1 epoch 0.07592201232910156 sec\n",
      "\n",
      "Epoch 988 Batch 0 Loss 0.0116\n",
      "Epoch 988 Loss 0.0116\n",
      "Time taken for 1 epoch 0.15423297882080078 sec\n",
      "\n",
      "Epoch 989 Batch 0 Loss 0.0080\n",
      "Epoch 989 Loss 0.0080\n",
      "Time taken for 1 epoch 0.0754861831665039 sec\n",
      "\n",
      "Epoch 990 Batch 0 Loss 0.0104\n",
      "Epoch 990 Loss 0.0104\n",
      "Time taken for 1 epoch 0.15246295928955078 sec\n",
      "\n",
      "Epoch 991 Batch 0 Loss 0.0073\n",
      "Epoch 991 Loss 0.0073\n",
      "Time taken for 1 epoch 0.07881307601928711 sec\n",
      "\n",
      "Epoch 992 Batch 0 Loss 0.0098\n",
      "Epoch 992 Loss 0.0098\n",
      "Time taken for 1 epoch 0.18083786964416504 sec\n",
      "\n",
      "Epoch 993 Batch 0 Loss 0.0128\n",
      "Epoch 993 Loss 0.0128\n",
      "Time taken for 1 epoch 0.11268925666809082 sec\n",
      "\n",
      "Epoch 994 Batch 0 Loss 0.0119\n",
      "Epoch 994 Loss 0.0119\n",
      "Time taken for 1 epoch 0.24540185928344727 sec\n",
      "\n",
      "Epoch 995 Batch 0 Loss 0.0100\n",
      "Epoch 995 Loss 0.0100\n",
      "Time taken for 1 epoch 0.11313605308532715 sec\n",
      "\n",
      "Epoch 996 Batch 0 Loss 0.0068\n",
      "Epoch 996 Loss 0.0068\n",
      "Time taken for 1 epoch 0.2369840145111084 sec\n",
      "\n",
      "Epoch 997 Batch 0 Loss 0.0102\n",
      "Epoch 997 Loss 0.0102\n",
      "Time taken for 1 epoch 0.11321187019348145 sec\n",
      "\n",
      "Epoch 998 Batch 0 Loss 0.0092\n",
      "Epoch 998 Loss 0.0092\n",
      "Time taken for 1 epoch 0.238372802734375 sec\n",
      "\n",
      "Epoch 999 Batch 0 Loss 0.0076\n",
      "Epoch 999 Loss 0.0076\n",
      "Time taken for 1 epoch 0.09905505180358887 sec\n",
      "\n",
      "Epoch 1000 Batch 0 Loss 0.0099\n",
      "Epoch 1000 Loss 0.0099\n",
      "Time taken for 1 epoch 0.21583294868469238 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000 # specifying the number of epochs or runs for training the model\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = model.layers[0].initialize_states(64)\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "      \n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9ZczUDcVG9B"
   },
   "source": [
    "### Translate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Excafr5LU_9p"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  attention_plot = np.zeros((output_len, input_len))\n",
    "\n",
    "  input_sentence = preprocess_sentence(input_sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in input_sentence.split()]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=input_len,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "  \n",
    "  encoder_output,state_h,state_c = model.layers[0](inputs,[tf.zeros((1, lstm_size)),tf.zeros((1, lstm_size))])\n",
    "\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(output_len):\n",
    "   predictions,state_h,state_c,attention_weights,context_vector = model.layers[1].onestepdecoder(dec_input,\n",
    "                                                                                                 encoder_output,\n",
    "                                                                                                 state_h,\n",
    "                                                                                                 state_c)\n",
    "\n",
    "   attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "   attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "   predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "   result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "   if targ_lang.index_word[predicted_id] == '<end>':\n",
    "     return result, input_sentence, attention_plot\n",
    "\n",
    "   dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, input_sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "O-U2_Lb-VObw"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sent, attention_plot = predict(sentence)\n",
    "\n",
    "  print('Input: %s' % (sent))\n",
    "  print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3sl-j0yVQax",
    "outputId": "b720ce20-9143-40c6-b171-12e80a490341"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lasa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLasa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [34], line 2\u001b[0m, in \u001b[0;36mtranslate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate\u001b[39m(sentence):\n\u001b[0;32m----> 2\u001b[0m   result, sent, attention_plot \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (sent))\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted translation: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(result))\n",
      "Cell \u001b[0;32mIn [33], line 7\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(input_sentence)\u001b[0m\n\u001b[1;32m      3\u001b[0m attention_plot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((output_len, input_len))\n\u001b[1;32m      5\u001b[0m input_sentence \u001b[38;5;241m=\u001b[39m preprocess_sentence(input_sentence)\n\u001b[0;32m----> 7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [inp_lang\u001b[38;5;241m.\u001b[39mword_index[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m input_sentence\u001b[38;5;241m.\u001b[39msplit()]\n\u001b[1;32m      8\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39msequence\u001b[38;5;241m.\u001b[39mpad_sequences([inputs],\n\u001b[1;32m      9\u001b[0m                                                        maxlen\u001b[38;5;241m=\u001b[39minput_len,\n\u001b[1;32m     10\u001b[0m                                                        padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(inputs)\n",
      "Cell \u001b[0;32mIn [33], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m attention_plot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((output_len, input_len))\n\u001b[1;32m      5\u001b[0m input_sentence \u001b[38;5;241m=\u001b[39m preprocess_sentence(input_sentence)\n\u001b[0;32m----> 7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\u001b[43minp_lang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m input_sentence\u001b[38;5;241m.\u001b[39msplit()]\n\u001b[1;32m      8\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39msequence\u001b[38;5;241m.\u001b[39mpad_sequences([inputs],\n\u001b[1;32m      9\u001b[0m                                                        maxlen\u001b[38;5;241m=\u001b[39minput_len,\n\u001b[1;32m     10\u001b[0m                                                        padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(inputs)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lasa'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/gradio/routes.py\", line 298, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/gradio/blocks.py\", line 790, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator)\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/gradio/blocks.py\", line 697, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/8v/ghq__vsn3sxc47p0y975hs880000gn/T/ipykernel_90295/1708147060.py\", line 2, in translate\n",
      "    result, sent, attention_plot = predict(sentence)\n",
      "  File \"/var/folders/8v/ghq__vsn3sxc47p0y975hs880000gn/T/ipykernel_90295/1741256839.py\", line 7, in predict\n",
      "    inputs = [inp_lang.word_index[i] for i in input_sentence.split()]\n",
      "  File \"/var/folders/8v/ghq__vsn3sxc47p0y975hs880000gn/T/ipykernel_90295/1741256839.py\", line 7, in <listcomp>\n",
      "    inputs = [inp_lang.word_index[i] for i in input_sentence.split()]\n",
      "KeyError: 'lui'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/gradio/routes.py\", line 298, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/gradio/blocks.py\", line 790, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator)\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/gradio/blocks.py\", line 697, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/8v/ghq__vsn3sxc47p0y975hs880000gn/T/ipykernel_90295/1708147060.py\", line 2, in translate\n",
      "    result, sent, attention_plot = predict(sentence)\n",
      "  File \"/var/folders/8v/ghq__vsn3sxc47p0y975hs880000gn/T/ipykernel_90295/1741256839.py\", line 7, in predict\n",
      "    inputs = [inp_lang.word_index[i] for i in input_sentence.split()]\n",
      "  File \"/var/folders/8v/ghq__vsn3sxc47p0y975hs880000gn/T/ipykernel_90295/1741256839.py\", line 7, in <listcomp>\n",
      "    inputs = [inp_lang.word_index[i] for i in input_sentence.split()]\n",
      "KeyError: 'liu'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/gradio/routes.py\", line 298, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/gradio/blocks.py\", line 790, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator)\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/gradio/blocks.py\", line 697, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/cm15/miniforge3/envs/tensorflow-env/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/8v/ghq__vsn3sxc47p0y975hs880000gn/T/ipykernel_90295/1708147060.py\", line 2, in translate\n",
      "    result, sent, attention_plot = predict(sentence)\n",
      "  File \"/var/folders/8v/ghq__vsn3sxc47p0y975hs880000gn/T/ipykernel_90295/1741256839.py\", line 7, in predict\n",
      "    inputs = [inp_lang.word_index[i] for i in input_sentence.split()]\n",
      "  File \"/var/folders/8v/ghq__vsn3sxc47p0y975hs880000gn/T/ipykernel_90295/1741256839.py\", line 7, in <listcomp>\n",
      "    inputs = [inp_lang.word_index[i] for i in input_sentence.split()]\n",
      "KeyError: 'lema'\n"
     ]
    }
   ],
   "source": [
    "translate('Lasa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sent, attention_plot = predict(sentence)\n",
    "\n",
    "  return result\n",
    "UI = gd.Interface(translate, inputs='text', outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x2e6588d90>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UI.launch()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Machine Translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
